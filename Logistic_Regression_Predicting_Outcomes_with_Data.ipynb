{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP5qs5CG5Kuvqng+Q/7VCuu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abhiss123/AlmaBetter-Projects/blob/main/Logistic_Regression_Predicting_Outcomes_with_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Project: Logistic Regression: Predicting Outcomes with Data\n",
        "\n",
        "**Purpose of the Project:**\n",
        "\n",
        "*  The purpose of this project is to demonstrate how logistic regression can be used to predict outcomes in various real-life scenarios. By building a logistic regression model, we can take raw data and use it to predict whether or not a specific event will occur. This technique is widely applicable across industries such as healthcare, finance, marketing, and e-commerce.\n",
        "\n",
        "For example, logistic regression can help answer questions like:\n",
        "\n",
        "* **Will a customer default on a loan?**\n",
        "* **Will a patient be diagnosed with a disease?**\n",
        "* **Will a user click on an advertisement?**\n",
        "* **Will a customer churn from a service?**\n",
        "\n",
        "This project illustrates how to apply logistic regression to analyze data, train a predictive model, and make informed decisions based on the results.\n"
      ],
      "metadata": {
        "id": "EX-Vavg2Ej9J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What is Logistic Regression?\n",
        "\n",
        "*  Logistic regression is a statistical method used to predict the probability of an event occurring. Specifically, it is a type of binary classification algorithm, which means it helps to predict one of two possible outcomes, such as yes/no, true/false, or clicked/not clicked. It works by analyzing the relationship between one or more independent variables (features) and a dependent variable (outcome). Logistic regression doesn't predict exact numbers; instead, it predicts the likelihood that a certain event will happen.\n",
        "\n",
        "\n",
        "#  How Logistic Regression Works?\n",
        "\n",
        "* Logistic regression uses a mathematical function called the logistic function (or sigmoid function) to convert predicted values into probabilities. The output is always between 0 and 1, which can be interpreted as a probability.\n",
        "\n",
        "**For example:**\n",
        "\n",
        "*  If the probability is **0.8, it means there is an 80% chance that the event will happen** (e.g., a customer will default on a loan).\n",
        "* If the probability is **0.2, it means there is a 20% chance that the event will happen.**\n",
        "\n",
        "We set a **threshold (commonly 0.5)** **to classify the results. If the probability is above the threshold, we predict the event will occur (e.g., \"yes\"). If it’s below the threshold, we predict the event will not occur (e.g., \"no\").**"
      ],
      "metadata": {
        "id": "6L-QtSSVHXdt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Real-Life Use Cases of Logistic Regression\n",
        "\n",
        "Logistic regression has a wide range of use cases across different industries. Here are some real-life applications:\n",
        "\n",
        "*  **Healthcare:** Predicting Heart Disease In healthcare, logistic regression can be used to predict whether a patient is at risk of developing a disease based on their medical history and test results. For example, by analyzing factors like **age, cholesterol levels, and blood pressure**, logistic regression can predict the probability that a patient will develop heart disease. **This helps doctors make preventive decisions.**\n",
        "\n",
        "* **Finance:** Loan Default Prediction Financial institutions use logistic regression to assess the likelihood of a customer defaulting on a loan. By analyzing data like a **customer's income, credit score, and loan amount**, the model can **predict the probability of default, helping banks decide whether or not to approve the loan.**\n",
        "\n",
        "* **Marketing:** Ad Click Prediction Logistic regression is widely used in marketing to predict **click-through rates (CTR).** It helps advertisers understand the likelihood of a user clicking on an online advertisement based on variables like **user demographics, time spent on the page, and device type. This allows marketers to optimize their ad campaigns and target the right audience.**\n",
        "\n",
        "* **E-commerce:** Customer Churn Prediction E-commerce platforms use logistic regression to predict whether a customer will churn (stop using the service). By analyzing **customer behavior, such as purchase history, time spent on the platform, and number of interactions,** logistic regression can forecast the probability of a customer leaving the platform. Companies can then implement strategies to retain high-risk customers.\n",
        "\n"
      ],
      "metadata": {
        "id": "YZgfqLnCIc6M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Key Elements of Logistic Regression\n",
        "\n",
        "Here are some important concepts related to logistic regression:\n",
        "\n",
        "* **Features (Independent Variables):** These are the inputs or factors that affect the outcome. **For example, in predicting heart disease, features could include age, gender, cholesterol levels, etc.**\n",
        "\n",
        "*  **Target Variable (Dependent Variable):** This is the outcome we are trying to predict, such as whether **the patient has heart disease or not (1 or 0).**\n",
        "\n",
        "* **Sigmoid Function:** This is the core function used in logistic regression to convert the **output into a probability between 0 and 1.**\n",
        "\n",
        "* **Threshold:** A decision boundary, usually set at **0.5, that determines whether the prediction is classified as a \"yes\" or \"no\".**"
      ],
      "metadata": {
        "id": "cFsjBR2UJQGr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Steps in Building a Logistic Regression Model\n",
        "\n",
        "Below is a step-by-step outline of how we would build and apply logistic regression to a project:\n",
        "\n",
        "* **Step 1:** **Data Collection** We start by gathering data that contains relevant features and the target variable. For example, in a heart disease prediction project, we would collect patient data including** age, blood pressure, cholesterol levels, and whether they were diagnosed with heart disease.**\n",
        "\n",
        "* **Step 2:** **Data Preprocessing** Preprocessing the data involves handling missing values, encoding categorical variables **(e.g., converting \"male/female\" into 0/1), and normalizing or scaling numerical values to ensure the model performs efficiently**.\n",
        "\n",
        "* **Step 3:** **Train-Test Split** We split the data into two sets: **training data** (used to train the model) and **testing data** (used to evaluate the model). Typically, **80% of the data is used for training and 20% for testing.**\n",
        "\n",
        "* **Step 4:** **Model Training** The logistic regression model is trained on the training dataset to learn the relationships between the features and the target variable.\n",
        "\n",
        "* **Step 5:** **Making Predictions** Once the model is trained, we use it to make predictions on the test dataset. The model will output probabilities that can be classified into **\"yes\" or \"no\" based on the threshold.**\n",
        "\n",
        "* **Step 6:** **Model Evaluation** We evaluate the model’s performance using metrics like **accuracy, precision, recall, and the confusion matrix** to understand how well the model is predicting the outcome."
      ],
      "metadata": {
        "id": "aTNH1aJsJxW2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Simulating data with random values\n",
        "np.random.seed(42)  # To ensure reproducibility\n",
        "\n",
        "# Creating a DataFrame with random values\n",
        "data = pd.DataFrame({\n",
        "    'age': np.random.randint(18, 65, size=1000),  # Random ages between 18 and 65\n",
        "    'time_on_page': np.random.uniform(5, 300, size=1000),  # Random time spent on page (in seconds)\n",
        "    'number_of_clicks': np.random.randint(1, 10, size=1000),  # Random number of clicks between 1 and 10\n",
        "    'clicked': np.random.choice([0, 1], size=1000)  # Randomly assigning whether the user clicked or not (binary)\n",
        "})\n",
        "\n",
        "# Save the simulated data to a CSV file\n",
        "data.to_csv('user_data.csv', index=False)\n",
        "\n",
        "print(\"Sample data created and saved as 'user_data.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEYtU2J-pdFb",
        "outputId": "4dea7079-a554-47f6-e0ca-50b78765de95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample data created and saved as 'user_data.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BirOInR7lHWn",
        "outputId": "e00d666f-1e24-4df3-8548-2e16d7d7f6b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Loaded Successfully!\n",
            "   age  time_on_page  number_of_clicks  clicked\n",
            "0   56    100.094384                 6        0\n",
            "1   46    243.912962                 2        0\n",
            "2   32     80.118993                 7        0\n",
            "3   60    206.043303                 3        0\n",
            "4   25    229.267219                 3        0\n",
            "Checking for missing values...\n",
            "age                 0\n",
            "time_on_page        0\n",
            "number_of_clicks    0\n",
            "clicked             0\n",
            "dtype: int64\n",
            "Model Accuracy: 49.00%\n",
            "Confusion Matrix:\n",
            "[[89  6]\n",
            " [96  9]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.94      0.64        95\n",
            "           1       0.60      0.09      0.15       105\n",
            "\n",
            "    accuracy                           0.49       200\n",
            "   macro avg       0.54      0.51      0.39       200\n",
            "weighted avg       0.54      0.49      0.38       200\n",
            "\n",
            "Feature: age, Coefficient: -0.020258006078327746\n",
            "Feature: time_on_page, Coefficient: -0.041656068478480406\n",
            "Feature: number_of_clicks, Coefficient: 0.042516173542091286\n"
          ]
        }
      ],
      "source": [
        "# Import all the necessary libraries that we will use in our project\n",
        "import pandas as pd  # for handling the data (structured in rows and columns)\n",
        "import numpy as np  # for mathematical operations\n",
        "from sklearn.model_selection import train_test_split  # to split the data into training and testing sets\n",
        "from sklearn.preprocessing import StandardScaler  # to standardize (normalize) the data\n",
        "from sklearn.linear_model import LogisticRegression  # the logistic regression model\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report  # to evaluate the model's performance\n",
        "\n",
        "# Step 1: Loading the Data (This should be replaced with your actual data)\n",
        "# In this example, we're assuming that you already have a CSV file with user behavior data\n",
        "# You will replace 'user_data.csv' with the actual file path containing data from the website\n",
        "# The dataset should have features like 'age', 'time_on_page', 'number_of_clicks', and the target 'clicked' (1 for yes, 0 for no)\n",
        "\n",
        "data = pd.read_csv('user_data.csv')  # Replace this with your actual file\n",
        "print(\"Data Loaded Successfully!\")\n",
        "print(data.head())  # Display the first 5 rows of the dataset\n",
        "\n",
        "# Step 2: Data Preprocessing (Handling missing values, converting categorical data, etc.)\n",
        "# Check if there are any missing values\n",
        "print(\"Checking for missing values...\")\n",
        "print(data.isnull().sum())  # This will show the number of missing values per column\n",
        "\n",
        "# In this example, we assume there are no missing values. Otherwise, you can handle missing data like this:\n",
        "# data.fillna(method='ffill', inplace=True)  # This fills missing values with the previous value (forward fill)\n",
        "\n",
        "# Step 3: Defining Features (X) and the Target (y)\n",
        "# X will be all the features that help us predict the outcome (like age, time spent, etc.)\n",
        "# y will be the binary target (whether the user clicked on a link or not)\n",
        "\n",
        "X = data[['age', 'time_on_page', 'number_of_clicks']]  # Replace with actual feature columns in your data\n",
        "y = data['clicked']  # This is the target column, where 1 means clicked, 0 means not clicked\n",
        "\n",
        "# Step 4: Splitting the data into Training and Testing Sets\n",
        "# We split the data so that we can train the model on one part and test its performance on another part\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 5: Standardizing the Features\n",
        "# Logistic regression models work better when features are standardized (mean of 0 and variance of 1)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Step 6: Initializing and Training the Logistic Regression Model\n",
        "# Here we create an instance of the logistic regression model and train it on our training data\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 7: Making Predictions on the Test Data\n",
        "# Now that the model is trained, we can make predictions on the test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Step 8: Evaluating the Model's Performance\n",
        "# We use different metrics to understand how well our model is performing\n",
        "# Accuracy tells us the percentage of correct predictions\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Confusion matrix shows the true positives, false positives, true negatives, and false negatives\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# The classification report gives a more detailed breakdown (precision, recall, f1-score)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Step 9: Model Interpretation (Optional, Advanced Step)\n",
        "# You can access the coefficients (weights) of the features to understand which features have the most impact on the outcome\n",
        "coefficients = model.coef_[0]\n",
        "for feature, coef in zip(['age', 'time_on_page', 'number_of_clicks'], coefficients):\n",
        "    print(f\"Feature: {feature}, Coefficient: {coef}\")\n",
        "\n",
        "# The larger the coefficient (positive or negative), the more influence the feature has on the outcome.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Accessing External Files:\n",
        "* Colab is a cloud-based environment, which means it doesn’t automatically have access to files stored on your local machine or in your Google Drive. If you have data files (e.g., CSV, ZIP) saved in your Google Drive that you want to use in Colab, you need to \"mount\" or connect your Google Drive to Colab so that it can access those files.\n",
        "\n",
        "# Using Data from Drive:\n",
        "* If you have a dataset, a ZIP file, or any other file stored in your Google Drive, mounting it allows you to access those files as if they were part of Colab’s local file system. This makes it easy to work with large datasets that you’ve already uploaded to your Drive.\n",
        "\n",
        "# Saving Results Back to Drive:\n",
        "* Not only can you read files from Google Drive, but you can also save output files or results back into your Google Drive. This is useful for saving model outputs, processed data, or other results that you may need later.\n",
        "\n",
        "# How It Works:\n",
        "* **drive.mount('/content/drive'):** This command mounts (connects) your Google Drive to your Colab environment. Once executed, Colab will prompt you to authorize the connection by signing in to your Google account and allowing access.\n",
        "\n",
        "* **Authorization:** You’ll need to grant permission for Colab to access your Google Drive. After that, the contents of your Google Drive will be available in the Colab environment."
      ],
      "metadata": {
        "id": "pmTZwPnRUEb4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Once mounted, your Google Drive files will be accessible under '/content/drive/MyDrive/'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2yjM9wRn6W7",
        "outputId": "0c76437a-aba5-43b6-b1cf-8ebb77327ac7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Import necessary libraries:**\n",
        "\n",
        "import zipfile\n",
        "\n",
        "import os\n",
        "\n",
        "* **zipfile:** This module is used to work with ZIP files. It allows you to read, write, and extract ZIP archives.\n",
        "* **os:** This module is used to interact with the file system. It helps in navigating directories, listing files, and other file-related operations.\n",
        "\n",
        "**2. Define the path to your ZIP file on Google Drive:**\n",
        "\n",
        "**zip_file_path** = '/content/drive/MyDrive/Ad Click Prediction/archive (2).zip'\n",
        "\n",
        "**Purpose:** You’re specifying the location of the ZIP file in Google Drive.\n",
        "* The **zip_file_path** points to the ZIP file you want to extract. This path must be the correct path where the ZIP file is located in Google Drive.\n",
        "* **/content/drive/MyDrive/** is the path to your Google Drive folder once it’s mounted in Colab.\n",
        "* **Ad Click Prediction/archive (2).zip** refers to the specific folder and ZIP file within Google Drive.\n",
        "\n",
        "**3. Specify the folder where the extracted files will be saved**\n",
        "\n",
        "**extracted_folder_path** = '/content/netflix_data/'\n",
        "\n",
        "* **Purpose:** Here, you define a local folder in your Colab environment where the contents of the ZIP file will be extracted.\n",
        "* **/content/netflix_data/** is a directory within Colab where you want to save the extracted files.\n",
        "* Colab operates in a cloud environment, so this path refers to a local folder in the Colab environment (not Google Drive).\n",
        "\n",
        "**4. Unzipping the file**\n",
        "\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "\n",
        "    zip_ref.extractall(extracted_folder_path)\n",
        "\n",
        "* **Purpose:** This step extracts the contents of the ZIP file.\n",
        "\n",
        "**How It Works:**\n",
        "\n",
        "* **zipfile.ZipFile(zip_file_path, 'r'):** Opens the ZIP file in **read mode** ('r'). The zip_file_path points to the file you want to extract.\n",
        "\n",
        "*  **zip_ref.extractall(extracted_folder_path):** Extracts all the contents of the ZIP file into the specified folder **(extracted_folder_path).**\n",
        "\n",
        "* **The extractall()** method takes the extracted contents and saves them into the folder path you defined earlier (in this case, /content/netflix_data/).\n",
        "\n",
        "**5. Listing the extracted files**\n",
        "\n",
        "extracted_files = os.listdir(extracted_folder_path)\n",
        "\n",
        "print(\"Extracted files:\", extracted_files)\n",
        "\n",
        "8 **Purpose:** This step lists and prints the files that were extracted to ensure the ZIP file was unpacked correctly.\n",
        "\n",
        "**How It Works:**\n",
        "* **os.listdir(extracted_folder_path):** This function lists all the files in the folder **/content/netflix_data/** (where the ZIP was extracted).\n",
        "* **print(extracted_files):** Prints the names of the files to the console so you can verify that the extraction process was successful and see which files were extracted.\n"
      ],
      "metadata": {
        "id": "Su1hI3IbWAt7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Define the path to your ZIP file on Google Drive\n",
        "zip_file_path = '/content/drive/MyDrive/Netflix Datset For Logistic Regression/archive.zip'  # Replace with actual path\n",
        "\n",
        "# Directory where the extracted file will be saved\n",
        "extracted_folder_path = '/content/netflix_data/'\n",
        "\n",
        "# Unzipping the file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extracted_folder_path)\n",
        "\n",
        "# List the extracted files to ensure it was successful\n",
        "extracted_files = os.listdir(extracted_folder_path)\n",
        "print(\"Extracted files:\", extracted_files)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3UntU6CxcpJ",
        "outputId": "88ff8ba1-867e-4042-b32a-04a38c1cd426"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted files: ['adsclicking.csv', 'netflix_titles.csv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Import the pandas library**\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "**Purpose:** This line imports the **pandas** library, which is a powerful Python library used for **data manipulation and analysis.**\n",
        "\n",
        "* **pandas** provides data structures like **DataFrames**, which make it easy to load, manipulate, and analyze tabular data (e.g., from CSV files).\n",
        "\n",
        "**2. Specify the path to the extracted CSV file**\n",
        "\n",
        "**csv_file_path** = '/content/netflix_data/netflix_titles.csv'\n",
        "\n",
        "**Purpose:** This line defines the path to the CSV file that you want to load into the Colab environment.\n",
        "* **csv_file_path** is a variable that holds the file path where the **netflix_titles.csv** file is located.\n",
        "\n",
        "* The path **/content/netflix_data/netflix_titles.csv** refers to the location in the Colab environment where the CSV file was extracted (in a previous step). You extracted this file from a ZIP archive, so now you're loading it for analysis.\n",
        "\n",
        "**3. Load the CSV file into a pandas DataFrame**\n",
        "\n",
        "**Purpose:** This line loads the CSV file into a pandas DataFrame.\n",
        "\n",
        "* **pd.read_csv(csv_file_path):** This function reads the CSV file from the specified path **(csv_file_path)** and loads it into a DataFrame, which is a table-like data structure in pandas. Each column in the CSV file becomes a column in the DataFrame, and each row in the CSV becomes a row in the DataFrame.\n",
        "\n",
        "*  The **DataFrame (data)** is a versatile structure that allows you to perform various operations like filtering, sorting, grouping, and analyzing data efficiently.\n",
        "\n",
        "**4. Display the first few rows of the data**\n",
        "\n",
        "print(data.head())\n",
        "\n",
        "**Purpose:** This line is used to print the first few rows of the loaded DataFrame to verify that the data was loaded successfully.\n",
        "*  **data.head():** This function returns the first 5 rows of the DataFrame by default. It is a quick way to inspect the data and ensure that it was loaded correctly.\n",
        "\n",
        "*  **Why It’s Important:** This step is crucial for confirming that the CSV file was read correctly. It helps you see if the data has been loaded as expected, whether the columns are named correctly, and if the data is properly structured.\n",
        "\n"
      ],
      "metadata": {
        "id": "0Xk_HnudZoQj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Verify if the 'netflix_titles.csv' exists in the extracted files\n",
        "csv_file_name = 'netflix_titles.csv'  # Name of the CSV file\n",
        "csv_file_path = os.path.join(extracted_folder_path, csv_file_name)\n",
        "\n",
        "if csv_file_name in extracted_files:\n",
        "    print(f\"File '{csv_file_name}' found! Proceeding to load the file.\")\n",
        "\n",
        "    # Step 6: Load the CSV file into a DataFrame\n",
        "    data = pd.read_csv(csv_file_path)\n",
        "\n",
        "    # Step 7: Display the first few rows of the data to confirm successful loading\n",
        "    print(\"First few rows of the dataset:\")\n",
        "    print(data.head())\n",
        "else:\n",
        "    print(f\"File '{csv_file_name}' not found in the extracted files. Please check the file path or extraction.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9US7yNox9sj",
        "outputId": "25be54d5-c9a0-4b88-a751-83221126c3ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File 'netflix_titles.csv' found! Proceeding to load the file.\n",
            "First few rows of the dataset:\n",
            "  show_id     type                  title         director  \\\n",
            "0      s1    Movie   Dick Johnson Is Dead  Kirsten Johnson   \n",
            "1      s2  TV Show          Blood & Water              NaN   \n",
            "2      s3  TV Show              Ganglands  Julien Leclercq   \n",
            "3      s4  TV Show  Jailbirds New Orleans              NaN   \n",
            "4      s5  TV Show           Kota Factory              NaN   \n",
            "\n",
            "                                                cast        country  \\\n",
            "0                                                NaN  United States   \n",
            "1  Ama Qamata, Khosi Ngema, Gail Mabalane, Thaban...   South Africa   \n",
            "2  Sami Bouajila, Tracy Gotoas, Samuel Jouy, Nabi...            NaN   \n",
            "3                                                NaN            NaN   \n",
            "4  Mayur More, Jitendra Kumar, Ranjan Raj, Alam K...          India   \n",
            "\n",
            "           date_added  release_year rating   duration  \\\n",
            "0  September 25, 2021          2020  PG-13     90 min   \n",
            "1  September 24, 2021          2021  TV-MA  2 Seasons   \n",
            "2  September 24, 2021          2021  TV-MA   1 Season   \n",
            "3  September 24, 2021          2021  TV-MA   1 Season   \n",
            "4  September 24, 2021          2021  TV-MA  2 Seasons   \n",
            "\n",
            "                                           listed_in  \\\n",
            "0                                      Documentaries   \n",
            "1    International TV Shows, TV Dramas, TV Mysteries   \n",
            "2  Crime TV Shows, International TV Shows, TV Act...   \n",
            "3                             Docuseries, Reality TV   \n",
            "4  International TV Shows, Romantic TV Shows, TV ...   \n",
            "\n",
            "                                         description  \n",
            "0  As her father nears the end of his life, filmm...  \n",
            "1  After crossing paths at a party, a Cape Town t...  \n",
            "2  To protect his family from a powerful drug lor...  \n",
            "3  Feuds, flirtations and toilet talk go down amo...  \n",
            "4  In a city of coaching centers known to train I...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Create the 'clicked' target column\n",
        "\n",
        "data['clicked'] = data['release_year'].apply(lambda x: 1 if x > 2015 else 0)\n",
        "\n",
        "**Purpose:** This step creates a new column called 'clicked' in the dataset. The idea here is to simulate user interaction by assuming that users are more likely to click on content released after 2015.\n",
        "\n",
        "**How It Works:** The .apply() function is used to apply a custom function to the release_year column. For each entry:\n",
        "\n",
        "*  If the release year is greater than 2015, the value in the clicked column is set to 1 (meaning the content was clicked).\n",
        "\n",
        "*  If the release year is less than or equal to 2015, the value is set to 0 (meaning the content was not clicked).\n",
        "\n",
        "**Example:**\n",
        "*  If the release_year is 2018, clicked = 1.\n",
        "*  If the release_year is 2013, clicked = 0.\n",
        "\n",
        "# 2. Select relevant features and target variable\n",
        "\n",
        "X = data[['type', 'release_year']]  # You can add more features here\n",
        "\n",
        "y = data['clicked']\n",
        "\n",
        "**Purpose:** This step selects the input features (X) and the target variable (y) for the logistic regression model.\n",
        "*   **X (Features):** In this case, the features are **'type'** (whether it’s a Movie or TV Show) and **'release_year'.**\n",
        "*  **y (Target):** The target is the **'clicked'** column we created in the previous step, which represents whether a user clicked on the content or not.\n",
        "\n",
        "**Example:**\n",
        "* **Features (X)** might be:\n",
        "     * **type:** Movie or TV Show.\n",
        "     * **release_year:** The year the content was released.\n",
        "*  **Target (y):** Whether the user clicked (1) or did not click (0) on the content.\n",
        "\n",
        "# 3. Encode categorical features\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "X['type'] = label_encoder.fit_transform(X['type'])\n",
        "\n",
        "**Purpose:** The 'type' column is categorical (it has non-numeric values like \"Movie\" and \"TV Show\"). Machine learning models like logistic regression require numeric values, so we use label encoding to convert the categories into numbers.\n",
        "\n",
        "* **Movie = 1**\n",
        "* **TV Show = 0**\n",
        "\n",
        "**How It Works:**\n",
        "\n",
        "**LabelEncoder():** This transforms the categorical values (Movie and TV Show) into numerical values.\n",
        "\n",
        "**Example:**\n",
        "* If a row has **type = \"Movie\",** it will be converted to **1.**\n",
        "* If a row has **type = \"TV Show\",** it will be converted to **0.**\n",
        "\n",
        "# 4. Split the data into training and testing sets\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "**How It Works:**\n",
        "\n",
        "**train_test_split(X, y, test_size=0.2):**\n",
        "\n",
        "* X_train and y_train are the training data and labels.\n",
        "\n",
        "* X_test and y_test are the testing data and labels.\n",
        "\n",
        "* The test_size=0.2 argument means 20% of the data will be used for testing, and 80% for training.\n",
        "\n",
        "* random_state=42: Ensures the same split each time you run the code for consistency in results.\n",
        "\n",
        "**Example:**\n",
        "*  If there are 1000 data points, 800 will be used for training and 200 for testing.\n",
        "\n",
        "**5. Train the logistic regression model**\n",
        "\n",
        "model = LogisticRegression()\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "**Purpose:** This step initializes and trains the logistic regression model using the training data.\n",
        "* LogisticRegression(): Creates an instance of the logistic regression model.\n",
        "* model.fit(X_train, y_train): Trains the model on the training data (X_train) and the corresponding labels (y_train).\n",
        "\n",
        "**How It Works:**\n",
        "* The logistic regression algorithm looks at the relationship between the features (type and release_year) and the target variable (clicked or not clicked) to learn a model that can predict clicks for new data.\n",
        "\n",
        "**Example:**\n",
        "* The model will learn that newer content (after 2015) and movies are more likely to be clicked based on the training data.\n",
        "\n",
        "**6. Make predictions**\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "**Purpose:** This step uses the trained model to make predictions on the test data.\n",
        "* model.predict(X_test): Uses the features in the test set (X_test) to predict whether users will click on the content (1) or not (0).\n",
        "\n",
        "**How It Works:**\n",
        "* The model takes the X_test data (which was not used during training) and uses the learned relationships from the training data to make predictions.\n",
        "\n",
        "**Example:**\n",
        "* For a test data point where release_year = 2018 and type = \"Movie\", the model might predict clicked = 1 (user clicked).\n",
        "\n",
        "# 7. Evaluate the model\n",
        "\n",
        "**7.1. Calculate the accuracy**\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "\n",
        "**Purpose:** This step calculates the accuracy of the model, which tells you the proportion of correct predictions.\n",
        "*  accuracy_score(y_test, y_pred): Compares the true labels (y_test) with the predicted labels (y_pred) and calculates the percentage of correct predictions.\n",
        "\n",
        "**Example:**\n",
        "* If the model correctly predicts 90 out of 100 test cases, the accuracy will be 90%.\n",
        "\n",
        "**7.2. Display the confusion matrix**\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "**Purpose:** The confusion matrix shows how many true positives, true negatives, false positives, and false negatives the model made.\n",
        "* **True Positive (TP):** Correctly predicted a click (clicked = 1).\n",
        "* **True Negative (TN):** Correctly predicted no click (clicked = 0).\n",
        "* **False Positive (FP):** Incorrectly predicted a click (predicted clicked = 1, but actual was 0).\n",
        "* **False Negative (FN):** Incorrectly predicted no click (predicted clicked = 0, but actual was 1).\n",
        "\n",
        "**Example:**\n",
        "\n",
        "**A confusion matrix of:**\n",
        "\n",
        "[[50, 10],\n",
        "\n",
        " [5, 35]]\n",
        "\n",
        "means:\n",
        "\n",
        "* 50 true negatives, 35 true positives.\n",
        "* 10 false positives, 5 false negatives.\n",
        "\n",
        "\n",
        "**7.3. Display the classification report**\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "**Purpose:** The classification report provides more detailed metrics, including:\n",
        "*  **Precision:** The proportion of true positive predictions out of all positive predictions.\n",
        "*  **Recall:** The proportion of actual positive cases that were correctly predicted.\n",
        "* **F1-Score:** A balanced metric that combines precision and recall.\n",
        "\n",
        "**Example:**\n",
        "\n",
        "\n",
        "A classification report might show:\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "This shows the model's performance for each class (0 = not clicked, 1 = clicked).\n",
        "\n"
      ],
      "metadata": {
        "id": "E_-JnrutcSHc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary libraries and modules\n",
        "\n",
        "# This module helps in splitting the data into training and testing sets.\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# This is the machine learning model that we will use to predict whether content will be clicked or not (Logistic Regression).\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# These functions will help us evaluate how well the model performs by providing metrics like accuracy, confusion matrix, etc.\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# LabelEncoder helps convert text values (like 'Movie' and 'TV Show') into numerical values that the model can understand.\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# SMOTE (Synthetic Minority Over-sampling Technique) is used to balance the dataset if there are more \"clicks\" than \"no clicks\".\n",
        "# It creates synthetic samples for the minority class (in this case, likely \"no clicks\") so that both classes have equal representation.\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Step 1: Simulate a 'clicked' target based on release year\n",
        "# Explanation: We are creating a new column called 'clicked' in our dataset.\n",
        "# The 'clicked' column will contain either a 1 (user clicked on the content) or a 0 (user did not click on the content).\n",
        "# We assume that content released after 2015 is more likely to be clicked, so we assign '1' if the release year is greater than 2015.\n",
        "# Otherwise, we assign '0' for content released before or in 2015.\n",
        "data['clicked'] = data['release_year'].apply(lambda x: 1 if x > 2015 else 0)\n",
        "\n",
        "# Step 2: Select relevant features\n",
        "# Explanation: Features are the factors that the model will use to make predictions.\n",
        "# In this case, we are using two features: 'type' (whether the content is a Movie or TV Show) and 'release_year' (the year the content was released).\n",
        "# 'X' is the variable that stores the features, and 'y' stores the target (whether the content was clicked or not).\n",
        "X = data[['type', 'release_year']]  # X contains the features\n",
        "y = data['clicked']  # y is the target variable we are trying to predict\n",
        "\n",
        "# Step 3: Convert categorical data\n",
        "# Explanation: The 'type' column contains text values (like 'Movie' and 'TV Show'), but the model needs numerical values.\n",
        "# We use the LabelEncoder to convert these text values into numbers. For example, 'Movie' becomes 1 and 'TV Show' becomes 0.\n",
        "label_encoder = LabelEncoder()\n",
        "X['type'] = label_encoder.fit_transform(X['type'])  # Transforming 'type' column into 1s and 0s\n",
        "\n",
        "# Step 4: Resample the data to address class imbalance\n",
        "# Explanation: If there are more \"clicks\" than \"no clicks\" in the data, the model may become biased towards predicting \"clicks\".\n",
        "# To prevent this, we use SMOTE to create synthetic examples of \"no clicks\" so that the dataset has an equal number of clicks and no clicks.\n",
        "# This helps the model learn to predict both outcomes more fairly.\n",
        "smote = SMOTE(random_state=42)  # SMOTE helps balance the dataset by adding synthetic examples\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)  # Resample the data to make sure both classes (click and no click) have the same amount of data\n",
        "\n",
        "# Step 5: Split the data into training and testing sets\n",
        "# Explanation: Before we train the model, we need to split the data into two parts: training data and testing data.\n",
        "# - Training data is used to teach the model.\n",
        "# - Testing data is used to evaluate how well the model performs on unseen data.\n",
        "# We use 80% of the data for training and 20% for testing.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 6: Train a Logistic Regression model with balanced class weight\n",
        "# Explanation: Logistic Regression is a model that predicts a binary outcome (in this case, clicked or not clicked).\n",
        "# We use class_weight='balanced' to give equal importance to both \"clicks\" and \"no clicks\".\n",
        "# The 'C=0.5' parameter controls how complex the model is, preventing it from overfitting the training data (i.e., making sure it doesn't perform too well on training data but poorly on new data).\n",
        "model = LogisticRegression(class_weight='balanced', C=0.5)  # Create the model with balanced classes and regularization\n",
        "model.fit(X_train, y_train)  # Train the model on the training data (teach the model)\n",
        "\n",
        "# Step 7: Make predictions\n",
        "# Explanation: Now that the model has been trained, we use it to predict whether the content in the test data will be clicked or not.\n",
        "# We pass the test data (X_test) into the model, and the model gives us predictions (y_pred), which tell us whether the content will be clicked (1) or not clicked (0).\n",
        "y_pred = model.predict(X_test)  # Use the trained model to make predictions on the test data\n",
        "\n",
        "# Step 8: Evaluate the model\n",
        "# Explanation: After making predictions, we evaluate how well the model did. There are a few metrics we use:\n",
        "# - Accuracy: The percentage of correct predictions made by the model.\n",
        "# - Confusion Matrix: Shows the number of correct and incorrect predictions for both \"click\" and \"no click\".\n",
        "# - Classification Report: Provides more details like precision (how many of the predicted clicks were correct) and recall (how many actual clicks were predicted correctly).\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))  # Print the accuracy of the model\n",
        "print(\"Confusion Matrix:\")  # The confusion matrix helps us understand where the model is making errors\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"Classification Report:\")  # The classification report provides detailed information on how well the model performs\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oag7Ss34mRpI",
        "outputId": "31e225f5-95f6-4efe-ef75-f9d64093ef33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-d95038341dff>:37: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X['type'] = label_encoder.fit_transform(X['type'])  # Transforming 'type' column into 1s and 0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5691559876270438\n",
            "Confusion Matrix:\n",
            "[[867 250]\n",
            " [725 421]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.78      0.64      1117\n",
            "           1       0.63      0.37      0.46      1146\n",
            "\n",
            "    accuracy                           0.57      2263\n",
            "   macro avg       0.59      0.57      0.55      2263\n",
            "weighted avg       0.59      0.57      0.55      2263\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the necessary libraries and modules\n",
        "\n",
        "# pandas is used for data manipulation and analysis. It helps load and work with datasets.\n",
        "import pandas as pd\n",
        "\n",
        "# train_test_split is used to split the dataset into training and testing parts\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# LogisticRegression is the machine learning model that predicts whether a user will click or not\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# These modules help evaluate the performance of the model using metrics like accuracy, confusion matrix, and classification report\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# LabelEncoder helps convert text-based (categorical) features into numerical values, since machine learning models work with numbers\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# SMOTE (Synthetic Minority Over-sampling Technique) is used to balance the dataset, especially when one class (e.g., \"clicks\") is over-represented\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Step 1: Create a 'clicked' target based on release year\n",
        "# Explanation: We create a new column in the dataset called 'clicked'.\n",
        "# This column has a value of 1 if the content was released after 2015 (indicating a click), and 0 otherwise (no click).\n",
        "data['clicked'] = data['release_year'].apply(lambda x: 1 if x > 2015 else 0)\n",
        "\n",
        "# Step 2: Select features (factors) that the model will use to predict clicks\n",
        "# Explanation: We need to give the model more information to make better predictions.\n",
        "# In addition to 'type' and 'release_year', we also include 'duration', 'country', 'listed_in', and 'rating'.\n",
        "# These are characteristics of the content that might affect whether someone clicks on it.\n",
        "X = data[['type', 'release_year', 'duration', 'country', 'listed_in', 'rating']]  # Features (factors) for prediction\n",
        "y = data['clicked']  # The target (whether a user clicked or not)\n",
        "\n",
        "# Step 3: Convert categorical data (text) into numerical data using LabelEncoder\n",
        "# Explanation: Machine learning models need numbers to work, so we need to convert text features like 'type', 'country', 'listed_in', and 'rating' into numbers.\n",
        "# LabelEncoder converts text values like 'Movie' and 'TV Show' into numerical codes.\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Convert 'type' column (Movie = 1, TV Show = 0)\n",
        "X['type'] = label_encoder.fit_transform(X['type'])  # 'Movie' becomes 1, 'TV Show' becomes 0\n",
        "\n",
        "# Convert 'country' column into numerical values (e.g., 'United States' might become 1, 'India' might become 2, etc.)\n",
        "X['country'] = label_encoder.fit_transform(X['country'].astype(str))  # Make sure no missing values exist\n",
        "\n",
        "# Convert 'listed_in' column (categories of content) into numerical values\n",
        "X['listed_in'] = label_encoder.fit_transform(X['listed_in'].astype(str))\n",
        "\n",
        "# Convert 'rating' column (e.g., PG, PG-13, TV-MA) into numerical values\n",
        "X['rating'] = label_encoder.fit_transform(X['rating'].astype(str))\n",
        "\n",
        "# Convert 'duration' column (length of content) into numerical values\n",
        "X['duration'] = label_encoder.fit_transform(X['duration'].astype(str))\n",
        "\n",
        "# Step 4: Balance the dataset using SMOTE (Synthetic Minority Over-sampling Technique)\n",
        "# Explanation: If the dataset has more clicks than no clicks, the model may become biased and predict \"click\" more often.\n",
        "# SMOTE generates synthetic data to balance the dataset, creating more \"no click\" examples so that both classes are fairly represented.\n",
        "smote = SMOTE(sampling_strategy=0.7, random_state=42)  # SMOTE will generate synthetic examples to ensure balance\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)  # Apply SMOTE to create balanced data\n",
        "\n",
        "# Step 5: Split the data into training and testing sets\n",
        "# Explanation: We split the dataset into two parts: training and testing.\n",
        "# - The training set (80%) is used to teach the model how to predict clicks.\n",
        "# - The testing set (20%) is used to check how well the model performs on unseen data.\n",
        "# 'random_state=42' ensures that the split is the same every time we run the code.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 6: Train a Logistic Regression model\n",
        "# Explanation: We use logistic regression to predict a binary outcome (click or no click).\n",
        "# 'class_weight=\"balanced\"' ensures the model gives equal importance to predicting both clicks and no clicks.\n",
        "# 'C=1.0' controls how much regularization the model applies to avoid overfitting (fitting too closely to the training data).\n",
        "model = LogisticRegression(class_weight='balanced', C=1.0)  # Train the model with balanced weights and a regularization factor\n",
        "model.fit(X_train, y_train)  # Fit the model (train it) using the training data\n",
        "\n",
        "# Step 7: Make predictions on the test data\n",
        "# Explanation: Now that the model is trained, we ask it to predict whether content in the test set will be clicked or not.\n",
        "# The model will output predictions (1 = clicked, 0 = not clicked).\n",
        "y_pred = model.predict(X_test)  # Use the trained model to predict clicks on the test data\n",
        "\n",
        "# Step 8: Evaluate the model using various metrics\n",
        "# Explanation: After making predictions, we evaluate how well the model performed.\n",
        "# We use three metrics:\n",
        "# 1) Accuracy: The percentage of correct predictions.\n",
        "# 2) Confusion Matrix: Shows how many correct and incorrect predictions the model made for both \"click\" and \"no click\".\n",
        "# 3) Classification Report: Provides more detailed metrics like precision (how often the model's \"click\" predictions were correct) and recall (how many actual clicks the model caught).\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))  # Print the accuracy of the model\n",
        "print(\"Confusion Matrix:\")  # The confusion matrix helps us see where the model is making errors\n",
        "print(confusion_matrix(y_test, y_pred))  # Shows how many correct/incorrect predictions for each class\n",
        "print(\"Classification Report:\")  # Provides detailed information on precision, recall, and F1-score\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKyNSBgFqWMX",
        "outputId": "c5bae233-e135-45c5-b2b4-0850a6c23a52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6432657306292252\n",
            "Confusion Matrix:\n",
            "[[487 307]\n",
            " [379 750]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.61      0.59       794\n",
            "           1       0.71      0.66      0.69      1129\n",
            "\n",
            "    accuracy                           0.64      1923\n",
            "   macro avg       0.64      0.64      0.64      1923\n",
            "weighted avg       0.65      0.64      0.65      1923\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-8fd51eeabcda>:39: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X['type'] = label_encoder.fit_transform(X['type'])  # 'Movie' becomes 1, 'TV Show' becomes 0\n",
            "<ipython-input-10-8fd51eeabcda>:42: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X['country'] = label_encoder.fit_transform(X['country'].astype(str))  # Make sure no missing values exist\n",
            "<ipython-input-10-8fd51eeabcda>:45: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X['listed_in'] = label_encoder.fit_transform(X['listed_in'].astype(str))\n",
            "<ipython-input-10-8fd51eeabcda>:48: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X['rating'] = label_encoder.fit_transform(X['rating'].astype(str))\n",
            "<ipython-input-10-8fd51eeabcda>:51: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X['duration'] = label_encoder.fit_transform(X['duration'].astype(str))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code 1: Netflix Dataset for Predicting User Engagement (Click-Through Prediction)\n",
        "\n",
        "**Purpose:**\n",
        "* This code is designed to predict user engagement (whether a user is likely to click on or interact with content) based on the Netflix dataset. It uses logistic regression to predict whether content will be \"clicked\" based on its release year and type (TV Show or Movie).\n"
      ],
      "metadata": {
        "id": "5AfUkYxIN0w7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Mount Google Drive\n",
        "# This step will allow you to access files stored on your Google Drive.\n",
        "# After running this, Colab will prompt you to grant access to your Google Drive account.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Once mounted, your Google Drive files will be accessible under '/content/drive/MyDrive/'\n",
        "# Make sure the ZIP file is uploaded to your Drive and note the path.\n",
        "\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Step 2: Define the path to your ZIP file on Google Drive\n",
        "# Replace the 'zip_file_path' with the actual path to your ZIP file in Google Drive\n",
        "zip_file_path = '/content/drive/MyDrive/Netflix Datset For Logistic Regression/archive.zip'\n",
        "\n",
        "# Step 3: Specify where the ZIP file will be extracted (inside Colab environment)\n",
        "extracted_folder_path = '/content/netflix_data/'\n",
        "\n",
        "# Step 4: Unzipping the file\n",
        "# The 'zipfile' module is used to extract the contents of the ZIP file.\n",
        "# The extracted files will be saved in the 'extracted_folder_path'.\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extracted_folder_path)\n",
        "\n",
        "# Step 5: List the extracted files to ensure that the ZIP file has been successfully unzipped\n",
        "extracted_files = os.listdir(extracted_folder_path)\n",
        "print(\"Extracted files:\", extracted_files)\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Step 6: Load the extracted CSV file into a DataFrame\n",
        "# This path is where the CSV file was extracted to in the previous step\n",
        "csv_file_path = '/content/netflix_data/netflix_titles.csv'\n",
        "\n",
        "# Use 'pandas' to load the CSV file and view the first few rows to confirm that the data was loaded correctly\n",
        "data = pd.read_csv(csv_file_path)\n",
        "print(\"First few rows of the dataset:\")\n",
        "print(data.head())\n",
        "\n",
        "# Importing the necessary libraries and modules\n",
        "\n",
        "# pandas is used for data manipulation and analysis. It helps load and work with datasets.\n",
        "import pandas as pd\n",
        "\n",
        "# train_test_split is used to split the dataset into training and testing parts\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# LogisticRegression is the machine learning model that predicts whether a user will click or not\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# These modules help evaluate the performance of the model using metrics like accuracy, confusion matrix, and classification report\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# LabelEncoder helps convert text-based (categorical) features into numerical values, since machine learning models work with numbers\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# SMOTE (Synthetic Minority Over-sampling Technique) is used to balance the dataset, especially when one class (e.g., \"clicks\") is over-represented\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Step 1: Create a 'clicked' target based on release year\n",
        "# Explanation: We create a new column in the dataset called 'clicked'.\n",
        "# This column has a value of 1 if the content was released after 2015 (indicating a click), and 0 otherwise (no click).\n",
        "data['clicked'] = data['release_year'].apply(lambda x: 1 if x > 2015 else 0)\n",
        "\n",
        "# Step 2: Select features (factors) that the model will use to predict clicks\n",
        "# Explanation: We need to give the model more information to make better predictions.\n",
        "# In addition to 'type' and 'release_year', we also include 'duration', 'country', 'listed_in', and 'rating'.\n",
        "# These are characteristics of the content that might affect whether someone clicks on it.\n",
        "X = data[['type', 'release_year', 'duration', 'country', 'listed_in', 'rating']]  # Features (factors) for prediction\n",
        "y = data['clicked']  # The target (whether a user clicked or not)\n",
        "\n",
        "# Step 3: Convert categorical data (text) into numerical data using LabelEncoder\n",
        "# Explanation: Machine learning models need numbers to work, so we need to convert text features like 'type', 'country', 'listed_in', and 'rating' into numbers.\n",
        "# LabelEncoder converts text values like 'Movie' and 'TV Show' into numerical codes.\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Convert 'type' column (Movie = 1, TV Show = 0)\n",
        "X['type'] = label_encoder.fit_transform(X['type'])  # 'Movie' becomes 1, 'TV Show' becomes 0\n",
        "\n",
        "# Convert 'country' column into numerical values (e.g., 'United States' might become 1, 'India' might become 2, etc.)\n",
        "X['country'] = label_encoder.fit_transform(X['country'].astype(str))  # Make sure no missing values exist\n",
        "\n",
        "# Convert 'listed_in' column (categories of content) into numerical values\n",
        "X['listed_in'] = label_encoder.fit_transform(X['listed_in'].astype(str))\n",
        "\n",
        "# Convert 'rating' column (e.g., PG, PG-13, TV-MA) into numerical values\n",
        "X['rating'] = label_encoder.fit_transform(X['rating'].astype(str))\n",
        "\n",
        "# Convert 'duration' column (length of content) into numerical values\n",
        "X['duration'] = label_encoder.fit_transform(X['duration'].astype(str))\n",
        "\n",
        "# Step 4: Balance the dataset using SMOTE (Synthetic Minority Over-sampling Technique)\n",
        "# Explanation: If the dataset has more clicks than no clicks, the model may become biased and predict \"click\" more often.\n",
        "# SMOTE generates synthetic data to balance the dataset, creating more \"no click\" examples so that both classes are fairly represented.\n",
        "smote = SMOTE(sampling_strategy=0.7, random_state=42)  # SMOTE will generate synthetic examples to ensure balance\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)  # Apply SMOTE to create balanced data\n",
        "\n",
        "# Step 5: Split the data into training and testing sets\n",
        "# Explanation: We split the dataset into two parts: training and testing.\n",
        "# - The training set (80%) is used to teach the model how to predict clicks.\n",
        "# - The testing set (20%) is used to check how well the model performs on unseen data.\n",
        "# 'random_state=42' ensures that the split is the same every time we run the code.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 6: Train a Logistic Regression model\n",
        "# Explanation: We use logistic regression to predict a binary outcome (click or no click).\n",
        "# 'class_weight=\"balanced\"' ensures the model gives equal importance to predicting both clicks and no clicks.\n",
        "# 'C=1.0' controls how much regularization the model applies to avoid overfitting (fitting too closely to the training data).\n",
        "model = LogisticRegression(class_weight='balanced', C=1.0)  # Train the model with balanced weights and a regularization factor\n",
        "model.fit(X_train, y_train)  # Fit the model (train it) using the training data\n",
        "\n",
        "# Step 7: Make predictions on the test data\n",
        "# Explanation: Now that the model is trained, we ask it to predict whether content in the test set will be clicked or not.\n",
        "# The model will output predictions (1 = clicked, 0 = not clicked).\n",
        "y_pred = model.predict(X_test)  # Use the trained model to predict clicks on the test data\n",
        "\n",
        "# Step 8: Evaluate the model using various metrics\n",
        "# Explanation: After making predictions, we evaluate how well the model performed.\n",
        "# We use three metrics:\n",
        "# 1) Accuracy: The percentage of correct predictions.\n",
        "# 2) Confusion Matrix: Shows how many correct and incorrect predictions the model made for both \"click\" and \"no click\".\n",
        "# 3) Classification Report: Provides more detailed metrics like precision (how often the model's \"click\" predictions were correct) and recall (how many actual clicks the model caught).\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))  # Print the accuracy of the model\n",
        "print(\"Confusion Matrix:\")  # The confusion matrix helps us see where the model is making errors\n",
        "print(confusion_matrix(y_test, y_pred))  # Shows how many correct/incorrect predictions for each class\n",
        "print(\"Classification Report:\")  # Provides detailed information on precision, recall, and F1-score\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhicpiQ_ySF4",
        "outputId": "2bafd1a8-5d04-4db4-c10c-c9288eeb7600"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Extracted files: ['adsclicking.csv', 'netflix_titles.csv']\n",
            "First few rows of the dataset:\n",
            "  show_id     type                  title         director  \\\n",
            "0      s1    Movie   Dick Johnson Is Dead  Kirsten Johnson   \n",
            "1      s2  TV Show          Blood & Water              NaN   \n",
            "2      s3  TV Show              Ganglands  Julien Leclercq   \n",
            "3      s4  TV Show  Jailbirds New Orleans              NaN   \n",
            "4      s5  TV Show           Kota Factory              NaN   \n",
            "\n",
            "                                                cast        country  \\\n",
            "0                                                NaN  United States   \n",
            "1  Ama Qamata, Khosi Ngema, Gail Mabalane, Thaban...   South Africa   \n",
            "2  Sami Bouajila, Tracy Gotoas, Samuel Jouy, Nabi...            NaN   \n",
            "3                                                NaN            NaN   \n",
            "4  Mayur More, Jitendra Kumar, Ranjan Raj, Alam K...          India   \n",
            "\n",
            "           date_added  release_year rating   duration  \\\n",
            "0  September 25, 2021          2020  PG-13     90 min   \n",
            "1  September 24, 2021          2021  TV-MA  2 Seasons   \n",
            "2  September 24, 2021          2021  TV-MA   1 Season   \n",
            "3  September 24, 2021          2021  TV-MA   1 Season   \n",
            "4  September 24, 2021          2021  TV-MA  2 Seasons   \n",
            "\n",
            "                                           listed_in  \\\n",
            "0                                      Documentaries   \n",
            "1    International TV Shows, TV Dramas, TV Mysteries   \n",
            "2  Crime TV Shows, International TV Shows, TV Act...   \n",
            "3                             Docuseries, Reality TV   \n",
            "4  International TV Shows, Romantic TV Shows, TV ...   \n",
            "\n",
            "                                         description  \n",
            "0  As her father nears the end of his life, filmm...  \n",
            "1  After crossing paths at a party, a Cape Town t...  \n",
            "2  To protect his family from a powerful drug lor...  \n",
            "3  Feuds, flirtations and toilet talk go down amo...  \n",
            "4  In a city of coaching centers known to train I...  \n",
            "Accuracy: 0.6432657306292252\n",
            "Confusion Matrix:\n",
            "[[487 307]\n",
            " [379 750]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.61      0.59       794\n",
            "           1       0.71      0.66      0.69      1129\n",
            "\n",
            "    accuracy                           0.64      1923\n",
            "   macro avg       0.64      0.64      0.64      1923\n",
            "weighted avg       0.65      0.64      0.65      1923\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-29702cd36e04>:79: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X['type'] = label_encoder.fit_transform(X['type'])  # 'Movie' becomes 1, 'TV Show' becomes 0\n",
            "<ipython-input-11-29702cd36e04>:82: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X['country'] = label_encoder.fit_transform(X['country'].astype(str))  # Make sure no missing values exist\n",
            "<ipython-input-11-29702cd36e04>:85: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X['listed_in'] = label_encoder.fit_transform(X['listed_in'].astype(str))\n",
            "<ipython-input-11-29702cd36e04>:88: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X['rating'] = label_encoder.fit_transform(X['rating'].astype(str))\n",
            "<ipython-input-11-29702cd36e04>:91: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X['duration'] = label_encoder.fit_transform(X['duration'].astype(str))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explaining the Output in Detail:\n",
        "\n",
        "**1. Model Accuracy: 0.6432657306292252 (64%)%**\n",
        "\n",
        "* **What It Means:** The model correctly predicted whether content would be clicked or not 64% of the time. This means that the model’s overall accuracy is 64%. While this is above random guessing (which would be 50% in a binary classification problem like this), it suggests that there is still room for improvement.\n",
        "\n",
        "* **Interpretation:**The model is doing moderately well but isn't perfect. A 64% accuracy shows that the model is making both correct and incorrect predictions, and we need to further investigate its performance.\n",
        "\n",
        "**2. Confusion Matrix:**\n",
        "\n",
        "[[487 307]\n",
        "\n",
        " [379 750]]\n",
        "\n",
        "\n",
        "**What It Is:** A confusion matrix provides insight into how well the model performs on each class (in this case, predicting whether content will be clicked or not clicked).\n",
        "\n",
        "* 487 (True Negatives): The model correctly predicted \"no clicks\" 487 times.\n",
        "* 307 (False Positives): The model predicted \"clicks\" when it should have predicted \"no clicks\" 307 times.\n",
        "* 379 (False Negatives): The model predicted \"no clicks\" when it should have predicted \"clicks\" 379 times.\n",
        "* 750 (True Positives): The model correctly predicted \"clicks\" 750 times.\n",
        "\n",
        "\n",
        "**Interpretation:**\n",
        "\n",
        "* The model is reasonably good at identifying \"clicks\" (750 correct predictions) but still misses quite a few (379 times it predicted no clicks when clicks actually happened).\n",
        "\n",
        "*  t is also reasonably good at predicting \"no clicks\" (487 correct predictions) but sometimes incorrectly predicts a click (307 times).\n",
        "\n",
        "**3. Classification Report:**\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n"
      ],
      "metadata": {
        "id": "VUYPgJFgy6VB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Precision:** This tells you how many of the positive predictions (clicks) were actually correct.\n",
        "\n",
        "* **0 (No Clicks): 0.56** - Out of all the times the model predicted \"no clicks\", it was correct 56% of the time.\n",
        "\n",
        "* **1 (Clicks): 0.71** - Out of all the times the model predicted \"clicks\", it was correct 71% of the time.\n",
        "\n",
        "\n",
        "**Recall:** This tells you how many of the actual instances of each class were correctly identified.\n",
        "\n",
        "* **0 (No Clicks): 0.61** - The model identified 61% of actual \"no clicks\".\n",
        "\n",
        "* **1 (Clicks): 0.66** - The model identified 66% of actual \"clicks\".\n",
        "\n",
        "\n",
        "**F1-Score:** This is the harmonic mean of precision and recall, balancing both metrics.\n",
        "\n",
        "*  0 (No Clicks): 0.59 - F1-Score balances precision and recall, giving an overall measure of how well the model performs for \"no clicks\".\n",
        "\n",
        "*  1 (Clicks): 0.69 - F1-Score for \"clicks\" is higher, meaning the model is performing better at predicting clicks than no clicks.\n",
        "\n",
        "**Support:**\n",
        "\n",
        "*  The support indicates the number of actual examples in each class (794 for \"no clicks\" and 1129 for \"clicks\").\n",
        "\n",
        "**Interpretation:**\n",
        "\n",
        "*  The model has a higher precision and recall for predicting \"clicks\" (class 1) than for predicting \"no clicks\" (class 0). This means the model is better at identifying content that users will click on but still misses many clicks (as shown by the 66% recall for clicks).\n",
        "\n",
        "*  The performance for \"no clicks\" is lower, with the model missing a significant portion of cases where users don't click (precision of 56% and recall of 61%).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*  **Macro Avg:** This is the average of precision, recall, and F1-score across both classes, treating them equally. The low values (0.32 for precision) show that the model is not balanced.\n",
        "\n",
        "*  **Weighted Avg:** This takes into account the number of instances in each class and gives a weighted average. This metric tells you that overall, the model is heavily biased towards predicting clicks.\n",
        "\n"
      ],
      "metadata": {
        "id": "0zeSFvg4z7O8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Accuracy (accuracy = 0.64):**\n",
        "\n",
        "*  **Definition:** Accuracy is the percentage of correct predictions out of all predictions made.\n",
        "\n",
        "*  **Explanation:** The model's accuracy is 64%, which means that out of 1,923 total predictions, approximately 64% were correct. This tells us how often the model gets the overall prediction right (whether it's predicting \"click\" or \"no click\").\n",
        "\n",
        "*  **Use:** Accuracy is a simple metric to evaluate the overall performance, but it can be misleading if the dataset is imbalanced. For example, if 90% of the content were \"no clicks\", a model that predicts \"no click\" 100% of the time would still have high accuracy, even though it fails to predict \"clicks.\"\n",
        "\n",
        "**2. Macro Average (macro avg):**\n",
        "\n",
        "Definition: Macro average calculates the metric (precision, recall, and F1-score) for each class (in this case, \"click\" and \"no click\") separately and then takes the average.\n",
        "\n",
        "**Explanation:**\n",
        "* **Precision (0.64):** On average, the model correctly predicts 64% of the times when it says something will happen (whether predicting clicks or no clicks)\n",
        "\n",
        "*  **Recall (0.64):** On average, the model correctly identifies 64% of the actual occurrences for both clicks and no clicks.\n",
        "\n",
        "*  **F1-score (0.64):** The F1-score is the harmonic mean of precision and recall, balancing the trade-off between these two metrics.\n",
        "\n",
        "**Use:** Macro average gives equal importance to both classes (\"click\" and \"no click\") by calculating metrics individually for each class and averaging them. This is useful if you care equally about predicting both outcomes, but it can underestimate performance on imbalanced datasets.\n",
        "\n",
        "**3. Weighted Average (weighted avg):**\n",
        "\n",
        "**Definition:** Weighted average takes the class imbalance into account by weighing the metrics based on the number of instances in each class.\n",
        "\n",
        "**Explanation:**\n",
        "\n",
        "* **Precision (0.65):** The model correctly predicts 65% of the times it says something will happen, giving more weight to the class that appears more frequently (e.g., more \"no clicks\").\n",
        "\n",
        "*  **Recall (0.64):** The model correctly identifies 64% of actual occurrences, with the calculation weighted by the number of examples for each class.\n",
        "\n",
        "*  **F1-score (0.65):** This weighted F1-score is a balanced measure, considering both precision and recall, while accounting for the number of examples in each class.\n",
        "\n",
        "**Use:** Weighted average is useful when your dataset is imbalanced because it accounts for the fact that one class might have more examples than the other. This gives you a more realistic picture of how the model performs overall.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YMmGB3QHzwvG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code 2: Ad Click Prediction (Predicting Ad Engagement)\n",
        "\n",
        "**Purpose:**\n",
        "* This code is aimed at predicting whether a user will click on an advertisement based on various user and behavior features. It uses logistic regression to predict ad engagement from an Ad Click dataset."
      ],
      "metadata": {
        "id": "GEfid0-nORtO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Mount Google Drive (if it's not already mounted)\n",
        "# This step allows Colab to access files stored in your Google Drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Step 2: Import necessary libraries for working with files, data analysis, and machine learning\n",
        "import zipfile\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder  # To encode categorical variables\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Step 3: Define the path to your ZIP file in Google Drive\n",
        "# Update this path with the actual path where your ZIP file is located in Google Drive\n",
        "zip_file_path = '/content/drive/MyDrive/Ad Click Prediction/archive (2).zip'\n",
        "\n",
        "# Step 4: Extract the ZIP file\n",
        "# We will extract the contents of the ZIP file to a local folder within Colab.\n",
        "extracted_folder_path = '/content/ad_click_data/'  # Folder where the extracted files will be stored\n",
        "\n",
        "# Unzipping the file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extracted_folder_path)\n",
        "\n",
        "# Step 5: List the extracted files to confirm successful extraction\n",
        "# This will help us see what files were inside the ZIP file\n",
        "extracted_files = os.listdir(extracted_folder_path)\n",
        "print(\"Extracted files:\", extracted_files)\n",
        "\n",
        "# Step 6: Load the dataset into a pandas DataFrame\n",
        "# We now know the file is named 'adsclicking.csv' based on the extraction, so we'll use that.\n",
        "csv_file_path = os.path.join(extracted_folder_path, 'adsclicking.csv')  # Correct file name\n",
        "data = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Step 7: Explore the dataset\n",
        "# Let's look at the first few rows to understand the structure of the dataset\n",
        "print(\"First few rows of the dataset:\")\n",
        "print(data.head())\n",
        "\n",
        "# Step 8: Preprocess the data\n",
        "# This step includes handling missing values, encoding categorical variables, and selecting the relevant features.\n",
        "\n",
        "# Step 8a: Check for missing values (already checked, no missing values)\n",
        "print(\"Missing values in the dataset:\")\n",
        "print(data.isnull().sum())\n",
        "\n",
        "# Step 8b: Encode categorical variables\n",
        "# We need to convert categorical variables like 'Gender', 'Location', 'Device', and 'Interest_Category' into numerical form.\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Encoding categorical columns\n",
        "data['Gender'] = label_encoder.fit_transform(data['Gender'])\n",
        "data['Location'] = label_encoder.fit_transform(data['Location'])\n",
        "data['Device'] = label_encoder.fit_transform(data['Device'])\n",
        "data['Interest_Category'] = label_encoder.fit_transform(data['Interest_Category'])\n",
        "\n",
        "# Step 8c: Select features and target variable\n",
        "# The features (X) include columns like 'Age', 'Gender', 'Income', 'Location', 'Device', etc.\n",
        "# The target variable (y) is 'Click', which indicates whether the user clicked on the ad (1 = yes, 0 = no).\n",
        "\n",
        "# Select features for the model\n",
        "X = data[['Age', 'Gender', 'Income', 'Location', 'Device', 'Interest_Category', 'Time_Spent_on_Site', 'Number_of_Pages_Viewed']]\n",
        "\n",
        "# Target variable\n",
        "y = data['Click']\n",
        "\n",
        "# Step 9: Split the data into training and testing sets\n",
        "# We will split the data into 80% training and 20% testing to evaluate model performance.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 10: Train a Logistic Regression model\n",
        "# Initialize the logistic regression model\n",
        "model = LogisticRegression()\n",
        "\n",
        "# Train the model on the training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 11: Make predictions on the test set\n",
        "# Now that the model is trained, we'll use it to predict on the test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Step 12: Evaluate the model\n",
        "# We will evaluate the performance using accuracy, confusion matrix, and classification report\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred) * 100:.2f}%\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Step 13: Analyze the results\n",
        "# Based on the accuracy and other metrics, you can see how well the logistic regression model predicts\n",
        "# user clicks based on the features selected.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jzZ2YmK42tB",
        "outputId": "050e7393-fa71-4b70-84d3-c9b52b3f134f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Extracted files: ['adsclicking.csv']\n",
            "First few rows of the dataset:\n",
            "   Unnamed: 0  Age  Gender  Income  Location  Device Interest_Category  \\\n",
            "0           0   56    Male   99003     Rural  Mobile            Sports   \n",
            "1           1   46    Male   72395  Suburban  Tablet            Sports   \n",
            "2           2   32    Male   59758  Suburban  Tablet            Sports   \n",
            "3           3   60    Male   74312     Urban  Tablet        Technology   \n",
            "4           4   25  Female   88670  Suburban  Mobile           Fashion   \n",
            "\n",
            "   Time_Spent_on_Site  Number_of_Pages_Viewed  Click  \n",
            "0           81.979324                       7      0  \n",
            "1           59.854070                       3      1  \n",
            "2           78.861989                       2      0  \n",
            "3            9.411579                       6      0  \n",
            "4           76.468409                       9      0  \n",
            "Missing values in the dataset:\n",
            "Unnamed: 0                0\n",
            "Age                       0\n",
            "Gender                    0\n",
            "Income                    0\n",
            "Location                  0\n",
            "Device                    0\n",
            "Interest_Category         0\n",
            "Time_Spent_on_Site        0\n",
            "Number_of_Pages_Viewed    0\n",
            "Click                     0\n",
            "dtype: int64\n",
            "Accuracy: 51.50%\n",
            "Confusion Matrix:\n",
            "[[130  68]\n",
            " [126  76]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.66      0.57       198\n",
            "           1       0.53      0.38      0.44       202\n",
            "\n",
            "    accuracy                           0.52       400\n",
            "   macro avg       0.52      0.52      0.51       400\n",
            "weighted avg       0.52      0.52      0.51       400\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code 3: L&T Vehicle Loan Default Prediction (Predicting Loan Default)\n",
        "\n",
        "**Purpose:**\n",
        "*  This code aims to predict whether a customer will default on a vehicle loan based on their financial data. Logistic regression is used to forecast the probability of loan default based on the L&T Vehicle Loan dataset."
      ],
      "metadata": {
        "id": "EKPyO5RMOXvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Mount Google Drive (if it's not already mounted)\n",
        "# This step allows Colab to access files stored in your Google Drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Step 2: Import necessary libraries for working with files, data analysis, and machine learning\n",
        "import zipfile\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder  # To encode categorical variables\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Step 3: Define the path to your ZIP file in Google Drive\n",
        "# Update this path with the actual path where your ZIP file is located in Google Drive\n",
        "zip_file_path = '/content/drive/MyDrive/L&T Vehicle Loan Default Prediction/archive (3).zip'\n",
        "\n",
        "# Step 4: Extract the ZIP file\n",
        "# We will extract the contents of the ZIP file to a local folder within Colab.\n",
        "extracted_folder_path = '/content/vehicle_loan_data/'  # Folder where the extracted files will be stored\n",
        "\n",
        "# Unzipping the file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extracted_folder_path)\n",
        "\n",
        "# Step 5: List the extracted files to confirm successful extraction\n",
        "# This will help us see what files were inside the ZIP file\n",
        "extracted_files = os.listdir(extracted_folder_path)\n",
        "print(\"Extracted files:\", extracted_files)\n",
        "\n",
        "# Step 6: Load the 'train.csv' dataset into a pandas DataFrame\n",
        "# We now use 'train.csv' for the training data as it contains the dataset you need.\n",
        "csv_file_path = os.path.join(extracted_folder_path, 'train.csv')  # Correct file name for training data\n",
        "data = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Step 7: Explore the dataset\n",
        "# Let's look at the first few rows to understand the structure of the dataset\n",
        "print(\"First few rows of the dataset:\")\n",
        "print(data.head())\n",
        "\n",
        "# Step 8: Preprocess the data\n",
        "# This step includes handling missing values, encoding categorical variables, and selecting the relevant features.\n",
        "\n",
        "# Step 8a: Check for missing values (already checked, handle as necessary)\n",
        "print(\"Missing values in the dataset:\")\n",
        "print(data.isnull().sum())\n",
        "\n",
        "# Step 8b: Handle missing values\n",
        "# For simplicity, we will fill missing values in 'Employment.Type' with the most frequent value.\n",
        "data['Employment.Type'].fillna(data['Employment.Type'].mode()[0], inplace=True)\n",
        "\n",
        "# Step 8c: Encode categorical variables\n",
        "# We need to convert categorical variables like 'Employment.Type' into numerical form.\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Encoding 'Employment.Type' column\n",
        "data['Employment.Type'] = label_encoder.fit_transform(data['Employment.Type'])\n",
        "\n",
        "# Step 8d: Select features and target variable\n",
        "# The features (X) include columns that will help us predict whether a customer will default on a loan.\n",
        "# The target variable (y) is 'loan_default', which indicates whether the loan defaulted (1 = yes, 0 = no).\n",
        "\n",
        "# Select features for the model\n",
        "X = data[['disbursed_amount', 'ltv', 'PERFORM_CNS.SCORE', 'NO.OF_INQUIRIES',\n",
        "          'NEW.ACCTS.IN.LAST.SIX.MONTHS']]  # Features for prediction\n",
        "\n",
        "# Target variable\n",
        "y = data['loan_default']  # Target column indicating loan default (1 = default, 0 = no default)\n",
        "\n",
        "# Step 9: Split the data into training and testing sets\n",
        "# We will split the data into 80% training and 20% testing to evaluate model performance.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 10: Train a Logistic Regression model\n",
        "# Initialize the logistic regression model\n",
        "model = LogisticRegression()\n",
        "\n",
        "# Train the model on the training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 11: Make predictions on the test set\n",
        "# Now that the model is trained, we'll use it to predict on the test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Step 12: Evaluate the model\n",
        "# We will evaluate the performance using accuracy, confusion matrix, and classification report\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred) * 100:.2f}%\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Step 13: Analyze the results\n",
        "# Based on the accuracy and other metrics, you can see how well the logistic regression model predicts\n",
        "# loan defaults based on the features selected.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Vv2NsbX8Oft",
        "outputId": "79d4e336-0505-4d0c-d25e-9e91e41c9a9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Extracted files: ['test.csv', 'data_dictionary.csv', 'train.csv']\n",
            "First few rows of the dataset:\n",
            "   UniqueID  disbursed_amount  asset_cost    ltv  branch_id  supplier_id  \\\n",
            "0    420825             50578       58400  89.55         67        22807   \n",
            "1    537409             47145       65550  73.23         67        22807   \n",
            "2    417566             53278       61360  89.63         67        22807   \n",
            "3    624493             57513       66113  88.48         67        22807   \n",
            "4    539055             52378       60300  88.39         67        22807   \n",
            "\n",
            "   manufacturer_id  Current_pincode_ID Date.of.Birth Employment.Type  ...  \\\n",
            "0               45                1441      01-01-84        Salaried  ...   \n",
            "1               45                1502      31-07-85   Self employed  ...   \n",
            "2               45                1497      24-08-85   Self employed  ...   \n",
            "3               45                1501      30-12-93   Self employed  ...   \n",
            "4               45                1495      09-12-77   Self employed  ...   \n",
            "\n",
            "  SEC.SANCTIONED.AMOUNT  SEC.DISBURSED.AMOUNT  PRIMARY.INSTAL.AMT  \\\n",
            "0                     0                     0                   0   \n",
            "1                     0                     0                1991   \n",
            "2                     0                     0                   0   \n",
            "3                     0                     0                  31   \n",
            "4                     0                     0                   0   \n",
            "\n",
            "   SEC.INSTAL.AMT  NEW.ACCTS.IN.LAST.SIX.MONTHS  \\\n",
            "0               0                             0   \n",
            "1               0                             0   \n",
            "2               0                             0   \n",
            "3               0                             0   \n",
            "4               0                             0   \n",
            "\n",
            "   DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS  AVERAGE.ACCT.AGE  \\\n",
            "0                                    0         0yrs 0mon   \n",
            "1                                    1        1yrs 11mon   \n",
            "2                                    0         0yrs 0mon   \n",
            "3                                    0         0yrs 8mon   \n",
            "4                                    0         0yrs 0mon   \n",
            "\n",
            "   CREDIT.HISTORY.LENGTH  NO.OF_INQUIRIES  loan_default  \n",
            "0              0yrs 0mon                0             0  \n",
            "1             1yrs 11mon                0             1  \n",
            "2              0yrs 0mon                0             0  \n",
            "3              1yrs 3mon                1             1  \n",
            "4              0yrs 0mon                1             1  \n",
            "\n",
            "[5 rows x 41 columns]\n",
            "Missing values in the dataset:\n",
            "UniqueID                                  0\n",
            "disbursed_amount                          0\n",
            "asset_cost                                0\n",
            "ltv                                       0\n",
            "branch_id                                 0\n",
            "supplier_id                               0\n",
            "manufacturer_id                           0\n",
            "Current_pincode_ID                        0\n",
            "Date.of.Birth                             0\n",
            "Employment.Type                        7661\n",
            "DisbursalDate                             0\n",
            "State_ID                                  0\n",
            "Employee_code_ID                          0\n",
            "MobileNo_Avl_Flag                         0\n",
            "Aadhar_flag                               0\n",
            "PAN_flag                                  0\n",
            "VoterID_flag                              0\n",
            "Driving_flag                              0\n",
            "Passport_flag                             0\n",
            "PERFORM_CNS.SCORE                         0\n",
            "PERFORM_CNS.SCORE.DESCRIPTION             0\n",
            "PRI.NO.OF.ACCTS                           0\n",
            "PRI.ACTIVE.ACCTS                          0\n",
            "PRI.OVERDUE.ACCTS                         0\n",
            "PRI.CURRENT.BALANCE                       0\n",
            "PRI.SANCTIONED.AMOUNT                     0\n",
            "PRI.DISBURSED.AMOUNT                      0\n",
            "SEC.NO.OF.ACCTS                           0\n",
            "SEC.ACTIVE.ACCTS                          0\n",
            "SEC.OVERDUE.ACCTS                         0\n",
            "SEC.CURRENT.BALANCE                       0\n",
            "SEC.SANCTIONED.AMOUNT                     0\n",
            "SEC.DISBURSED.AMOUNT                      0\n",
            "PRIMARY.INSTAL.AMT                        0\n",
            "SEC.INSTAL.AMT                            0\n",
            "NEW.ACCTS.IN.LAST.SIX.MONTHS              0\n",
            "DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS       0\n",
            "AVERAGE.ACCT.AGE                          0\n",
            "CREDIT.HISTORY.LENGTH                     0\n",
            "NO.OF_INQUIRIES                           0\n",
            "loan_default                              0\n",
            "dtype: int64\n",
            "Accuracy: 78.22%\n",
            "Confusion Matrix:\n",
            "[[36477     0]\n",
            " [10154     0]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      1.00      0.88     36477\n",
            "           1       0.00      0.00      0.00     10154\n",
            "\n",
            "    accuracy                           0.78     46631\n",
            "   macro avg       0.39      0.50      0.44     46631\n",
            "weighted avg       0.61      0.78      0.69     46631\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Code 4: Heart Disease Risk Prediction (Predicting Risk of Heart Disease)\n",
        "\n",
        "**Purpose:**\n",
        "* This code is used to predict the risk of a patient developing heart disease based on various medical factors. It utilizes logistic regression to classify patients as either likely to have heart disease (1) or not (0) based on the dataset from heart disease studies."
      ],
      "metadata": {
        "id": "66yVBzVHOh7n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Mount Google Drive\n",
        "# This step allows Colab to access files stored in your Google Drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Step 2: Import necessary libraries for working with files, data analysis, and machine learning\n",
        "import zipfile\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder  # To encode categorical variables if needed\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Step 3: Define the path to your ZIP file in Google Drive\n",
        "# This is the path where your ZIP file is located in Google Drive\n",
        "zip_file_path = '/content/drive/MyDrive/Identification of Risk Factors for Heart Disease/archive (4).zip'\n",
        "\n",
        "# Step 4: Extract the ZIP file\n",
        "# Extract the contents of the ZIP file to a local folder within Colab\n",
        "extracted_folder_path = '/content/heart_disease_risk_data/'  # Folder where the extracted files will be stored\n",
        "\n",
        "# Unzipping the file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extracted_folder_path)\n",
        "\n",
        "# Step 5: List the extracted files to confirm successful extraction\n",
        "# This will help us see what files were inside the ZIP file\n",
        "extracted_files = os.listdir(extracted_folder_path)\n",
        "print(\"Extracted files:\", extracted_files)\n",
        "\n",
        "# Step 6: Load the dataset (assuming 'processed_cleveland_data.csv' is the correct file)\n",
        "csv_file_path = os.path.join(extracted_folder_path, 'processed_cleveland_data.csv')  # Load the actual dataset\n",
        "data = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Step 7: Explore the dataset\n",
        "# Let's look at the first few rows to understand the structure of the dataset\n",
        "print(\"First few rows of the dataset:\")\n",
        "print(data.head())\n",
        "\n",
        "# Step 8: Preprocess the data\n",
        "# This step includes handling missing values, encoding categorical variables, and selecting relevant features.\n",
        "\n",
        "# Step 8a: Check for missing values\n",
        "print(\"Missing values in the dataset:\")\n",
        "print(data.isnull().sum())\n",
        "\n",
        "# Step 8b: Select features and target variable\n",
        "# The features (X) include columns that help predict the risk of heart disease.\n",
        "# The target variable (y) is the column indicating heart disease diagnosis (1 = disease, 0 = no disease).\n",
        "\n",
        "# From the output of the dataset, the column names are likely strings like '63', '145', etc.\n",
        "# We need to reference them correctly using the actual column names as strings.\n",
        "\n",
        "# Features (replace column names with appropriate feature names based on your data)\n",
        "X = data[['63', '145', '233', '150']]  # Using some columns as features based on the dataset provided\n",
        "\n",
        "# Target variable (Replace with actual column name if needed)\n",
        "y = data['6']  # Assuming column '6' is the target variable indicating heart disease\n",
        "\n",
        "# Step 9: Split the data into training and testing sets\n",
        "# We will split the data into 80% training and 20% testing to evaluate model performance\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 10: Train a Logistic Regression model\n",
        "# Initialize the logistic regression model\n",
        "model = LogisticRegression()\n",
        "\n",
        "# Train the model on the training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 11: Make predictions on the test set\n",
        "# Now that the model is trained, we'll use it to predict on the test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Step 12: Evaluate the model\n",
        "# We will evaluate the performance using accuracy, confusion matrix, and classification report\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred) * 100:.2f}%\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Step 13: Analyze the results\n",
        "# Based on the accuracy and other metrics, you can see how well the logistic regression model predicts\n",
        "# heart disease based on the features selected.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_8tzLoTAD1-",
        "outputId": "0371329e-6870-4a6d-9079-1f02ec168624"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Extracted files: ['processed_cleveland_data.csv', 'cleveland_data.csv', 'bak.csv', 'new_data.csv', 'Index Of heart disease.txt', 'DatasetDescription.txt', 'processed_va_data.csv', 'processed_hungarian_data.csv', 'long-beach-va_data.csv', 'reprocessed_hungarian_data.csv', 'switzerland_data.csv', 'hungarian_data.csv', 'processed_switzerland_data.csv']\n",
            "First few rows of the dataset:\n",
            "   index  63  1  1.1  145  233  1.2  2  150  0  2.3  3 0.1  6  0.2\n",
            "0      0  67  1    4  160  286    0  2  108  1  1.5  2   3  3    2\n",
            "1      1  67  1    4  120  229    0  2  129  1  2.6  2   2  7    1\n",
            "2      2  37  1    3  130  250    0  0  187  0  3.5  3   0  3    0\n",
            "3      3  41  0    2  130  204    0  2  172  0  1.4  1   0  3    0\n",
            "4      4  56  1    2  120  236    0  0  178  0  0.8  1   0  3    0\n",
            "Missing values in the dataset:\n",
            "index    0\n",
            "63       0\n",
            "1        0\n",
            "1.1      0\n",
            "145      0\n",
            "233      0\n",
            "1.2      0\n",
            "2        0\n",
            "150      0\n",
            "0        0\n",
            "2.3      0\n",
            "3        0\n",
            "0.1      0\n",
            "6        0\n",
            "0.2      0\n",
            "dtype: int64\n",
            "Accuracy: 63.93%\n",
            "Confusion Matrix:\n",
            "[[29  0  5]\n",
            " [ 5  0  0]\n",
            " [11  1 10]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           3       0.64      0.85      0.73        34\n",
            "           6       0.00      0.00      0.00         5\n",
            "           7       0.67      0.45      0.54        22\n",
            "\n",
            "    accuracy                           0.64        61\n",
            "   macro avg       0.44      0.44      0.42        61\n",
            "weighted avg       0.60      0.64      0.60        61\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Are the Logistic Regression Codes the Same for Every Field?\n",
        "\n",
        "In general, logistic regression follows the same core structure regardless of the field. The core steps involve:\n",
        "\n",
        "* Data Preprocessing **(Handling missing values, encoding categorical variables, selecting features)**\n",
        "\n",
        "* Splitting the Data **(Training and testing sets)**\n",
        "\n",
        "* Model Training **(Training the logistic regression model)**\n",
        "\n",
        "* Making Predictions **(Using the model to make predictions on the test data)**\n",
        "\n",
        "* Evaluating the Model (Using **accuracy, confusion matrix, classification report**, etc.)\n",
        "\n",
        "These steps are the same across different domains, whether it's **marketing, finance, healthcare, or e-commerce.**\n",
        "\n",
        "However, there are minor differences in the code based on the nature of the data and the problem being solved. Let me explain:\n",
        "\n",
        "# Common Steps Across All Codes:\n",
        "\n",
        "**1. Mounting Google Drive:**\n",
        "* All codes start by mounting Google Drive to access the dataset stored there.\n",
        "\n",
        "**2. Loading the Dataset:**\n",
        "* The datasets are read using pandas and stored in a DataFrame. The only difference is the specific dataset being used, but the process of loading data is identical.\n",
        "\n",
        "**3. Data Preprocessing:**\n",
        "\n",
        "Preprocessing is similar across codes:\n",
        "\n",
        "* **Handling Missing Values:** Missing data is handled either by filling in values (like mode/median) or dropping missing rows.\n",
        "* **Encoding Categorical Variables:** Any categorical variables (like Gender, Device, Employment.Type, etc.) are encoded into numerical values using label encoding. This step is essential for logistic regression and is present in all codes.\n",
        "\n",
        "**4. Splitting the Data:**\n",
        "* All codes use train_test_split to divide the dataset into training (80%) and testing (20%) sets. This step is identical in format and purpose across all the codes.\n",
        "\n",
        "**5. Training the Logistic Regression Model:**\n",
        "* The logistic regression model is trained using LogisticRegression() in all codes. The training process is the same regardless of whether you are predicting ad clicks, loan defaults, or heart disease.\n",
        "\n",
        "**6. Making Predictions:**\n",
        "*  After the model is trained, it is used to make predictions on the test set in all codes using the .predict() method.\n",
        "\n",
        "**7. Evaluating the Model:**\n",
        "* The evaluation process is identical across all codes. Accuracy, confusion matrix, and classification report are used to assess how well the model is performing. This part of the code is exactly the same in every instance."
      ],
      "metadata": {
        "id": "kmawKJ_5Pgq_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Differences in the Codes:\n",
        "\n",
        "While the steps and structure of logistic regression are the same, the differences arise from the nature of the dataset and the specific problem being solved. These differences include:\n",
        "\n",
        "**1. Dataset and Features:**\n",
        "\n",
        "Each code uses a different dataset **(Netflix, Ad Click, Loan Default, Heart Disease)**, and therefore the features selected for prediction are different:\n",
        "\n",
        "* In the **Netflix code**, features like **type and release_year** **are used.**\n",
        "* In the **Ad Click code**, features like **Age, Gender, Device, and Time_Spent_on_Site are used.**\n",
        "* In the **Loan Default code**, financial features like **disbursed_amount, ltv, and PERFORM_CNS.SCORE are used.**\n",
        "\n",
        "* In the **Heart Disease code**, medical features like **age, cholesterol, and blood pressure are used.**\n",
        "\n",
        "**2. Target Variable:**\n",
        "The target variable (what you're predicting) is different for each field:\n",
        "\n",
        "* Netflix: **clicked** (whether content was clicked or not)\n",
        "* Ad Click: **Click** (whether the user clicked the ad or not)\n",
        "* Loan Default: **loan_default** (whether the loan was defaulted or not)\n",
        "* Heart Disease: **6** (whether the patient has heart disease or not)\n",
        "\n",
        "**3. Handling Categorical Variables:**\n",
        "\n",
        "Depending on the dataset, different categorical variables are encoded. For example:\n",
        "\n",
        "* In the Ad Click dataset, **Gender, Location, and Device** are encoded.\n",
        "*  In the Loan Default dataset, **Employment.Type** is encoded.\n",
        "* In the Netflix dataset, **type** (Movie or TV Show) is encoded. Each dataset has different columns that need encoding based on the problem domain.\n",
        "\n",
        "**4. Missing Values:**\n",
        "\n",
        "* Each dataset might have different missing values to handle. In the **Loan Default dataset**, we fill missing values in the **Employment.Type** column, while in other datasets, there might not be any missing values."
      ],
      "metadata": {
        "id": "YK4EJ69ER7Yn"
      }
    }
  ]
}