{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNIgzdL+IULeGeXfHa0s3S8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abhiss123/AlmaBetter-Projects/blob/main/AI_Driven_Query_Expansion_Powered_by_Word_Embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name : AI-Driven Query Expansion Powered by Word Embeddings**\n",
        "\n",
        "\n",
        "### **Purpose of the Project:**\n",
        "\n",
        "The purpose of this project is to enhance the search experience on websites or digital platforms by improving how search queries are understood and processed. This is achieved through **query expansion** powered by **AI and word embeddings**, which allows for a deeper understanding of user intent and better matching of search results. Let me explain this step by step, in simple terms, so that even a non-technical person can easily grasp it.\n",
        "\n",
        "---\n",
        "\n",
        "### **What Problem Does This Project Solve?**\n",
        "\n",
        "1. **Search Misunderstandings:**  \n",
        "   Sometimes, when people search for something online, they don’t use the exact words that are present in the website’s content. For example:\n",
        "   - A user searches for “affordable SEO packages.”\n",
        "   - The website might use the phrase “budget-friendly SEO plans.”\n",
        "   - The search fails to connect these two similar ideas because they don’t use the same exact words.\n",
        "\n",
        "2. **Limited Search Results:**  \n",
        "   Traditional search systems only match the exact words typed by the user. They don’t understand related terms, synonyms, or the broader meaning of the query. This means users might not find what they’re looking for, even if it’s available.\n",
        "\n",
        "3. **Content Gaps on Websites:**  \n",
        "   Websites might unknowingly miss creating content for commonly searched terms. For example:\n",
        "   - If many users search for “e-commerce SEO for small businesses,” but the website doesn’t have a page dedicated to this topic, the users leave unsatisfied.\n",
        "\n",
        "---\n",
        "\n",
        "### **What Does This Project Do?**\n",
        "\n",
        "This project addresses the problems above by introducing **AI-powered query expansion.** Here’s what it does:\n",
        "\n",
        "1. **Expands User Queries:**  \n",
        "   When a user types a search term, the system expands it by adding related terms, synonyms, or phrases that mean the same thing. For example:\n",
        "   - User Query: “AI SEO tools”\n",
        "   - Expanded Query: “artificial intelligence for SEO,” “machine learning SEO tools,” “automated SEO solutions”\n",
        "\n",
        "2. **Matches Content with User Intent:**  \n",
        "   The expanded query is then matched against the website’s content. Even if the user’s exact words don’t exist, the system finds related content based on meaning. This ensures users get relevant results.\n",
        "\n",
        "3. **Ranks Relevant Pages:**  \n",
        "   The system ranks pages based on how well they match the expanded query, showing the most relevant pages at the top.\n",
        "\n",
        "4. **Provides Analytics Insights:**  \n",
        "   The project also tracks search trends, showing website owners:\n",
        "   - What users are searching for.\n",
        "   - Which terms are frequently expanded.\n",
        "   - Where the website might lack content.\n",
        "\n",
        "---\n",
        "\n",
        "### **How Does This Help Website Owners?**\n",
        "\n",
        "1. **Better Search Experience for Users:**  \n",
        "   Users find what they’re looking for faster and more accurately, even if their query isn’t perfect.\n",
        "\n",
        "2. **Increased Traffic and Engagement:**  \n",
        "   When users find relevant content, they’re more likely to stay on the website, explore more pages, and even make purchases.\n",
        "\n",
        "3. **Content Strategy Improvement:**  \n",
        "   Website owners get insights into popular search terms and content gaps. For example:\n",
        "   - If users frequently search for “SEO for small businesses,” and the website lacks content on this topic, the owner can create a dedicated page to attract more visitors.\n",
        "\n",
        "4. **Higher Search Engine Rankings:**  \n",
        "   By targeting a broader range of keywords and phrases, the website becomes more visible on search engines like Google, attracting organic traffic.\n",
        "\n",
        "5. **Competitive Advantage:**  \n",
        "   This project helps the website stay ahead of competitors by understanding user intent better and delivering a superior search experience.\n",
        "\n",
        "---\n",
        "\n",
        "### **Who Can Benefit from This Project?**\n",
        "\n",
        "- **E-Commerce Websites:** To help users find products quickly.\n",
        "- **Blogs or Educational Sites:** To match queries with relevant articles.\n",
        "- **Service-Based Businesses:** To ensure users land on the right service pages (e.g., “local SEO services” matching with “SEO for small businesses”).\n",
        "- **Large Portals or Marketplaces:** To organize and retrieve vast amounts of content efficiently.\n",
        "\n",
        "---\n",
        "\n",
        "### **How Does the Project Work?**\n",
        "\n",
        "1. **Scraping and Preprocessing Content:**  \n",
        "   The project starts by collecting and cleaning all the website’s content (titles, meta descriptions, body text).\n",
        "\n",
        "2. **Training Word Embeddings:**  \n",
        "   It trains a machine learning model to understand relationships between words. For example:\n",
        "   - It learns that “affordable” and “budget-friendly” are similar.\n",
        "   - It knows “AI” is related to “artificial intelligence.”\n",
        "\n",
        "3. **Query Expansion and Matching:**  \n",
        "   When a user searches for something, the system:\n",
        "   - Expands the query using the word embeddings.\n",
        "   - Matches it with the website’s content.\n",
        "   - Ranks the most relevant results.\n",
        "\n",
        "4. **Advanced Insights and Analytics:**  \n",
        "   The project tracks trends, user behavior, and content gaps to give website owners actionable insights.\n",
        "\n",
        "---\n",
        "\n",
        "### **Real-World Example:**\n",
        "\n",
        "Let’s say this system is used on **www.thatware.co**, which provides SEO services.  \n",
        "- A user searches for: “SEO pricing.”  \n",
        "- The system expands the query to include terms like:\n",
        "  - “SEO packages,” “affordable SEO plans,” “cost of SEO services.”  \n",
        "- The system matches these expanded terms to relevant pages, such as:\n",
        "  - **www.thatware.co/seo-pricing**  \n",
        "  - **www.thatware.co/seo-packages**  \n",
        "- It ranks the results so the most relevant page appears at the top.\n",
        "- The website owner can also see in the analytics that many users search for “local SEO pricing.” If no such page exists, they can create one to fill the gap.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "HXvZs5r7qEu1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# **What are Word Embeddings for Query Expansion?**\n",
        "\n",
        "**Word embeddings** are mathematical representations of words in a continuous vector space, where words with similar meanings have similar vector representations. For **query expansion**, word embeddings are used to analyze the context and meaning of a search term to intelligently add related or synonymous terms to the query. This improves search accuracy by increasing the likelihood of matching the user's intent with relevant content on your website.\n",
        "\n",
        "---\n",
        "\n",
        "### Use Cases of Word Embeddings for Query Expansion\n",
        "\n",
        "1. **Search Engine Optimization (SEO):** Improves the relevance of search results on websites by predicting user intent and broadening the search scope.\n",
        "2. **E-Commerce:** Enhances product search by expanding customer queries to include synonyms, related terms, or alternative phrasings.\n",
        "3. **Customer Support Systems:** Improves search within FAQ databases by including synonyms or rephrased terms.\n",
        "4. **Digital Libraries and Content Management Systems:** Helps users find the right documents by expanding their queries to include related terms.\n",
        "5. **Websites:** Improves user experience by returning more relevant pages even when users search with incomplete or ambiguous terms.\n",
        "\n",
        "---\n",
        "\n",
        "### Real-Life Implementation Examples\n",
        "\n",
        "1. **Google Search:** Uses advanced query expansion to predict what users are searching for, even when they use partial or ambiguous keywords.\n",
        "2. **Amazon:** Expands queries for products so that a search for \"laptop bag\" also includes results for \"computer backpack\" or \"notebook case.\"\n",
        "3. **Educational Websites:** Helps users find study material by recognizing synonyms (e.g., “AI” for “artificial intelligence”).\n",
        "\n",
        "---\n",
        "\n",
        "### Use Case for Websites\n",
        "\n",
        "For a website, query expansion can ensure that users find the most relevant content even if their search terms don’t exactly match the keywords used in the website's content. For example:\n",
        "- A user searches for \"affordable smartphones.\" The query expansion model might automatically include \"cheap phones,\" \"budget mobiles,\" or \"low-cost devices.\"\n",
        "- On your website, these expanded terms help direct the user to appropriate content or products, improving engagement and reducing bounce rates.\n",
        "\n",
        "\n",
        "### What Kind of Data Does It Need?\n",
        "\n",
        "The model requires **text data** for training or operation. Examples include:\n",
        "- **Website Content:** Page titles, meta descriptions, and body text.\n",
        "- **Search Logs:** Historical search queries and user behavior data.\n",
        "- **Domain-Specific Glossary:** Industry-related terms to improve the embedding's accuracy.\n",
        "\n",
        "---\n",
        "\n",
        "### How Does It Work?\n",
        "\n",
        "1. **Preprocessing:** The text content is cleaned and tokenized (split into words or phrases).\n",
        "2. **Embedding Creation:** The words are converted into vector representations using pre-trained models (like Word2Vec, GloVe, or FastText) or fine-tuned embeddings for your domain.\n",
        "3. **Query Matching:** When a user enters a query, the model:\n",
        "   - Analyzes the query's word embeddings.\n",
        "   - Expands the query by adding semantically similar terms.\n",
        "   - Matches the expanded query against the website content.\n",
        "4. **Ranking and Output:** The system ranks the matched results by relevance and presents them to the user.\n",
        "\n",
        "---\n",
        "\n",
        "### What Output Does the Model Provide?\n",
        "\n",
        "1. **Expanded Query Terms:**\n",
        "   - For the input query \"affordable smartphones,\" the model might output related terms like:\n",
        "     ```\n",
        "     [\"cheap phones\", \"budget mobiles\", \"low-cost smartphones\"]\n",
        "     ```\n",
        "2. **Ranked Search Results:**\n",
        "   - The model generates a list of URLs or content snippets ranked by relevance to the expanded query.\n",
        "\n",
        "3. **Visualization (Optional):**\n",
        "   - Highlighting how the expanded terms improved search accuracy.\n",
        "\n",
        "---\n",
        "\n",
        "### Expected Output in Website Context\n",
        "\n",
        "For a website, the query expansion model outputs:\n",
        "- **Relevant Content URLs:** Links to pages that match the expanded query terms.\n",
        "- **Improved Search Suggestions:** Terms or phrases that better match user intent.\n",
        "- **Analytics Insights:** Reports on frequently expanded terms and search trends.\n",
        "\n",
        "---\n",
        "\n",
        "### Simplified Workflow for Non-Tech Background\n",
        "\n",
        "1. Gather Data:\n",
        "   - Use URLs or export content into CSV format.\n",
        "2. Preprocess Text:\n",
        "   - Clean the text data using simple Python libraries.\n",
        "3. Train/Use Embeddings:\n",
        "   - Use pre-trained word embedding models to generate expanded query terms.\n",
        "4. Output:\n",
        "   - Get a list of related terms or ranked pages based on relevance.\n",
        "\n",
        "---\n",
        "\n",
        "### Conclusion\n",
        "\n",
        "Word Embeddings for Query Expansion is a powerful tool to enhance search functionality on websites. Whether using website URLs or structured CSV data, the process involves analyzing user queries, expanding them with related terms, and matching them with website content to improve visibility and engagement. The output includes expanded query terms, ranked results, and insights into user behavior, making it an invaluable asset for improving website search capabilities.\n"
      ],
      "metadata": {
        "id": "uaTMMJI3qV9Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# **What Outputs Does the Model Provide?**\n",
        "\n",
        "The Word Embeddings for Query Expansion Model generates the following outputs:\n",
        "\n",
        "1. **Expanded Query Terms:**\n",
        "   - When a user enters a search term (like \"SEO services\"), the model expands it by adding related or synonymous terms.\n",
        "   - For example:\n",
        "     - Input Query: \"SEO services\"\n",
        "     - Expanded Terms: [\"Search engine optimization services\", \"digital marketing services\", \"website ranking solutions\", \"online visibility services\"]\n",
        "   - This helps the search system understand the intent behind the query better and retrieve all relevant content, even if the exact terms don’t match.\n",
        "\n",
        "2. **Ranked Search Results:**\n",
        "   - The model processes the expanded query and matches it to your website content (titles, meta descriptions, page content, etc.).\n",
        "   - It ranks the results by relevance. For example:\n",
        "     - Input Query: \"affordable SEO packages\"\n",
        "     - Expanded Terms: [\"budget SEO plans\", \"low-cost SEO services\"]\n",
        "     - Ranked Results: URLs or page titles like:\n",
        "       1. **www.thatware.co/affordable-seo-services**\n",
        "       2. **www.thatware.co/budget-seo-plans**\n",
        "       3. **www.thatware.co/seo-pricing**\n",
        "   - These ranked results are shown to the user to improve the accuracy and usefulness of the search.\n",
        "\n",
        "3. **Visualization (Optional):**\n",
        "   - For internal analysis, you can see how the model expanded the query and matched it with your website’s content.\n",
        "   - Example Visualization:\n",
        "     ```\n",
        "     User Query: \"SEO for small business\"\n",
        "     Expanded Terms: [\"local SEO\", \"small business online marketing\", \"SEO for startups\"]\n",
        "     Matched Content: [Page 1: Small Business SEO Tips, Page 2: Affordable SEO Solutions]\n",
        "     ```\n",
        "\n",
        "4. **Improved Search Suggestions:**\n",
        "   - The model can suggest additional terms as the user types. For example, if a user starts typing \"SEO,\" suggestions like \"SEO for small business\" or \"SEO pricing\" appear, helping users refine their search.\n",
        "\n",
        "5. **Analytics Insights:**\n",
        "   - The model tracks frequently expanded terms and user behavior. This helps you identify:\n",
        "     - Popular search queries.\n",
        "     - Commonly expanded terms.\n",
        "     - Content gaps where users search for terms not covered on your website.\n",
        "\n",
        "---\n",
        "\n",
        "### **How Does This Apply to www.thatware.co?**\n",
        "\n",
        "Your website, **thatware.co**, specializes in digital marketing and SEO services. The Word Embeddings for Query Expansion Model can benefit your site in the following ways:\n",
        "\n",
        "#### 1. **Expanded Query Terms for User Queries**\n",
        "   - Visitors to your site may search for “AI-driven SEO” or “SEO for e-commerce.” If your content uses terms like “machine learning for SEO” or “SEO for online stores,” the query expansion model bridges this gap.\n",
        "   - Expanded terms include related phrases such as:\n",
        "     - Input Query: \"AI SEO\"\n",
        "     - Expanded Terms: [\"artificial intelligence SEO\", \"ML for search engine optimization\", \"automated SEO tools\"]\n",
        "\n",
        "#### 2. **Ranking Relevant Pages**\n",
        "   - If a user searches for “SEO pricing,” the model finds all related content (like blogs, service pages, or pricing plans) and ranks them.\n",
        "   - This helps users quickly land on pages like:\n",
        "     - **www.thatware.co/seo-packages**\n",
        "     - **www.thatware.co/affordable-seo-pricing**\n",
        "\n",
        "#### 3. **Improved User Experience**\n",
        "   - By providing more relevant results, users stay longer on your website, increasing engagement and reducing bounce rates.\n",
        "   - For example, if a user searches for “digital marketing trends,” and the expanded query includes “latest SEO techniques” or “current marketing strategies,” they’ll find blogs or case studies matching these terms.\n",
        "\n",
        "#### 4. **Search Suggestions**\n",
        "   - As users type in the search bar, suggestions appear, such as:\n",
        "     - User starts typing: “SEO”\n",
        "     - Suggestions: “SEO services for startups,” “SEO trends 2024,” “AI-driven SEO strategies”\n",
        "\n",
        "#### 5. **Identifying Content Gaps**\n",
        "   - By analyzing expanded queries that users search for, you can discover missing content. For instance:\n",
        "     - Users frequently search for “e-commerce SEO for startups,” but your website lacks specific pages on this topic. This insight allows you to create targeted content to fill gaps.\n",
        "\n",
        "#### 6. **Enhanced Keyword Targeting for SEO**\n",
        "   - The model ensures you’re targeting a broader set of keywords, improving your organic search rankings. For instance:\n",
        "     - Query: “local SEO”\n",
        "     - Expanded Terms: [\"SEO for small businesses,\" \"nearby SEO services,\" \"Google My Business optimization\"]\n",
        "     - Result: Better visibility for your local SEO-related pages.\n",
        "\n",
        "---\n",
        "\n",
        "### **Detailed Explanation of Outputs for Thatware.co**\n",
        "\n",
        "1. **Relevant Content URLs:**\n",
        "   - These are links to the pages on your site that match the expanded query terms.\n",
        "   - Example:\n",
        "     - Query: “AI SEO tools”\n",
        "     - URLs Returned:\n",
        "       - **www.thatware.co/ai-seo-tools**\n",
        "       - **www.thatware.co/ai-in-seo**\n",
        "       - **www.thatware.co/machine-learning-seo**\n",
        "\n",
        "2. **Improved Search Suggestions:**\n",
        "   - These help users refine their queries, ensuring they find exactly what they’re looking for.\n",
        "   - Example:\n",
        "     - User starts typing “SEO.”\n",
        "     - Suggestions: “SEO packages,” “SEO for startups,” “affordable SEO services.”\n",
        "\n",
        "3. **Analytics Insights:**\n",
        "   - Reports that show:\n",
        "     - What terms users search for.\n",
        "     - How their queries were expanded.\n",
        "     - Which pages were visited after the search.\n",
        "   - Example Insight:\n",
        "     - Popular Query: “best SEO practices”\n",
        "     - Expanded Terms: [\"SEO best practices 2024,\" \"effective SEO techniques\"]\n",
        "     - Pages Visited: Blog on SEO trends, Service page on SEO audits.\n",
        "\n",
        "4. **Visualization:**\n",
        "   - Internal reports showing how expanded terms match content. Useful for reviewing how search functionality is improving.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "0cjoq_LFq3LR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part 1: Scraping and Preprocessing Website Content**\n",
        "\n",
        "- **Why this name?**\n",
        "  - This part of the code focuses on collecting data (web content) from multiple URLs and cleaning it for further analysis. It extracts key components like the webpage title, meta descriptions, body text, and keywords.\n",
        "\n",
        "- **What happens in this part?**\n",
        "  1. **Scrape Web Content**:\n",
        "     - The function `scrape_webpage()` fetches content from a list of URLs. It extracts titles, meta descriptions, and raw body text.\n",
        "     - Example: From a page like \"https://thatware.co/\", it will pull information like the title (\"THATWARE - SEO Services\"), description, and visible text.\n",
        "  2. **Preprocess Text**:\n",
        "     - Using the `preprocess_text()` function, the raw body text is cleaned by:\n",
        "       - Removing stopwords (e.g., \"the,\" \"is,\" \"and\").\n",
        "       - Removing punctuation and digits.\n",
        "       - Converting the text to lowercase for consistency.\n",
        "     - Example: The sentence \"SEO Services are the best in 2023!\" becomes \"seo services best.\"\n",
        "  3. **Extract Key Terms**:\n",
        "     - Using TF-IDF (a mathematical method), the `extract_key_terms()` function identifies the most important words in the cleaned text. For example, it might extract \"seo,\" \"services,\" and \"digital.\"\n",
        "  4. **Save Scraped Data**:\n",
        "     - The cleaned and structured data (title, description, body text, and key terms) is saved into a CSV file (`scraped_data_with_key_terms.csv`) for future use.\n",
        "\n",
        "- **Summary of Part 1**:\n",
        "  This part is the foundation of the model. It gathers data from the web and prepares it for analysis by cleaning and identifying key terms.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "T_CvAGoKZaf3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import requests  # To fetch webpage content\n",
        "from bs4 import BeautifulSoup  # For parsing HTML and extracting webpage elements\n",
        "import pandas as pd  # To save and manipulate structured data\n",
        "import re  # For cleaning text data\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer  # To extract key terms\n",
        "import nltk\n",
        "from nltk.corpus import stopwords  # To remove common stopwords\n",
        "import string  # To handle punctuation\n",
        "\n",
        "# Ensure necessary NLTK resources are downloaded\n",
        "nltk.download('stopwords')  # Download stopwords for text preprocessing\n",
        "\n",
        "# Step 1: Function to scrape webpage content\n",
        "def scrape_webpage(url):\n",
        "    \"\"\"\n",
        "    Scrapes a webpage to extract meta descriptions, titles, and body text.\n",
        "\n",
        "    Args:\n",
        "        url (str): URL of the webpage to scrape.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary with structured data including:\n",
        "            - Title\n",
        "            - Description\n",
        "            - Key terms (TF-IDF extracted)\n",
        "            - Cleaned body text\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Fetch webpage content\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()  # Ensure the request was successful\n",
        "\n",
        "        # Parse webpage content using BeautifulSoup\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # Extract the title of the page\n",
        "        title = soup.title.string.strip() if soup.title else \"No Title Found\"\n",
        "\n",
        "        # Extract meta description (if available)\n",
        "        description_meta = soup.find(\"meta\", attrs={\"name\": \"description\"})\n",
        "        description = description_meta[\"content\"].strip() if description_meta else \"No Description Found\"\n",
        "\n",
        "        # Extract all visible text from the page\n",
        "        body_text = soup.get_text(separator=\" \")\n",
        "\n",
        "        # Preprocess and clean the body text\n",
        "        cleaned_body_text = preprocess_text(body_text)\n",
        "\n",
        "        # Extract key terms from the cleaned text using TF-IDF\n",
        "        key_terms = extract_key_terms(cleaned_body_text)\n",
        "\n",
        "        return {\n",
        "            \"url\": url,\n",
        "            \"title\": title,\n",
        "            \"description\": description,\n",
        "            \"key_terms\": \", \".join(key_terms),  # Key terms joined into a single string\n",
        "            \"body_text\": cleaned_body_text\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"Error scraping {url}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Step 2: Function to clean and preprocess text\n",
        "def preprocess_text(text):\n",
        "    \"\"\"\n",
        "    Cleans text by removing stopwords, punctuation, and digits.\n",
        "\n",
        "    Args:\n",
        "        text (str): Raw text to preprocess.\n",
        "\n",
        "    Returns:\n",
        "        str: Cleaned and processed text.\n",
        "    \"\"\"\n",
        "    # Convert text to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove digits\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "\n",
        "    # Remove punctuation\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "    # Tokenize text into words\n",
        "    words = text.split()\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_words = [word for word in words if word not in stop_words]\n",
        "\n",
        "    # Join the cleaned words back into a single string\n",
        "    return \" \".join(filtered_words)\n",
        "\n",
        "# Step 3: Function to extract key terms using TF-IDF\n",
        "def extract_key_terms(text, top_n=10):\n",
        "    \"\"\"\n",
        "    Extracts top key terms from text using TF-IDF.\n",
        "\n",
        "    Args:\n",
        "        text (str): Cleaned text.\n",
        "        top_n (int): Number of top terms to extract.\n",
        "\n",
        "    Returns:\n",
        "        list: List of key terms.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # TF-IDF requires input as a list of documents\n",
        "        documents = [text]\n",
        "\n",
        "        # Initialize TF-IDF vectorizer\n",
        "        vectorizer = TfidfVectorizer(max_features=top_n)\n",
        "        tfidf_matrix = vectorizer.fit_transform(documents)\n",
        "\n",
        "        # Extract feature names (key terms)\n",
        "        return vectorizer.get_feature_names_out()\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting key terms: {e}\")\n",
        "        return []\n",
        "\n",
        "# Step 4: URLs to scrape\n",
        "urls = [\n",
        "    'https://thatware.co/',\n",
        "    'https://thatware.co/services/',\n",
        "    'https://thatware.co/advanced-seo-services/',\n",
        "    'https://thatware.co/digital-marketing-services/',\n",
        "    'https://thatware.co/business-intelligence-services/',\n",
        "    'https://thatware.co/link-building-services/',\n",
        "    'https://thatware.co/branding-press-release-services/',\n",
        "    'https://thatware.co/conversion-rate-optimization/',\n",
        "    'https://thatware.co/social-media-marketing/',\n",
        "    'https://thatware.co/content-proofreading-services/',\n",
        "    'https://thatware.co/website-design-services/',\n",
        "    'https://thatware.co/web-development-services/',\n",
        "    'https://thatware.co/app-development-services/',\n",
        "    'https://thatware.co/website-maintenance-services/',\n",
        "    'https://thatware.co/bug-testing-services/',\n",
        "    'https://thatware.co/software-development-services/',\n",
        "    'https://thatware.co/competitor-keyword-analysis/'\n",
        "]\n",
        "\n",
        "# Step 5: Scrape each URL and save results\n",
        "scraped_data = [scrape_webpage(url) for url in urls]\n",
        "\n",
        "# Filter out None values (errors)\n",
        "scraped_data = [data for data in scraped_data if data]\n",
        "\n",
        "# Step 6: Save data to CSV\n",
        "df = pd.DataFrame(scraped_data)\n",
        "df.to_csv('scraped_data_with_key_terms.csv', index=False)\n",
        "print(\"Data scraped and saved successfully!\")\n",
        "\n",
        "# Display the first few rows\n",
        "print(df.head(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbOolxs91D36",
        "outputId": "9ca5b002-4d5f-4291-f1e3-4a5540907785"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data scraped and saved successfully!\n",
            "                                                 url  \\\n",
            "0                               https://thatware.co/   \n",
            "1                      https://thatware.co/services/   \n",
            "2         https://thatware.co/advanced-seo-services/   \n",
            "3    https://thatware.co/digital-marketing-services/   \n",
            "4  https://thatware.co/business-intelligence-serv...   \n",
            "5        https://thatware.co/link-building-services/   \n",
            "6  https://thatware.co/branding-press-release-ser...   \n",
            "7  https://thatware.co/conversion-rate-optimization/   \n",
            "8        https://thatware.co/social-media-marketing/   \n",
            "9  https://thatware.co/content-proofreading-servi...   \n",
            "\n",
            "                                               title  \\\n",
            "0  THATWARE® - Revolutionizing SEO with Hyper-Int...   \n",
            "1  Digital Marketing Services by Thatware - Top R...   \n",
            "2  Advanced SEO Services - Professional SEO Agenc...   \n",
            "3  Digital Marketing Services - Advanced Digital ...   \n",
            "4  Business Intelligence Services - Competitive A...   \n",
            "5  Link Building Services - Off Page SEO Agency -...   \n",
            "6  PPC Paid Marketing Services Agency -Branding |...   \n",
            "7  Conversion Rate Optimization (CRO) Services - ...   \n",
            "8  Social Media Marketing Agency- SMO and SMM Ser...   \n",
            "9  Content Proofreading Services | Hire Content P...   \n",
            "\n",
            "                                         description  \\\n",
            "0  THATWARE® is the world's first SEO agency to s...   \n",
            "1  Watch our exclusive digital marketing services...   \n",
            "2  Now you can enjoy advanced seo services for yo...   \n",
            "3  Thatware provides exclusive digital marketing ...   \n",
            "4  Get the exclusive benefits by tapping into the...   \n",
            "5  Thatware provides a wide range of strategies f...   \n",
            "6  Try out the exclusive PPC media buying service...   \n",
            "7  Improve your sales funnel today with Thatware'...   \n",
            "8  Thatware provides exclusive social media marke...   \n",
            "9  Thatware is recognized as the leading agency f...   \n",
            "\n",
            "                                           key_terms  \\\n",
            "0  advanced, ai, company, content, development, g...   \n",
            "1  advanced, ai, company, content, development, d...   \n",
            "2  advanced, audit, business, digital, implementa...   \n",
            "3  advanced, business, content, digital, marketin...   \n",
            "4  analysis, business, competitor, data, intellig...   \n",
            "5  advanced, backlinks, building, content, link, ...   \n",
            "6  agency, branding, marketing, online, ppc, pr, ...   \n",
            "7  conversion, help, make, optimization, page, ra...   \n",
            "8  brand, company, content, help, marketing, medi...   \n",
            "9  content, editing, proofreading, quality, seo, ...   \n",
            "\n",
            "                                           body_text  \n",
            "0  thatware® revolutionizing seo hyperintelligenc...  \n",
            "1  digital marketing services thatware top rated ...  \n",
            "2  advanced seo services professional seo agency ...  \n",
            "3  digital marketing services advanced digital co...  \n",
            "4  business intelligence services competitive ana...  \n",
            "5  link building services page seo agency thatwar...  \n",
            "6  ppc paid marketing services agency branding ad...  \n",
            "7  conversion rate optimization cro services cro ...  \n",
            "8  social media marketing agency smo smm services...  \n",
            "9  content proofreading services hire content pro...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### Explanation of the Output:\n",
        "\n",
        "The output is a **table** with rows and columns. Each row represents a web page, and the columns provide different types of information about that page.\n",
        "\n",
        "#### **Columns Explained:**\n",
        "\n",
        "1. **`url` (Column 1):**\n",
        "   - This column contains the web addresses (URLs) of the pages that were scraped. For example:\n",
        "     - `https://thatware.co/`\n",
        "     - `https://thatware.co/services/`\n",
        "   - These URLs are the actual locations of the pages on the internet.\n",
        "\n",
        "2. **`title` (Column 2):**\n",
        "   - This column shows the title of each web page. The title is usually the headline or the most prominent text you see on a page in your browser.\n",
        "   - Example Titles:\n",
        "     - `THATWARE® - Revolutionizing SEO with Hyper-Intelligence`\n",
        "     - `Digital Marketing Services by Thatware - Top Rated SEO Agency`\n",
        "   - These titles summarize what the page is about.\n",
        "\n",
        "3. **`description` (Column 3):**\n",
        "   - The description provides a short summary of what each page contains. This is typically used to describe the page's content in search engine results.\n",
        "   - Examples of descriptions:\n",
        "     - `THATWARE® is the world's first SEO agency to seamlessly integrate AI into its strategies...`\n",
        "     - `Watch our exclusive digital marketing services from the leading industrial experts...`\n",
        "   - This helps readers quickly understand what the page is about without opening it.\n",
        "\n",
        "4. **`key_terms` (Column 4):**\n",
        "   - This column contains a list of important keywords or phrases related to the page. These keywords summarize the main topics discussed on the page.\n",
        "   - Example Key Terms:\n",
        "     - `advanced, ai, company, content, development, google, marketing, seo`\n",
        "     - `conversion, help, make, optimization, page, rate, services`\n",
        "   - These keywords are often used to improve the visibility of the page in search results (SEO).\n",
        "\n",
        "5. **`body_text` (Column 5):**\n",
        "   - This column contains the full text content of the web page. This is the detailed text or article that appears on the page.\n",
        "   - Example (simplified for clarity):\n",
        "     - \"ThatWare® revolutionizing SEO hyper-intelligence services advanced digital marketing advanced...\"\n",
        "   - This is the actual information you’d read on the page if you opened the URL.\n",
        "\n",
        "---\n",
        "\n",
        "#### **How to Understand a Row:**\n",
        "\n",
        "Each **row** in the table represents a single web page. Let’s look at an example:\n",
        "\n",
        "- **Row 0**:\n",
        "  - **URL:** `https://thatware.co/` (This is the address of the page.)\n",
        "  - **Title:** `THATWARE® - Revolutionizing SEO with Hyper-Intelligence` (This is the headline of the page.)\n",
        "  - **Description:** `THATWARE® is the world's first SEO agency to seamlessly integrate AI into its strategies...` (This is a summary of the page.)\n",
        "  - **Key Terms:** `advanced, ai, company, content, development, google, marketing, seo` (These are the main topics covered on the page.)\n",
        "  - **Body Text:** This contains the main article or detailed content on the page, starting with \"ThatWare® revolutionizing SEO hyper-intelligence services...\"\n",
        "\n",
        "---\n",
        "\n",
        "#### **Purpose of the Output:**\n",
        "\n",
        "1. **Data Organization:**\n",
        "   - The output organizes all the important information from the scraped web pages into a structured format (table). Each row corresponds to one web page, and the columns provide specific details about the page.\n",
        "\n",
        "2. **Application in Query Expansion:**\n",
        "   - This data will later be used to analyze the content and keywords on the pages. For example, if a user searches for \"SEO services,\" the program can look at the keywords in the `key_terms` column to suggest related terms like \"digital marketing\" or \"link building.\"\n",
        "\n",
        "3. **Improving Search Results:**\n",
        "   - By analyzing titles, descriptions, and keywords, the system can better understand the context of each page. This helps in expanding queries and finding more relevant results for a user’s search.\n",
        "\n",
        "---\n",
        "\n",
        "### Non-Technical Takeaway:\n",
        "\n",
        "Think of this output as a well-organized **catalog** of web pages. Each page has:\n",
        "- Its address (URL),\n",
        "- A headline (title),\n",
        "- A short summary (description),\n",
        "- A list of main topics (key terms),\n",
        "- And the actual content (body text).\n",
        "\n",
        "The system will use this data to improve searches by finding patterns and relationships between different pages. For example, it might identify that \"SEO\" is often discussed alongside \"AI\" and \"digital marketing,\" which helps expand searches for users looking for related content.\n"
      ],
      "metadata": {
        "id": "B6x3zKYCMXaZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# **Part 2: Word Embedding Training and Similarity Analysis**\n",
        "\n",
        "- **Why this name?**\n",
        "  - This part of the code trains a Word2Vec model (a machine learning algorithm) to generate word embeddings. These embeddings capture relationships between words, enabling the model to find similar terms.\n",
        "\n",
        "- **What happens in this part?**\n",
        "  1. **Train Word Embeddings**:\n",
        "     - The `train_word_embeddings()` function trains a Word2Vec model on the cleaned text data from Part 1.\n",
        "     - Words are represented as numerical vectors, capturing their meanings and relationships. For example:\n",
        "       - The word \"seo\" might be represented as a vector like `[0.2, -0.3, 0.8, ...]`.\n",
        "  2. **Generate Similar Word Lists**:\n",
        "     - The `generate_embedding_dataframe()` function finds the top 5 most similar words for each term in the dataset. For example:\n",
        "       - For \"seo,\" similar words might be \"optimization,\" \"services,\" and \"digital.\"\n",
        "  3. **Save Word Embeddings**:\n",
        "     - The embeddings and similar words are saved to a CSV file (`word_embeddings_with_similar_words.csv`) for future use.\n",
        "\n",
        "- **Summary of Part 2**:\n",
        "  This part uses machine learning to create word embeddings, which are numerical representations of words. It identifies relationships between words and saves this information for query expansion.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "Z4YXBGeN2P8Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec  # For training word embeddings\n",
        "from gensim.utils import simple_preprocess  # For tokenizing and preprocessing text\n",
        "import pandas as pd  # For handling structured data\n",
        "import csv  # For saving the embeddings into a CSV file\n",
        "\n",
        "# Function to train the Word2Vec model\n",
        "def train_word_embeddings(dataframe):\n",
        "    \"\"\"\n",
        "    Trains a Word2Vec model on the cleaned text data from the DataFrame.\n",
        "\n",
        "    Args:\n",
        "        dataframe (pd.DataFrame): The DataFrame containing cleaned body text.\n",
        "\n",
        "    Returns:\n",
        "        Word2Vec: A trained Word2Vec model.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Step 1: Tokenize the body text\n",
        "        # Tokenizing breaks the text into individual words (tokens) while removing punctuation and stopwords.\n",
        "        tokenized_text = dataframe['body_text'].apply(simple_preprocess)\n",
        "\n",
        "        # Step 2: Train the Word2Vec model\n",
        "        model = Word2Vec(\n",
        "            sentences=tokenized_text,  # Tokenized text\n",
        "            vector_size=100,  # 100-dimensional vector for each word\n",
        "            window=5,  # Context window size for capturing relationships\n",
        "            min_count=2,  # Ignore words that appear less than twice\n",
        "            workers=4  # Utilize multiple CPU threads for faster training\n",
        "        )\n",
        "\n",
        "        # Step 3: Save the trained model\n",
        "        model.save('word2vec_model.model')\n",
        "        print(\"Word2Vec model trained and saved successfully.\")\n",
        "\n",
        "        return model\n",
        "    except Exception as e:\n",
        "        print(f\"Error training Word2Vec model: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "# Function to generate a DataFrame with embeddings and similar words\n",
        "def generate_embedding_dataframe(word2vec_model):\n",
        "    \"\"\"\n",
        "    Creates a DataFrame with word embeddings, their similar words, and numerical vectors.\n",
        "\n",
        "    Args:\n",
        "        word2vec_model (Word2Vec): The trained Word2Vec model.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A DataFrame containing words, embeddings, and similar words.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Create a list to store data for all words\n",
        "        data = []\n",
        "\n",
        "        # Iterate through each word in the vocabulary\n",
        "        for word in word2vec_model.wv.index_to_key:\n",
        "            # Retrieve the embedding vector\n",
        "            vector = word2vec_model.wv[word]\n",
        "\n",
        "            # Find top 5 similar words\n",
        "            similar_words = word2vec_model.wv.most_similar(word, topn=5)\n",
        "\n",
        "            # Append data as a dictionary\n",
        "            data.append({\n",
        "                \"Word\": word,\n",
        "                \"Embedding_Vector\": vector.tolist(),\n",
        "                \"Similar_Words\": [f\"{similar[0]} ({similar[1]:.2f})\" for similar in similar_words]\n",
        "            })\n",
        "\n",
        "        # Convert the list into a DataFrame\n",
        "        embedding_df = pd.DataFrame(data)\n",
        "\n",
        "        # Save the DataFrame as a CSV file\n",
        "        embedding_df.to_csv(\"word_embeddings_with_similar_words.csv\", index=False)\n",
        "        print(\"Embedding DataFrame created and saved as 'word_embeddings_with_similar_words.csv'.\")\n",
        "\n",
        "        # Return the DataFrame for further use\n",
        "        return embedding_df\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating embedding DataFrame: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "# Function to display a preview of the embedding DataFrame\n",
        "def preview_embedding_dataframe(dataframe):\n",
        "    \"\"\"\n",
        "    Displays the first few rows of the embedding DataFrame.\n",
        "\n",
        "    Args:\n",
        "        dataframe (pd.DataFrame): The embedding DataFrame.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    print(\"\\nPreview of the Embedding DataFrame:\")\n",
        "    print(dataframe.head())\n",
        "\n",
        "\n",
        "# Main execution\n",
        "# Step 1: Load the scraped data from the CSV file\n",
        "# Ensure the scraped data has a 'body_text' column\n",
        "df = pd.read_csv('scraped_data_with_key_terms.csv')\n",
        "\n",
        "# Step 2: Train the Word2Vec model on the cleaned body text\n",
        "word2vec_model = train_word_embeddings(df)\n",
        "\n",
        "# Step 3: Generate a DataFrame with embeddings and similar words\n",
        "embedding_df = generate_embedding_dataframe(word2vec_model)\n",
        "\n",
        "# Step 4: Preview the created DataFrame\n",
        "if embedding_df is not None:\n",
        "    preview_embedding_dataframe(embedding_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yf0m4ozeykCI",
        "outputId": "6d84808e-6e86-499c-eb6b-cbdf97d26426"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word2Vec model trained and saved successfully.\n",
            "Embedding DataFrame created and saved as 'word_embeddings_with_similar_words.csv'.\n",
            "\n",
            "Preview of the Embedding DataFrame:\n",
            "        Word                                   Embedding_Vector  \\\n",
            "0        seo  [-0.6112529635429382, 0.7676607370376587, 0.50...   \n",
            "1   services  [-0.5725305080413818, 0.5901663303375244, 0.41...   \n",
            "2  marketing  [-0.5322718024253845, 0.7903143763542175, 0.42...   \n",
            "3    website  [-0.6315702795982361, 0.9170331954956055, 0.46...   \n",
            "4   business  [-0.626875102519989, 0.9419310092926025, 0.475...   \n",
            "\n",
            "                                       Similar_Words  \n",
            "0  [noida (1.00), nadu (1.00), based (1.00), sura...  \n",
            "1  [europe (0.99), gujarat (0.99), bangalore (0.9...  \n",
            "2  [digital (1.00), business (1.00), one (1.00), ...  \n",
            "3  [process (1.00), need (1.00), application (1.0...  \n",
            "4  [online (1.00), strategies (1.00), time (1.00)...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explanation of the Output\n",
        "\n",
        "The output represents data generated by a **Word2Vec model**, which is a machine learning technique used to understand relationships between words. Let’s break it down **column by column** and **row by row** in simple terms.\n",
        "\n",
        "---\n",
        "\n",
        "#### What is Word2Vec and Embeddings?\n",
        "Before we dive into the output:\n",
        "- Word2Vec is a model that converts words into numbers (called vectors) so that a computer can understand their meaning.\n",
        "- These vectors represent how words are related to each other in a mathematical space. Words with similar meanings or context will have similar vectors.\n",
        "\n",
        "---\n",
        "\n",
        "#### Columns in the Output\n",
        "\n",
        "1. **`Word` (First Column):**\n",
        "   - This column lists the words the model has learned from your data. These are the main words you want to analyze or expand queries for.\n",
        "   - For example:\n",
        "     - `seo`: Refers to Search Engine Optimization.\n",
        "     - `services`: Refers to offerings or assistance provided.\n",
        "     - `marketing`: Refers to the process of promoting products or services.\n",
        "\n",
        "2. **`Embedding_Vector` (Second Column):**\n",
        "   - This column contains the **vector representation** of each word.\n",
        "   - A vector is a set of numbers (like coordinates) that shows where the word is located in a multidimensional space. Words that are closer in this space have similar meanings or contexts.\n",
        "   - Example:\n",
        "     - For `seo`, the embedding vector looks like: `[-0.611, 0.767, 0.501, ...]`. This is just a fancy way of representing the word mathematically.\n",
        "\n",
        "3. **`Similar_Words` (Third Column):**\n",
        "   - This column lists the words that are most similar to the word in the first column. The numbers in parentheses indicate how similar the words are on a scale from 0 to 1 (1 means identical).\n",
        "   - Example:\n",
        "     - For `seo`, the similar words might include `[noida (1.00), nadu (1.00), based (1.00)]`.\n",
        "     - This means the word `seo` is often related to `noida`, `nadu`, and `based` in the data.\n",
        "\n",
        "---\n",
        "\n",
        "#### Rows in the Output\n",
        "\n",
        "Each row represents one word, its vector, and its most similar words. Let’s go row by row:\n",
        "\n",
        "1. **Row 0 (`seo`):**\n",
        "   - **Word:** `seo`\n",
        "   - **Embedding Vector:** A series of numbers like `[-0.611, 0.767, 0.501...]`. This represents how the word \"seo\" is placed in the mathematical space.\n",
        "   - **Similar Words:** `[noida (1.00), nadu (1.00), based (1.00), ...]`.\n",
        "     - This means the word `seo` is closely related to locations like `noida`, `nadu`, and the term `based`. These relationships come from the data you provided, where these words often appear in the same context as `seo`.\n",
        "\n",
        "2. **Row 1 (`services`):**\n",
        "   - **Word:** `services`\n",
        "   - **Embedding Vector:** Numbers like `[-0.572, 0.590, 0.417...]`.\n",
        "   - **Similar Words:** `[europe (0.99), gujarat (0.99), bangalore (0.99)]`.\n",
        "     - This means `services` is closely related to geographical regions like `europe`, `gujarat`, and `bangalore`.\n",
        "\n",
        "3. **Row 2 (`marketing`):**\n",
        "   - **Word:** `marketing`\n",
        "   - **Embedding Vector:** Numbers like `[-0.532, 0.790, 0.429...]`.\n",
        "   - **Similar Words:** `[digital (1.00), business (1.00), one (1.00)]`.\n",
        "     - This means `marketing` is closely related to `digital`, `business`, and the word `one`. These words are likely found together in the text.\n",
        "\n",
        "4. **Row 3 (`website`):**\n",
        "   - **Word:** `website`\n",
        "   - **Embedding Vector:** Numbers like `[-0.631, 0.917, 0.469...]`.\n",
        "   - **Similar Words:** `[process (1.00), need (1.00), application (1.00)]`.\n",
        "     - This means the term `website` is related to tasks like `process`, `need`, and `application`.\n",
        "\n",
        "5. **Row 4 (`business`):**\n",
        "   - **Word:** `business`\n",
        "   - **Embedding Vector:** Numbers like `[-0.626, 0.941, 0.475...]`.\n",
        "   - **Similar Words:** `[online (1.00), strategies (1.00), time (1.00)]`.\n",
        "     - This means `business` is closely associated with `online`, `strategies`, and `time`.\n",
        "\n",
        "---\n",
        "\n",
        "#### What Does This Mean?\n",
        "\n",
        "1. **Word Relationships:**\n",
        "   - The model has learned which words are commonly used together. For example:\n",
        "     - `seo` is linked to `noida` and `based`, which suggests that these terms are often discussed together in your data.\n",
        "\n",
        "2. **Query Expansion:**\n",
        "   - This output is useful for expanding search queries. If someone searches for `seo`, your model can also suggest related terms like `noida` or `based` to improve the search results.\n",
        "\n",
        "3. **Word Embeddings:**\n",
        "   - The numbers in the `Embedding_Vector` column allow computers to mathematically understand the meaning and relationships of words. This is the foundation of how modern search engines work.\n",
        "\n",
        "---\n",
        "\n",
        "#### Why Is This Important?\n",
        "\n",
        "- **Improved Search Results:** By analyzing the `Similar_Words`, you can provide users with better search suggestions.\n",
        "- **Keyword Insights:** This helps identify which words are most relevant to a topic.\n",
        "- **Query Expansion:** If someone searches for `marketing`, you can also suggest `digital` or `business`, leading to more relevant results.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "adk_6iAQNMt1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# **Final Part 3: Query Expansion and URL Relevance Analysis**\n",
        "\n",
        "- **Why this name?**\n",
        "  - This part expands the queries (words) by analyzing their co-occurrences and mapping them to relevant URLs. It also ranks URLs based on their relevance to specific terms.\n",
        "\n",
        "- **What happens in this part?**\n",
        "  1. **Map Words to URLs**:\n",
        "     - The `map_words_to_urls()` function identifies which URLs are most relevant to each word based on how often the word appears in the content.\n",
        "     - Example: For \"seo,\" relevant URLs might include `https://thatware.co/advanced-seo-services/`.\n",
        "  2. **Calculate Co-occurrences**:\n",
        "     - The `compute_cooccurrences()` function analyzes which words frequently appear together within a sliding window of text.\n",
        "     - Example: The word \"seo\" might co-occur with \"services\" and \"optimization.\"\n",
        "  3. **Categorize Co-occurrences**:\n",
        "     - The `group_cooccurrences_by_category()` function organizes co-occurrences into categories like \"technical\" or \"business.\"\n",
        "     - Example: \"seo\" might be categorized under \"technical,\" while \"marketing\" might fall under \"business.\"\n",
        "  4. **Save and Summarize Results**:\n",
        "     - The `save_results_to_csv_and_df()` function combines all the data (word frequencies, relevant URLs, and co-occurrences) into a CSV file (`final_query_results.csv`).\n",
        "\n",
        "- **Summary of Part 3**:\n",
        "  This part expands the queries by finding related words and mapping them to the most relevant URLs. It also provides insights into word relationships and saves the final results.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "I4Kf2wt574zg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "# **Step 1: Function to Rank URLs by Term Frequency**\n",
        "# Purpose: Rank URLs based on how often a term appears in them. This helps identify the most relevant pages for a term.\n",
        "def rank_urls(term, urls_with_counts, top_n=5):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        term (str): The term being analyzed.\n",
        "        urls_with_counts (list of tuples): URLs with their frequency counts for the term.\n",
        "        top_n (int): Number of top-ranked URLs to return.\n",
        "\n",
        "    Returns:\n",
        "        list: Top N URLs sorted by frequency for the given term.\n",
        "    \"\"\"\n",
        "    return sorted(urls_with_counts, key=lambda x: x[1], reverse=True)[:top_n]\n",
        "\n",
        "# **Step 2: Function to Compute Word Co-occurrences**\n",
        "# Purpose: Find out which words appear near each other (co-occurrences) in the content to capture their relationships.\n",
        "def compute_cooccurrences(terms, content_list, window=5):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        terms (list): List of target terms to analyze.\n",
        "        content_list (list): Text content from the dataset.\n",
        "        window (int): Sliding window size (number of words before and after a term).\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary mapping each term to its co-occurring words and their frequencies.\n",
        "    \"\"\"\n",
        "    cooccurrence_counts = Counter()\n",
        "    for content in content_list:\n",
        "        words = content.split()\n",
        "        for i, word in enumerate(words):\n",
        "            if word in terms:\n",
        "                # Define the window of words around the current term\n",
        "                window_terms = words[max(0, i-window):min(len(words), i+window+1)]\n",
        "                for adjacent_word in window_terms:\n",
        "                    if adjacent_word in terms and adjacent_word != word:\n",
        "                        cooccurrence_counts[(word, adjacent_word)] += 1\n",
        "\n",
        "    # Organize co-occurrences by each term\n",
        "    ranked_cooccurrences = defaultdict(list)\n",
        "    for (term1, term2), count in cooccurrence_counts.items():\n",
        "        ranked_cooccurrences[term1].append((term2, count))\n",
        "    return ranked_cooccurrences\n",
        "\n",
        "# **Step 3: Group Co-occurrences by Category**\n",
        "# Purpose: Organize co-occurrences into predefined categories (e.g., \"technical\", \"business\") for easier interpretation.\n",
        "def group_cooccurrences_by_category(ranked_cooccurrences, categories):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        ranked_cooccurrences (dict): Co-occurrence data for terms.\n",
        "        categories (dict): Mapping of terms to predefined categories.\n",
        "\n",
        "    Returns:\n",
        "        dict: Grouped co-occurrences categorized by type (e.g., \"technical\", \"business\").\n",
        "    \"\"\"\n",
        "    grouped_cooccurrences = defaultdict(lambda: defaultdict(list))\n",
        "    for term, co_occurrences in ranked_cooccurrences.items():\n",
        "        for related_term, count in co_occurrences:\n",
        "            category = categories.get(related_term, 'others')  # Default to 'others' if no category is defined\n",
        "            grouped_cooccurrences[term][category].append((related_term, count))\n",
        "    return grouped_cooccurrences\n",
        "\n",
        "# **Step 4: Map Words to Relevant URLs**\n",
        "# Purpose: Identify which URLs are most relevant for each word based on frequency of occurrence.\n",
        "def map_words_to_urls(terms, content_data, top_n=5):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        terms (list): List of target terms.\n",
        "        content_data (pd.DataFrame): Dataset containing content and URLs.\n",
        "        top_n (int): Number of top URLs to return for each term.\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary mapping terms to their most relevant URLs with frequency counts.\n",
        "    \"\"\"\n",
        "    url_mapping = defaultdict(list)\n",
        "    for _, row in content_data.iterrows():\n",
        "        url = row['url']\n",
        "        body_text = row['body_text'].lower()\n",
        "        for term in terms:\n",
        "            count = body_text.count(term)\n",
        "            if count > 0:\n",
        "                url_mapping[term].append((url, count))\n",
        "    return {term: rank_urls(term, urls, top_n) for term, urls in url_mapping.items()}\n",
        "\n",
        "# **Step 5: Save Results to CSV and DataFrame**\n",
        "# Purpose: Save the combined results (frequency, URLs, co-occurrences) into a CSV file and return a DataFrame.\n",
        "def save_results_to_csv_and_df(terms, url_mapping, grouped_cooccurrences, filename=\"final_query_results.csv\"):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        terms (list): List of target terms.\n",
        "        url_mapping (dict): URLs relevant to each term.\n",
        "        grouped_cooccurrences (dict): Grouped co-occurrence terms by category.\n",
        "        filename (str): Name of the output CSV file.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame containing the final results.\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    for term in terms:\n",
        "        urls = \", \".join([url for url, _ in url_mapping.get(term, [])])\n",
        "        co_occurrences = grouped_cooccurrences.get(term, {})\n",
        "        co_occurrence_summary = \"; \".join(\n",
        "            [f\"{category}: \" + \", \".join([f\"{t[0]} ({t[1]})\" for t in terms]) for category, terms in co_occurrences.items()]\n",
        "        )\n",
        "        frequency = sum([count for _, count in url_mapping.get(term, [])])\n",
        "        results.append({\n",
        "            \"Word\": term,\n",
        "            \"Frequency\": frequency,\n",
        "            \"Relevant URLs\": urls,\n",
        "            \"Co-occurrences (Grouped by Category)\": co_occurrence_summary,\n",
        "        })\n",
        "\n",
        "    # Save to CSV\n",
        "    df = pd.DataFrame(results)\n",
        "    df.to_csv(filename, index=False)\n",
        "    print(f\"Results saved to {filename}\")\n",
        "    return df\n",
        "\n",
        "# **Main Execution**\n",
        "# Purpose: Bring all steps together and generate the final results.\n",
        "if __name__ == \"__main__\":\n",
        "    # Load the required datasets\n",
        "    embedding_df = pd.read_csv('word_embeddings_with_similar_words.csv')  # Contains words and embeddings\n",
        "    content_df = pd.read_csv('scraped_data_with_key_terms.csv')  # Contains web page content and URLs\n",
        "\n",
        "    # Extract all terms and content\n",
        "    all_terms = embedding_df['Word'].tolist()\n",
        "    content_list = content_df['body_text'].fillna(\"\").str.lower().tolist()\n",
        "\n",
        "    # Define categories for grouping terms\n",
        "    predefined_categories = {\n",
        "        \"seo\": \"technical\",\n",
        "        \"marketing\": \"business\",\n",
        "        \"services\": \"business\",\n",
        "        \"digital\": \"technical\",\n",
        "        \"strategy\": \"business\",\n",
        "    }\n",
        "\n",
        "    # Generate mappings and analytics\n",
        "    url_mapping = map_words_to_urls(all_terms, content_df)\n",
        "    ranked_cooccurrences = compute_cooccurrences(all_terms, content_list)\n",
        "    grouped_cooccurrences = group_cooccurrences_by_category(ranked_cooccurrences, predefined_categories)\n",
        "\n",
        "    # Save and display results\n",
        "    final_df = save_results_to_csv_and_df(all_terms, url_mapping, grouped_cooccurrences)\n",
        "    print(\"Preview of Final Results:\")\n",
        "    print(final_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aS3IncidSon_",
        "outputId": "b019b265-7615-49c7-b91d-75ab1e3c061f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results saved to final_query_results.csv\n",
            "Preview of Final Results:\n",
            "        Word  Frequency                                      Relevant URLs  \\\n",
            "0        seo        732  https://thatware.co/advanced-seo-services/, ht...   \n",
            "1   services        419  https://thatware.co/content-proofreading-servi...   \n",
            "2  marketing        289  https://thatware.co/digital-marketing-services...   \n",
            "3    website        310  https://thatware.co/website-design-services/, ...   \n",
            "4   business        252  https://thatware.co/advanced-seo-services/, ht...   \n",
            "\n",
            "                Co-occurrences (Grouped by Category)  \n",
            "0  others: revolutionizing (3), advanced (303), l...  \n",
            "1  others: revolutionizing (1), advanced (119), m...  \n",
            "2  business: services (97), strategy (44); others...  \n",
            "3  others: consulting (17), aws (34), managed (18...  \n",
            "4  others: link (20), building (27), fully (35), ...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### Explanation of the Final Part of the Model\n",
        "\n",
        "The **final part of the Word Embeddings Query Expansion Model** combines and processes all the information from earlier steps to produce **actionable insights**. Here's how it works and what its output means:\n",
        "\n",
        "---\n",
        "\n",
        "#### **What Happens in the Final Part?**\n",
        "\n",
        "The final part performs the following key tasks:\n",
        "\n",
        "1. **Map Words to Relevant URLs**:\n",
        "   - The model identifies which URLs (web pages) are most relevant for each word. For example, for the word \"seo,\" it finds pages like `https://thatware.co/advanced-seo-services/` because these pages discuss SEO-related topics.\n",
        "   - It ranks these URLs based on how often the word appears in their content. Words appearing more frequently on a page make that page more relevant.\n",
        "\n",
        "2. **Calculate Word Frequencies**:\n",
        "   - It counts how many times each word appears in all the content combined. This is helpful to prioritize high-impact words. For example, the word \"seo\" appears 732 times, indicating it is an important term.\n",
        "\n",
        "3. **Analyze Co-occurrences**:\n",
        "   - The model checks which words frequently appear together in the same context. For example, \"seo\" might often appear with \"advanced\" or \"services.\"\n",
        "   - These co-occurrences are grouped into categories (e.g., \"technical,\" \"business\") for better understanding.\n",
        "\n",
        "4. **Save and Summarize Results**:\n",
        "   - The final results are saved in a structured CSV file (`final_query_results.csv`), making it easy to view and analyze.\n",
        "\n",
        "---\n",
        "\n",
        "#### **Output Structure**\n",
        "\n",
        "The final output is a table (or CSV) with the following columns:\n",
        "\n",
        "1. **Word**:\n",
        "   - These are the key terms analyzed by the model, such as \"seo,\" \"services,\" \"marketing,\" \"website,\" and \"business.\"\n",
        "   - Each word represents a topic or concept the model analyzed.\n",
        "\n",
        "2. **Frequency**:\n",
        "   - This tells us how many times a word appeared across all the website content.\n",
        "   - Example: \"seo\" appears 732 times, showing it is a highly relevant term.\n",
        "\n",
        "3. **Relevant URLs**:\n",
        "   - This lists the web pages where the word appears most frequently.\n",
        "   - Example: For \"seo,\" URLs like `https://thatware.co/advanced-seo-services/` are shown because they contain a lot of SEO-related content.\n",
        "\n",
        "4. **Co-occurrences (Grouped by Category)**:\n",
        "   - This shows words that frequently appear alongside the main word (e.g., \"seo\") and groups them into categories.\n",
        "   - Example:\n",
        "     - For \"seo,\" related terms like \"advanced,\" \"link,\" and \"revolutionizing\" are listed.\n",
        "     - Categories like \"technical\" or \"business\" help you understand the context.\n",
        "\n",
        "---\n",
        "\n",
        "#### **Breaking Down the Output Row by Row**\n",
        "\n",
        "Let's analyze a row of the output to make things clearer:\n",
        "\n",
        "1. **Word**: `seo`\n",
        "   - This term is one of the most important in the dataset because it appears 732 times.\n",
        "   \n",
        "2. **Frequency**: `732`\n",
        "   - The word \"seo\" appears 732 times across all web pages, showing its importance.\n",
        "\n",
        "3. **Relevant URLs**:\n",
        "   - The URLs listed (e.g., `https://thatware.co/advanced-seo-services/`) are the pages where \"seo\" appears most frequently.\n",
        "   - This helps users know where to find the most relevant content for \"seo.\"\n",
        "\n",
        "4. **Co-occurrences (Grouped by Category)**:\n",
        "   - The word \"seo\" frequently appears with:\n",
        "     - \"revolutionizing\" (3 times)\n",
        "     - \"advanced\" (303 times)\n",
        "     - \"link\" (27 times)\n",
        "   - These terms are grouped under categories like \"others\" or \"business,\" providing context.\n",
        "\n",
        "---\n",
        "\n",
        "#### **How This Aligns with the Expected Output**\n",
        "\n",
        "1. **Relevant Content URLs**:\n",
        "   - The output successfully identifies and ranks URLs for each word based on relevance.\n",
        "   - Example: For \"marketing,\" URLs focus on pages about digital marketing.\n",
        "\n",
        "2. **Improved Search Suggestions**:\n",
        "   - Co-occurrences suggest related terms, enhancing search accuracy. For \"services,\" suggestions include \"advanced,\" \"managed,\" and \"technical.\"\n",
        "\n",
        "3. **Analytics Insights**:\n",
        "   - The frequency column helps identify high-priority words for SEO and content optimization.\n",
        "   - Grouped co-occurrences reveal relationships and trends among terms.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "B7Y2TxR5YYnD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import requests  # To fetch webpage content\n",
        "from bs4 import BeautifulSoup  # For parsing HTML and extracting webpage elements\n",
        "import pandas as pd  # To save and manipulate structured data\n",
        "import re  # For cleaning text data\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer  # To extract key terms\n",
        "import nltk\n",
        "from nltk.corpus import stopwords  # To remove common stopwords\n",
        "import string  # To handle punctuation\n",
        "\n",
        "# Ensure necessary NLTK resources are downloaded\n",
        "nltk.download('stopwords')  # Download stopwords for text preprocessing\n",
        "\n",
        "# Step 1: Function to scrape webpage content\n",
        "def scrape_webpage(url):\n",
        "    \"\"\"\n",
        "    Scrapes a webpage to extract meta descriptions, titles, and body text.\n",
        "\n",
        "    Args:\n",
        "        url (str): URL of the webpage to scrape.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary with structured data including:\n",
        "            - Title\n",
        "            - Description\n",
        "            - Key terms (TF-IDF extracted)\n",
        "            - Cleaned body text\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Fetch webpage content\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()  # Ensure the request was successful\n",
        "\n",
        "        # Parse webpage content using BeautifulSoup\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # Extract the title of the page\n",
        "        title = soup.title.string.strip() if soup.title else \"No Title Found\"\n",
        "\n",
        "        # Extract meta description (if available)\n",
        "        description_meta = soup.find(\"meta\", attrs={\"name\": \"description\"})\n",
        "        description = description_meta[\"content\"].strip() if description_meta else \"No Description Found\"\n",
        "\n",
        "        # Extract all visible text from the page\n",
        "        body_text = soup.get_text(separator=\" \")\n",
        "\n",
        "        # Preprocess and clean the body text\n",
        "        cleaned_body_text = preprocess_text(body_text)\n",
        "\n",
        "        # Extract key terms from the cleaned text using TF-IDF\n",
        "        key_terms = extract_key_terms(cleaned_body_text)\n",
        "\n",
        "        return {\n",
        "            \"url\": url,\n",
        "            \"title\": title,\n",
        "            \"description\": description,\n",
        "            \"key_terms\": \", \".join(key_terms),  # Key terms joined into a single string\n",
        "            \"body_text\": cleaned_body_text\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"Error scraping {url}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Step 2: Function to clean and preprocess text\n",
        "def preprocess_text(text):\n",
        "    \"\"\"\n",
        "    Cleans text by removing stopwords, punctuation, and digits.\n",
        "\n",
        "    Args:\n",
        "        text (str): Raw text to preprocess.\n",
        "\n",
        "    Returns:\n",
        "        str: Cleaned and processed text.\n",
        "    \"\"\"\n",
        "    # Convert text to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove digits\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "\n",
        "    # Remove punctuation\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "    # Tokenize text into words\n",
        "    words = text.split()\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_words = [word for word in words if word not in stop_words]\n",
        "\n",
        "    # Join the cleaned words back into a single string\n",
        "    return \" \".join(filtered_words)\n",
        "\n",
        "# Step 3: Function to extract key terms using TF-IDF\n",
        "def extract_key_terms(text, top_n=10):\n",
        "    \"\"\"\n",
        "    Extracts top key terms from text using TF-IDF.\n",
        "\n",
        "    Args:\n",
        "        text (str): Cleaned text.\n",
        "        top_n (int): Number of top terms to extract.\n",
        "\n",
        "    Returns:\n",
        "        list: List of key terms.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # TF-IDF requires input as a list of documents\n",
        "        documents = [text]\n",
        "\n",
        "        # Initialize TF-IDF vectorizer\n",
        "        vectorizer = TfidfVectorizer(max_features=top_n)\n",
        "        tfidf_matrix = vectorizer.fit_transform(documents)\n",
        "\n",
        "        # Extract feature names (key terms)\n",
        "        return vectorizer.get_feature_names_out()\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting key terms: {e}\")\n",
        "        return []\n",
        "\n",
        "# Step 4: URLs to scrape\n",
        "urls = [\n",
        "    'https://thatware.co/',\n",
        "    'https://thatware.co/services/',\n",
        "    'https://thatware.co/advanced-seo-services/',\n",
        "    'https://thatware.co/digital-marketing-services/',\n",
        "    'https://thatware.co/business-intelligence-services/',\n",
        "    'https://thatware.co/link-building-services/',\n",
        "    'https://thatware.co/branding-press-release-services/',\n",
        "    'https://thatware.co/conversion-rate-optimization/',\n",
        "    'https://thatware.co/social-media-marketing/',\n",
        "    'https://thatware.co/content-proofreading-services/',\n",
        "    'https://thatware.co/website-design-services/',\n",
        "    'https://thatware.co/web-development-services/',\n",
        "    'https://thatware.co/app-development-services/',\n",
        "    'https://thatware.co/website-maintenance-services/',\n",
        "    'https://thatware.co/bug-testing-services/',\n",
        "    'https://thatware.co/software-development-services/',\n",
        "    'https://thatware.co/competitor-keyword-analysis/'\n",
        "]\n",
        "\n",
        "# Step 5: Scrape each URL and save results\n",
        "scraped_data = [scrape_webpage(url) for url in urls]\n",
        "\n",
        "# Filter out None values (errors)\n",
        "scraped_data = [data for data in scraped_data if data]\n",
        "\n",
        "# Step 6: Save data to CSV\n",
        "df = pd.DataFrame(scraped_data)\n",
        "df.to_csv('scraped_data_with_key_terms.csv', index=False)\n",
        "print(\"Data scraped and saved successfully!\")\n",
        "\n",
        "# Display the first few rows\n",
        "print(df.head(10))\n",
        "\n",
        "\n",
        "from gensim.models import Word2Vec  # For training word embeddings\n",
        "from gensim.utils import simple_preprocess  # For tokenizing and preprocessing text\n",
        "import pandas as pd  # For handling structured data\n",
        "import csv  # For saving the embeddings into a CSV file\n",
        "\n",
        "# Function to train the Word2Vec model\n",
        "def train_word_embeddings(dataframe):\n",
        "    \"\"\"\n",
        "    Trains a Word2Vec model on the cleaned text data from the DataFrame.\n",
        "\n",
        "    Args:\n",
        "        dataframe (pd.DataFrame): The DataFrame containing cleaned body text.\n",
        "\n",
        "    Returns:\n",
        "        Word2Vec: A trained Word2Vec model.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Step 1: Tokenize the body text\n",
        "        # Tokenizing breaks the text into individual words (tokens) while removing punctuation and stopwords.\n",
        "        tokenized_text = dataframe['body_text'].apply(simple_preprocess)\n",
        "\n",
        "        # Step 2: Train the Word2Vec model\n",
        "        model = Word2Vec(\n",
        "            sentences=tokenized_text,  # Tokenized text\n",
        "            vector_size=100,  # 100-dimensional vector for each word\n",
        "            window=5,  # Context window size for capturing relationships\n",
        "            min_count=2,  # Ignore words that appear less than twice\n",
        "            workers=4  # Utilize multiple CPU threads for faster training\n",
        "        )\n",
        "\n",
        "        # Step 3: Save the trained model\n",
        "        model.save('word2vec_model.model')\n",
        "        print(\"Word2Vec model trained and saved successfully.\")\n",
        "\n",
        "        return model\n",
        "    except Exception as e:\n",
        "        print(f\"Error training Word2Vec model: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "# Function to generate a DataFrame with embeddings and similar words\n",
        "def generate_embedding_dataframe(word2vec_model):\n",
        "    \"\"\"\n",
        "    Creates a DataFrame with word embeddings, their similar words, and numerical vectors.\n",
        "\n",
        "    Args:\n",
        "        word2vec_model (Word2Vec): The trained Word2Vec model.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A DataFrame containing words, embeddings, and similar words.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Create a list to store data for all words\n",
        "        data = []\n",
        "\n",
        "        # Iterate through each word in the vocabulary\n",
        "        for word in word2vec_model.wv.index_to_key:\n",
        "            # Retrieve the embedding vector\n",
        "            vector = word2vec_model.wv[word]\n",
        "\n",
        "            # Find top 5 similar words\n",
        "            similar_words = word2vec_model.wv.most_similar(word, topn=5)\n",
        "\n",
        "            # Append data as a dictionary\n",
        "            data.append({\n",
        "                \"Word\": word,\n",
        "                \"Embedding_Vector\": vector.tolist(),\n",
        "                \"Similar_Words\": [f\"{similar[0]} ({similar[1]:.2f})\" for similar in similar_words]\n",
        "            })\n",
        "\n",
        "        # Convert the list into a DataFrame\n",
        "        embedding_df = pd.DataFrame(data)\n",
        "\n",
        "        # Save the DataFrame as a CSV file\n",
        "        embedding_df.to_csv(\"word_embeddings_with_similar_words.csv\", index=False)\n",
        "        print(\"Embedding DataFrame created and saved as 'word_embeddings_with_similar_words.csv'.\")\n",
        "\n",
        "        # Return the DataFrame for further use\n",
        "        return embedding_df\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating embedding DataFrame: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "# Function to display a preview of the embedding DataFrame\n",
        "def preview_embedding_dataframe(dataframe):\n",
        "    \"\"\"\n",
        "    Displays the first few rows of the embedding DataFrame.\n",
        "\n",
        "    Args:\n",
        "        dataframe (pd.DataFrame): The embedding DataFrame.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    print(\"\\nPreview of the Embedding DataFrame:\")\n",
        "    print(dataframe.head())\n",
        "\n",
        "\n",
        "# Main execution\n",
        "# Step 1: Load the scraped data from the CSV file\n",
        "# Ensure the scraped data has a 'body_text' column\n",
        "df = pd.read_csv('scraped_data_with_key_terms.csv')\n",
        "\n",
        "# Step 2: Train the Word2Vec model on the cleaned body text\n",
        "word2vec_model = train_word_embeddings(df)\n",
        "\n",
        "# Step 3: Generate a DataFrame with embeddings and similar words\n",
        "embedding_df = generate_embedding_dataframe(word2vec_model)\n",
        "\n",
        "# Step 4: Preview the created DataFrame\n",
        "if embedding_df is not None:\n",
        "    preview_embedding_dataframe(embedding_df)\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "# **Step 1: Function to Rank URLs by Term Frequency**\n",
        "# Purpose: Rank URLs based on how often a term appears in them. This helps identify the most relevant pages for a term.\n",
        "def rank_urls(term, urls_with_counts, top_n=5):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        term (str): The term being analyzed.\n",
        "        urls_with_counts (list of tuples): URLs with their frequency counts for the term.\n",
        "        top_n (int): Number of top-ranked URLs to return.\n",
        "\n",
        "    Returns:\n",
        "        list: Top N URLs sorted by frequency for the given term.\n",
        "    \"\"\"\n",
        "    return sorted(urls_with_counts, key=lambda x: x[1], reverse=True)[:top_n]\n",
        "\n",
        "# **Step 2: Function to Compute Word Co-occurrences**\n",
        "# Purpose: Find out which words appear near each other (co-occurrences) in the content to capture their relationships.\n",
        "def compute_cooccurrences(terms, content_list, window=5):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        terms (list): List of target terms to analyze.\n",
        "        content_list (list): Text content from the dataset.\n",
        "        window (int): Sliding window size (number of words before and after a term).\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary mapping each term to its co-occurring words and their frequencies.\n",
        "    \"\"\"\n",
        "    cooccurrence_counts = Counter()\n",
        "    for content in content_list:\n",
        "        words = content.split()\n",
        "        for i, word in enumerate(words):\n",
        "            if word in terms:\n",
        "                # Define the window of words around the current term\n",
        "                window_terms = words[max(0, i-window):min(len(words), i+window+1)]\n",
        "                for adjacent_word in window_terms:\n",
        "                    if adjacent_word in terms and adjacent_word != word:\n",
        "                        cooccurrence_counts[(word, adjacent_word)] += 1\n",
        "\n",
        "    # Organize co-occurrences by each term\n",
        "    ranked_cooccurrences = defaultdict(list)\n",
        "    for (term1, term2), count in cooccurrence_counts.items():\n",
        "        ranked_cooccurrences[term1].append((term2, count))\n",
        "    return ranked_cooccurrences\n",
        "\n",
        "# **Step 3: Group Co-occurrences by Category**\n",
        "# Purpose: Organize co-occurrences into predefined categories (e.g., \"technical\", \"business\") for easier interpretation.\n",
        "def group_cooccurrences_by_category(ranked_cooccurrences, categories):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        ranked_cooccurrences (dict): Co-occurrence data for terms.\n",
        "        categories (dict): Mapping of terms to predefined categories.\n",
        "\n",
        "    Returns:\n",
        "        dict: Grouped co-occurrences categorized by type (e.g., \"technical\", \"business\").\n",
        "    \"\"\"\n",
        "    grouped_cooccurrences = defaultdict(lambda: defaultdict(list))\n",
        "    for term, co_occurrences in ranked_cooccurrences.items():\n",
        "        for related_term, count in co_occurrences:\n",
        "            category = categories.get(related_term, 'others')  # Default to 'others' if no category is defined\n",
        "            grouped_cooccurrences[term][category].append((related_term, count))\n",
        "    return grouped_cooccurrences\n",
        "\n",
        "# **Step 4: Map Words to Relevant URLs**\n",
        "# Purpose: Identify which URLs are most relevant for each word based on frequency of occurrence.\n",
        "def map_words_to_urls(terms, content_data, top_n=5):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        terms (list): List of target terms.\n",
        "        content_data (pd.DataFrame): Dataset containing content and URLs.\n",
        "        top_n (int): Number of top URLs to return for each term.\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary mapping terms to their most relevant URLs with frequency counts.\n",
        "    \"\"\"\n",
        "    url_mapping = defaultdict(list)\n",
        "    for _, row in content_data.iterrows():\n",
        "        url = row['url']\n",
        "        body_text = row['body_text'].lower()\n",
        "        for term in terms:\n",
        "            count = body_text.count(term)\n",
        "            if count > 0:\n",
        "                url_mapping[term].append((url, count))\n",
        "    return {term: rank_urls(term, urls, top_n) for term, urls in url_mapping.items()}\n",
        "\n",
        "# **Step 5: Save Results to CSV and DataFrame**\n",
        "# Purpose: Save the combined results (frequency, URLs, co-occurrences) into a CSV file and return a DataFrame.\n",
        "def save_results_to_csv_and_df(terms, url_mapping, grouped_cooccurrences, filename=\"final_query_results.csv\"):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        terms (list): List of target terms.\n",
        "        url_mapping (dict): URLs relevant to each term.\n",
        "        grouped_cooccurrences (dict): Grouped co-occurrence terms by category.\n",
        "        filename (str): Name of the output CSV file.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame containing the final results.\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    for term in terms:\n",
        "        urls = \", \".join([url for url, _ in url_mapping.get(term, [])])\n",
        "        co_occurrences = grouped_cooccurrences.get(term, {})\n",
        "        co_occurrence_summary = \"; \".join(\n",
        "            [f\"{category}: \" + \", \".join([f\"{t[0]} ({t[1]})\" for t in terms]) for category, terms in co_occurrences.items()]\n",
        "        )\n",
        "        frequency = sum([count for _, count in url_mapping.get(term, [])])\n",
        "        results.append({\n",
        "            \"Word\": term,\n",
        "            \"Frequency\": frequency,\n",
        "            \"Relevant URLs\": urls,\n",
        "            \"Co-occurrences (Grouped by Category)\": co_occurrence_summary,\n",
        "        })\n",
        "\n",
        "    # Save to CSV\n",
        "    df = pd.DataFrame(results)\n",
        "    df.to_csv(filename, index=False)\n",
        "    print(f\"Results saved to {filename}\")\n",
        "    return df\n",
        "\n",
        "# **Main Execution**\n",
        "# Purpose: Bring all steps together and generate the final results.\n",
        "if __name__ == \"__main__\":\n",
        "    # Load the required datasets\n",
        "    embedding_df = pd.read_csv('word_embeddings_with_similar_words.csv')  # Contains words and embeddings\n",
        "    content_df = pd.read_csv('scraped_data_with_key_terms.csv')  # Contains web page content and URLs\n",
        "\n",
        "    # Extract all terms and content\n",
        "    all_terms = embedding_df['Word'].tolist()\n",
        "    content_list = content_df['body_text'].fillna(\"\").str.lower().tolist()\n",
        "\n",
        "    # Define categories for grouping terms\n",
        "    predefined_categories = {\n",
        "        \"seo\": \"technical\",\n",
        "        \"marketing\": \"business\",\n",
        "        \"services\": \"business\",\n",
        "        \"digital\": \"technical\",\n",
        "        \"strategy\": \"business\",\n",
        "    }\n",
        "\n",
        "    # Generate mappings and analytics\n",
        "    url_mapping = map_words_to_urls(all_terms, content_df)\n",
        "    ranked_cooccurrences = compute_cooccurrences(all_terms, content_list)\n",
        "    grouped_cooccurrences = group_cooccurrences_by_category(ranked_cooccurrences, predefined_categories)\n",
        "\n",
        "    # Save and display results\n",
        "    final_df = save_results_to_csv_and_df(all_terms, url_mapping, grouped_cooccurrences)\n",
        "    print(\"Preview of Final Results:\")\n",
        "    print(final_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8Lz9nk1SZGI",
        "outputId": "c49999e5-4a6a-4fa8-a51c-a2afd29489e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data scraped and saved successfully!\n",
            "                                                 url  \\\n",
            "0                               https://thatware.co/   \n",
            "1                      https://thatware.co/services/   \n",
            "2         https://thatware.co/advanced-seo-services/   \n",
            "3    https://thatware.co/digital-marketing-services/   \n",
            "4  https://thatware.co/business-intelligence-serv...   \n",
            "5        https://thatware.co/link-building-services/   \n",
            "6  https://thatware.co/branding-press-release-ser...   \n",
            "7  https://thatware.co/conversion-rate-optimization/   \n",
            "8        https://thatware.co/social-media-marketing/   \n",
            "9  https://thatware.co/content-proofreading-servi...   \n",
            "\n",
            "                                               title  \\\n",
            "0  THATWARE® - Revolutionizing SEO with Hyper-Int...   \n",
            "1  Digital Marketing Services by Thatware - Top R...   \n",
            "2  Advanced SEO Services - Professional SEO Agenc...   \n",
            "3  Digital Marketing Services - Advanced Digital ...   \n",
            "4  Business Intelligence Services - Competitive A...   \n",
            "5  Link Building Services - Off Page SEO Agency -...   \n",
            "6  PPC Paid Marketing Services Agency -Branding |...   \n",
            "7  Conversion Rate Optimization (CRO) Services - ...   \n",
            "8  Social Media Marketing Agency- SMO and SMM Ser...   \n",
            "9  Content Proofreading Services | Hire Content P...   \n",
            "\n",
            "                                         description  \\\n",
            "0  THATWARE® is the world's first SEO agency to s...   \n",
            "1  Watch our exclusive digital marketing services...   \n",
            "2  Now you can enjoy advanced seo services for yo...   \n",
            "3  Thatware provides exclusive digital marketing ...   \n",
            "4  Get the exclusive benefits by tapping into the...   \n",
            "5  Thatware provides a wide range of strategies f...   \n",
            "6  Try out the exclusive PPC media buying service...   \n",
            "7  Improve your sales funnel today with Thatware'...   \n",
            "8  Thatware provides exclusive social media marke...   \n",
            "9  Thatware is recognized as the leading agency f...   \n",
            "\n",
            "                                           key_terms  \\\n",
            "0  advanced, ai, company, content, development, g...   \n",
            "1  advanced, ai, company, content, development, d...   \n",
            "2  advanced, audit, business, digital, implementa...   \n",
            "3  advanced, business, content, digital, marketin...   \n",
            "4  analysis, business, competitor, data, intellig...   \n",
            "5  advanced, backlinks, building, content, link, ...   \n",
            "6  agency, branding, marketing, online, ppc, pr, ...   \n",
            "7  conversion, help, make, optimization, page, ra...   \n",
            "8  brand, company, content, help, marketing, medi...   \n",
            "9  content, editing, proofreading, quality, seo, ...   \n",
            "\n",
            "                                           body_text  \n",
            "0  thatware® revolutionizing seo hyperintelligenc...  \n",
            "1  digital marketing services thatware top rated ...  \n",
            "2  advanced seo services professional seo agency ...  \n",
            "3  digital marketing services advanced digital co...  \n",
            "4  business intelligence services competitive ana...  \n",
            "5  link building services page seo agency thatwar...  \n",
            "6  ppc paid marketing services agency branding ad...  \n",
            "7  conversion rate optimization cro services cro ...  \n",
            "8  social media marketing agency smo smm services...  \n",
            "9  content proofreading services hire content pro...  \n",
            "Word2Vec model trained and saved successfully.\n",
            "Embedding DataFrame created and saved as 'word_embeddings_with_similar_words.csv'.\n",
            "\n",
            "Preview of the Embedding DataFrame:\n",
            "        Word                                   Embedding_Vector  \\\n",
            "0        seo  [-0.6700692176818848, 0.6944795250892639, 0.56...   \n",
            "1   services  [-0.570732057094574, 0.517040491104126, 0.4251...   \n",
            "2  marketing  [-0.609894871711731, 0.7633475065231323, 0.498...   \n",
            "3    website  [-0.6735963225364685, 0.8285033106803894, 0.52...   \n",
            "4   business  [-0.7044728994369507, 0.8841999769210815, 0.55...   \n",
            "\n",
            "                                       Similar_Words  \n",
            "0  [israel (0.99), europe (0.99), noida (0.99), g...  \n",
            "1  [hyderabad (0.99), kolkata (0.99), israel (0.9...  \n",
            "2  [digital (1.00), link (1.00), one (1.00), stra...  \n",
            "3  [process (1.00), application (1.00), test (1.0...  \n",
            "4  [online (1.00), strategies (1.00), help (1.00)...  \n",
            "Results saved to final_query_results.csv\n",
            "Preview of Final Results:\n",
            "        Word  Frequency                                      Relevant URLs  \\\n",
            "0        seo        732  https://thatware.co/advanced-seo-services/, ht...   \n",
            "1   services        419  https://thatware.co/content-proofreading-servi...   \n",
            "2  marketing        289  https://thatware.co/digital-marketing-services...   \n",
            "3    website        310  https://thatware.co/website-design-services/, ...   \n",
            "4   business        252  https://thatware.co/advanced-seo-services/, ht...   \n",
            "\n",
            "                Co-occurrences (Grouped by Category)  \n",
            "0  others: revolutionizing (3), advanced (303), l...  \n",
            "1  others: revolutionizing (1), advanced (119), m...  \n",
            "2  business: services (97), strategy (44); others...  \n",
            "3  others: consulting (17), aws (34), managed (18...  \n",
            "4  others: link (20), building (27), fully (35), ...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# **Explanation of the Output**\n",
        "\n",
        "This output is the result of running the **Word Embeddings Query Expansion Model**. The goal of this model is to analyze your website's content and extract actionable insights for improving search engine optimization (SEO) and user engagement.\n",
        "\n",
        "Here is a breakdown of each column in the output:\n",
        "\n",
        "---\n",
        "\n",
        "#### **1. Word**\n",
        "- **What it means:**\n",
        "  - These are the keywords or terms that are frequently used in your website content. Examples include \"seo,\" \"services,\" \"marketing,\" \"website,\" and \"business.\"\n",
        "- **Use case:**\n",
        "  - These words represent the main topics your website focuses on. For example, \"seo\" suggests your site is about search engine optimization, while \"marketing\" indicates a broader focus on online marketing.\n",
        "- **Action as a website owner:**\n",
        "  - Focus on optimizing these keywords further in your content to ensure they match what users are searching for on Google. For example, ensure \"seo\" is part of your headers, meta descriptions, and blog titles.\n",
        "\n",
        "---\n",
        "\n",
        "#### **2. Frequency**\n",
        "- **What it means:**\n",
        "  - This shows how many times each word appears across your website. For example:\n",
        "    - \"seo\" appears **732 times**.\n",
        "    - \"services\" appears **419 times**.\n",
        "    - \"marketing\" appears **289 times**.\n",
        "- **Use case:**\n",
        "  - Frequency gives you an idea of how much emphasis your site places on specific topics. A higher frequency indicates that the topic is a core focus of your website.\n",
        "- **Action as a website owner:**\n",
        "  - Balance the frequency of keywords to avoid overuse (keyword stuffing) or underuse. For example:\n",
        "    - If \"seo\" appears too frequently compared to other terms, it might look unnatural to search engines.\n",
        "    - Add more instances of underused but relevant terms like \"marketing\" or \"business\" to diversify your content.\n",
        "\n",
        "---\n",
        "\n",
        "#### **3. Relevant URLs**\n",
        "- **What it means:**\n",
        "  - These are the specific pages on your website where the keyword is most frequently used. For example:\n",
        "    - For \"seo,\" relevant URLs include `https://thatware.co/advanced-seo-services/`.\n",
        "    - For \"services,\" relevant URLs include `https://thatware.co/content-proofreading-services/`.\n",
        "- **Use case:**\n",
        "  - This tells you which pages are performing well for specific keywords. It helps you identify the focus of each page.\n",
        "- **Action as a website owner:**\n",
        "  - Optimize the relevant URLs further by:\n",
        "    - Adding meta descriptions and headers that align with the keyword.\n",
        "    - Ensuring these pages load quickly and have engaging content to retain visitors.\n",
        "    - Internally linking these pages with other relevant content to improve their authority.\n",
        "\n",
        "---\n",
        "\n",
        "#### **4. Co-occurrences (Grouped by Category)**\n",
        "- **What it means:**\n",
        "  - This column lists words that frequently appear alongside the primary word in the same context. They are grouped by categories, such as \"business\" or \"others.\" For example:\n",
        "    - For \"seo,\" co-occurrences include:\n",
        "      - \"advanced\" (303 times),\n",
        "      - \"link\" (125 times), and\n",
        "      - \"services\" (1893 times).\n",
        "    - For \"marketing,\" co-occurrences include:\n",
        "      - \"strategy\" (44 times) under \"business.\"\n",
        "- **Use case:**\n",
        "  - Co-occurrences reveal related concepts and terms that users might also search for. This helps you create content that matches user intent and answers more questions.\n",
        "- **Action as a website owner:**\n",
        "  - Use co-occurring terms to create new content. For example:\n",
        "    - If \"seo\" co-occurs with \"advanced,\" write a blog titled \"Advanced SEO Techniques for 2024.\"\n",
        "    - If \"marketing\" co-occurs with \"strategy,\" create a guide called \"Marketing Strategies for Small Businesses.\"\n",
        "\n",
        "---\n",
        "\n",
        "### What Steps to Take After Getting This Output\n",
        "\n",
        "Based on the insights from the output, here’s a step-by-step guide to grow your website:\n",
        "\n",
        "#### **1. Optimize Existing Pages**\n",
        "- Review the \"Relevant URLs\" for each keyword and ensure:\n",
        "  - The page has a clear focus on the keyword (e.g., \"seo\").\n",
        "  - The content is well-written and informative.\n",
        "  - The page includes subheadings, images, and internal links to enhance user experience.\n",
        "\n",
        "#### **2. Diversify Content with Related Terms**\n",
        "- Use the \"Co-occurrences\" column to identify related terms and create content around them. For example:\n",
        "  - If \"seo\" co-occurs with \"link building,\" write a blog post like \"How Link Building Enhances SEO.\"\n",
        "  - If \"marketing\" co-occurs with \"strategy,\" create a YouTube video about marketing strategies.\n",
        "\n",
        "#### **3. Balance Keyword Frequency**\n",
        "- Avoid overusing high-frequency keywords like \"seo.\" Instead:\n",
        "  - Spread them naturally across different pages.\n",
        "  - Add variations of the keyword, such as \"search engine optimization.\"\n",
        "\n",
        "#### **4. Improve On-Page SEO**\n",
        "- For the URLs listed in the output, improve:\n",
        "  - **Title tags**: Include the keyword naturally in the title.\n",
        "  - **Meta descriptions**: Write a compelling summary using the keyword to improve click-through rates.\n",
        "  - **Headers (H1, H2)**: Use the keyword in at least one header on the page.\n",
        "\n",
        "#### **5. Focus on User Intent**\n",
        "- From the keywords and co-occurrences, identify what users might be looking for. For example:\n",
        "  - Users searching for \"seo\" might want guides or services.\n",
        "  - Create content or landing pages that directly answer user needs.\n",
        "\n",
        "#### **6. Track and Update Content**\n",
        "- Use tools like Google Analytics or Google Search Console to monitor:\n",
        "  - Which keywords are bringing traffic.\n",
        "  - Whether your rankings are improving after implementing changes.\n",
        "\n",
        "---\n",
        "\n",
        "### Summary of What This Output Means\n",
        "\n",
        "1. **\"Word\" Column**: Tells you the main focus areas of your website.\n",
        "2. **\"Frequency\" Column**: Shows how often each keyword is used, helping you balance content.\n",
        "3. **\"Relevant URLs\" Column**: Identifies which pages are ranking or associated with each keyword.\n",
        "4. **\"Co-occurrences\" Column**: Reveals related terms, helping you expand your content and improve SEO.\n",
        "\n",
        "By understanding and using these insights, one can improve his website’s SEO, attract more visitors, and better meet user expectations.\n"
      ],
      "metadata": {
        "id": "NjN7kM0AlQsR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# **What the Output Represents**\n",
        "The output provides insights into the keywords used on your website, their frequency, related URLs, and co-occurring terms grouped into categories. This data helps you optimize your website's content, improve its visibility on search engines, and enhance user experience.\n",
        "\n",
        "Let’s break it down:\n",
        "\n",
        "---\n",
        "#### **1. Expanded Keyword Targeting**\n",
        "- **How It Helps:**  \n",
        "  The \"Word\" column lists the main terms (like \"seo,\" \"services,\" \"marketing\") that your website is optimized for or frequently uses. This is a clear map of your website’s focus areas.\n",
        "- **Actions to Take:**\n",
        "  - Use this information to refine your **SEO strategy.** For example:\n",
        "    - If \"seo\" is already dominant (732 mentions), ensure related terms like \"digital marketing\" or \"website\" are also emphasized to capture a broader audience.\n",
        "  - Expand content on underrepresented but relevant terms like \"business\" or \"marketing\" to attract new visitors.\n",
        "\n",
        "---\n",
        "\n",
        "#### **2. Keyword Frequency Analysis**\n",
        "- **How It Helps:**  \n",
        "  The \"Frequency\" column shows how often each word appears. This helps you balance your content for better search engine optimization.\n",
        "- **Actions to Take:**\n",
        "  - Avoid **keyword stuffing** for frequently used terms like \"seo.\" Overusing a term can result in penalties from search engines like Google.\n",
        "  - Focus on underused keywords with high potential (e.g., \"marketing\" with 289 mentions). Add blogs, service pages, or case studies targeting these terms.\n",
        "\n",
        "---\n",
        "\n",
        "#### **3. Relevant URLs**\n",
        "- **How It Helps:**  \n",
        "  This column shows the pages where a particular term is most relevant. For example:\n",
        "  - The term \"seo\" is linked to pages like `https://thatware.co/advanced-seo-services/`.\n",
        "  - This identifies which pages are performing well for specific terms.\n",
        "- **Actions to Take:**\n",
        "  - **Optimize these pages further:**  \n",
        "    - Add meta descriptions with the keyword.\n",
        "    - Use the keyword naturally in headings, subheadings, and image alt text.\n",
        "    - Ensure the page loads quickly and has engaging content.\n",
        "  - **Promote these pages:**  \n",
        "    - Share them on social media or include them in email marketing campaigns to drive more traffic.\n",
        "\n",
        "---\n",
        "\n",
        "#### **4. Co-occurrences (Grouped by Category)**\n",
        "- **How It Helps:**  \n",
        "  Co-occurrences show which terms are frequently mentioned together, revealing related concepts. For instance:\n",
        "  - \"seo\" often co-occurs with \"advanced\" (303 times) and \"services\" (1893 times).\n",
        "  - This suggests that users looking for \"seo\" might also be interested in \"advanced seo services.\"\n",
        "- **Actions to Take:**\n",
        "  - Use co-occurring terms to create **new, targeted content.** For example:\n",
        "    - Write a blog on \"Advanced SEO Services for Small Businesses.\"\n",
        "    - Create a guide like \"Comprehensive SEO Strategies for 2024.\"\n",
        "  - **Improve internal linking** by connecting pages that feature co-occurring terms. For example, link a page about \"seo\" to one about \"services.\"\n",
        "\n",
        "---\n",
        "\n",
        "### **Overall Benefits of This Output**\n",
        "\n",
        "#### **1. Enhanced Content Strategy**\n",
        "- **How It Helps:**\n",
        "  - The output identifies content gaps and opportunities. For instance, if \"business\" is mentioned less frequently, you can focus on creating more business-oriented content.\n",
        "- **Actions to Take:**\n",
        "  - Analyze which terms have low frequency but high potential. Write blogs, case studies, or service pages targeting those terms.\n",
        "\n",
        "#### **2. Improved SEO and Search Rankings**\n",
        "- **How It Helps:**\n",
        "  - By balancing keyword usage and optimizing pages based on relevance, your website can rank higher on Google.\n",
        "- **Actions to Take:**\n",
        "  - Update meta descriptions, title tags, and page content for better alignment with high-frequency terms.\n",
        "\n",
        "#### **3. Better User Experience**\n",
        "- **How It Helps:**\n",
        "  - Users can find relevant content more easily when your site is optimized for expanded queries.\n",
        "- **Actions to Take:**\n",
        "  - Use co-occurrence data to anticipate what users want. If \"seo\" co-occurs with \"link building,\" create a blog on how link building enhances SEO.\n",
        "\n",
        "#### **4. Increased Engagement and Traffic**\n",
        "- **How It Helps:**\n",
        "  - Optimized pages attract more visitors and keep them engaged longer, reducing bounce rates.\n",
        "- **Actions to Take:**\n",
        "  - Promote top-performing pages with high-frequency terms through social media, newsletters, or ads.\n",
        "\n",
        "#### **5. Competitive Advantage**\n",
        "- **How It Helps:**\n",
        "  - The model ensures you cover a wide range of related keywords, giving you an edge over competitors targeting only basic terms.\n",
        "- **Actions to Take:**\n",
        "  - Regularly analyze the output to adapt to changing trends. If \"marketing\" becomes a high-demand term, prioritize it in your content strategy.\n",
        "\n",
        "---\n",
        "\n",
        "### **Key Steps for Website Growth After Getting This Output**\n",
        "\n",
        "1. **Content Optimization**\n",
        "   - Add more content targeting underrepresented but important terms like \"business.\"\n",
        "   - Use the co-occurrence data to align your content with user intent.\n",
        "\n",
        "2. **SEO Enhancements**\n",
        "   - Balance keyword frequency across your site.\n",
        "   - Improve metadata for the URLs associated with high-frequency terms.\n",
        "\n",
        "3. **New Content Creation**\n",
        "   - Write blogs or create videos for related terms from the co-occurrence data.\n",
        "   - Examples:\n",
        "     - \"10 Advanced SEO Techniques to Improve Rankings\"\n",
        "     - \"How to Choose the Right Marketing Strategy for Your Business\"\n",
        "\n",
        "4. **Promote Key Pages**\n",
        "   - Use the \"Relevant URLs\" data to identify high-value pages.\n",
        "   - Share these pages via social media, newsletters, and partnerships.\n",
        "\n",
        "5. **Track Performance**\n",
        "   - Use tools like Google Analytics to monitor:\n",
        "     - Traffic to pages listed in \"Relevant URLs.\"\n",
        "     - Engagement rates for new content targeting expanded queries.\n",
        "\n",
        "---\n",
        "\n",
        "### **Conclusion**\n",
        "\n",
        "This output from the Word Embeddings Query Expansion Model provides a **blueprint** for improving your website. It identifies which keywords are driving your content, which pages need optimization, and how to create content aligned with user intent.\n",
        "\n"
      ],
      "metadata": {
        "id": "FeKEyw0YpKqp"
      }
    }
  ]
}