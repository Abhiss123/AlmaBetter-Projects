{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMQ/LtF4D3QHY13qYGXH1DM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abhiss123/AlmaBetter-Projects/blob/main/A_Simulated_Annealing_Model_for_SEO_and_Advanced_Website_Performance_Optimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Project Name: A Simulated Annealing Model for SEO and Advanced Website Performance Optimization\n",
        "\n",
        "**Purpose of the Project:**\n",
        "\n",
        "* The purpose of this project is to develop a sophisticated optimization model based on **Simulated Annealing** to enhance the **SEO** and overall performance of a website. By applying this advanced algorithm, the project aims to find the best balance between **page load times, content structure, and user experience**, which are critical factors for improving search engine rankings and website efficiency.\n",
        "\n",
        "**The model focuses on:**\n",
        "\n",
        "*  **Improving SEO metrics** by optimizing content length and keyword placement to enhance visibility in search engine results.\n",
        "\n",
        "*  **Boosting website performance** by minimizing page response times, which positively impacts user engagement and search engine ranking algorithms like Google’s Page Experience update.\n",
        "\n",
        "*  **Providing a data-driven**, iterative approach to website optimization, where different solutions are tested to identify the optimal configuration for the website's structure and content delivery.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QvrIsb8n0GCV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What is Simulated Annealing?\n",
        "\n",
        "*  **Simulated Annealing (SA)** is an optimization technique inspired by a process in **metallurgy called \"annealing,\"** where metals are slowly cooled to remove defects and reach a stable state. Similarly, in optimization, **SA is used to solve complex problems** by finding the **best possible solution (global optimum)** among many possible solutions. It works by starting with a solution and slowly improving it, much like how a metal cools and settles into a stable form.\n",
        "\n",
        "**How Does SA Work in Simple Terms?**\n",
        "\n",
        "Imagine you’re looking for the best route to visit multiple cities. You can try many different routes, but finding the best one quickly can be hard because there are so many options. Simulated Annealing tries random routes, accepts some that are good, but also keeps testing other possibilities. Over time, it focuses on better and better routes until it finds one that is likely the best.\n",
        "\n",
        "\n",
        "# Real-Life Use Cases of Simulated Annealing:\n",
        "\n",
        "*  **Scheduling Problems:** SA is often used to find the best way to schedule tasks or resources. For example, airline companies use it to schedule flights, ensuring that planes, crew, and passengers are all in the right place at the right time.\n",
        "\n",
        "*  **Traveling Salesman Problem:** This classic problem involves finding the shortest path to visit a set of cities. Simulated Annealing is used to approximate the best route.\n",
        "\n",
        "*  **Network Optimization:** SA helps in designing networks (like telecommunications or logistics networks) to ensure that data or goods move efficiently.\n",
        "\n",
        "*  **Image Processing:** It’s used in image recognition and computer vision to help computers understand patterns in images.\n",
        "\n",
        "*  **Machine Learning:** SA can be used to fine-tune machine learning algorithms, helping them perform better.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "37UpkRtO16Xd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simulated Annealing in SEO Strategies\n",
        "\n",
        "In **SEO (Search Engine Optimization),** the goal is to find the best strategy for improving a website's ranking on search engines like Google. The **SA algorithm can be used to try different strategies** (e.g., **keyword placements, backlink structures**) and find the most effective combination to rank higher. Since SEO has many factors (**keywords, content length, page speed**, etc.), SA helps by **testing different combinations** and settling on the best approach over time.\n",
        "\n",
        "To run **Simulated Annealing for SEO purposes**, it depends on what data you’re optimizing. If you're **optimizing on-page content, like keywords or meta descriptions**, the **SA algorithm** might work with **CSV files** where the data (like **keyword statistics or ranking metrics) is stored**. If you’re analyzing the **structure of a website or its performance**, the algorithm might need to **process URLs, accessing the page content or metadata directly**.\n",
        "\n",
        "**For example:**\n",
        "\n",
        "*  If the goal is to **optimize keywords**, you might start with a **CSV file listing different keywords, their current rankings**, and other metrics. The algorithm would use this data to try various combinations and find the best one.\n",
        "\n",
        "*  If you're optimizing the **website's technical SEO** (like **page speed, structure**, etc.), the algorithm might need **URLs to access the pages and analyze their content and structure.**\n"
      ],
      "metadata": {
        "id": "05m1EdKW3L0f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Prioritizing Key Website Pages for SEO Optimization Using Simulated Annealing\n",
        "\n",
        "When using **Simulated Annealing (SA)** to optimize technical SEO, it’s important to **select the right pages from the website for analysis**. Since there are **many different types of pages** (**home page, service pages, blog posts**, etc.), you should focus on the pages that are most critical to SEO performance.\n",
        "\n",
        "**Here's a breakdown of the kinds of URLs you should consider:**\n",
        "\n",
        "**1. Core Pages (Main Website Pages)**\n",
        "\n",
        "These are the most important pages of your website that represent your brand, services, and key offerings. They often drive the most traffic and should be optimized thoroughly. The SA model should analyze:\n",
        "\n",
        "*  **Home Page:** The main page that introduces the website.\n",
        "\n",
        "*  **About Us Page:** This page usually includes essential information about the company, which helps with authority and trust signals.\n",
        "\n",
        "*  **Services Pages:** Pages that detail the specific services provided by Website. These are often optimized for targeted keywords that align with user search intent.\n",
        "\n",
        "* **Contact Page:** Optimizing for quick loading and ease of use can help user experience, which is a ranking factor.\n",
        "\n",
        "**2. Blog Posts (Content Pages)**\n",
        "\n",
        "If Website publishes blog posts about **SEO, AI,** or other relevant topics, these pages are important for content SEO. The blogs target specific keywords and serve to rank for informational queries. Simulated Annealing can help identify the best **internal linking structure and keyword optimization strategies.** Prioritize URLs for:\n",
        "\n",
        "*  **Top-performing Blog Posts:** Posts that already rank well or bring significant traffic. These can be further optimized for content, speed, or structure.\n",
        "\n",
        "*  **New or Poorly Performing Blogs:** These are pages that could benefit from keyword improvements or better technical optimization.\n",
        "\n",
        "**3. Landing Pages**\n",
        "\n",
        "These are pages built for specific campaigns or marketing efforts and are key for conversions. Simulated Annealing can help you find the best optimization strategies (like page speed, content layout, or meta tags) for:\n",
        "\n",
        "*  **Service-specific Landing Pages:** These are often focused on driving leads for specific services.\n",
        "\n",
        "*  **Location-based Pages:** If Website offers services in different locations, these pages are important for local SEO.\n",
        "\n",
        "**4. High Traffic or Priority Pages**\n",
        "\n",
        "Any pages that consistently bring in **high traffic** or are seen as high-priority for the business (based on goals like lead generation, sales, etc.) should also be included. These can be **identified via tools like Google Analytics or Search Console.**\n",
        "\n",
        "**5. Slow-loading Pages**\n",
        "\n",
        "If you have pages with **slow load times**, provide their **URLs** to the **Simulated Annealing model.** Improving the performance of these pages can boost rankings, as page speed is an important SEO factor.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rFSvsdBu4Urs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests  # Import the requests library to make HTTP requests\n",
        "\n",
        "# Function to fetch content length and response time for multiple URLs\n",
        "def get_page_info_for_multiple_urls(urls):\n",
        "    \"\"\"\n",
        "    This function takes a list of URLs, fetches their content,\n",
        "    and returns both the response time and content length for each URL.\n",
        "\n",
        "    urls: list of strings, the URLs of the web pages to analyze\n",
        "    return: dictionary where the key is the URL, and the value is another dictionary with response time and content length\n",
        "    \"\"\"\n",
        "    results = {}  # Initialize an empty dictionary to store results for each URL\n",
        "\n",
        "    for url in urls:  # Loop through each URL in the list\n",
        "        try:\n",
        "            response = requests.get(url)  # Make a request to fetch the web page content\n",
        "            page_info = {\n",
        "                'response_time': response.elapsed.total_seconds(),  # Time taken to fetch the page (in seconds)\n",
        "                'content_length': len(response.content)  # Length of the content (size of the page in bytes)\n",
        "            }\n",
        "            results[url] = page_info  # Add the fetched data to the results dictionary\n",
        "        except Exception as e:\n",
        "            results[url] = {'error': str(e)}  # Handle any errors by recording the error message for that URL\n",
        "\n",
        "    return results  # Return the dictionary containing response time and content length for each URL\n",
        "\n",
        "# List of URLs you want to optimize for SEO (core pages of the website)\n",
        "urls = [\n",
        "    'https://thatware.co/',  # Home page\n",
        "    'https://thatware.co/services/',  # Services page\n",
        "    'https://thatware.co/why-ai/',  # AI explanation page\n",
        "    'https://thatware.co/contact-us/'  # Contact us page\n",
        "]\n",
        "\n",
        "# Call the function and print the results\n",
        "results = get_page_info_for_multiple_urls(urls)\n",
        "for url, data in results.items():\n",
        "    print(f\"URL: {url}, Data: {data}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iiHVcQD_KOx",
        "outputId": "1415dd11-e60a-4d7d-9ed8-24312f684abd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "URL: https://thatware.co/, Data: {'response_time': 0.118873, 'content_length': 131335}\n",
            "URL: https://thatware.co/services/, Data: {'response_time': 0.073748, 'content_length': 193006}\n",
            "URL: https://thatware.co/why-ai/, Data: {'response_time': 0.075198, 'content_length': 175143}\n",
            "URL: https://thatware.co/contact-us/, Data: {'response_time': 0.076085, 'content_length': 130614}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explanation of Each Step:\n",
        "\n",
        "**1. import requests:**\n",
        "\n",
        "The requests library is imported to handle HTTP requests. This allows the function to fetch the content from the web pages provided in the URLs.\n",
        "\n",
        "**2. def get_page_info_for_multiple_urls(urls)::**\n",
        "\n",
        "This is the function definition that accepts a list of URLs as input and returns their response time and content length.\n",
        "\n",
        "**3. results = {}:**\n",
        "\n",
        "An empty dictionary is initialized to store the response time and content length for each URL.\n",
        "\n",
        "**4. for url in urls::**\n",
        "\n",
        "This loop goes through each URL in the list of URLs, allowing the function to make requests one by one.\n",
        "\n",
        "**5. response = requests.get(url):**\n",
        "\n",
        "Makes an HTTP request to the URL. If the page is accessible, the response object will contain details like the content and how long the server took to respond.\n",
        "\n",
        "**6. 'response_time': response.elapsed.total_seconds():**\n",
        "\n",
        "This calculates the response time (how fast the server responded) in seconds using elapsed.total_seconds().\n",
        "\n",
        "**7.  'content_length': len(response.content):**\n",
        "\n",
        "This returns the size of the content on the web page in bytes. The len() function calculates how many bytes of data the response contains, giving you an idea of the page’s size.\n",
        "\n",
        "**8. results[url] = page_info:**\n",
        "\n",
        "This step stores the response time and content length for each URL inside the results dictionary, using the URL as the key and the fetched data as the value.\n",
        "\n",
        "**9. except Exception as e::**\n",
        "\n",
        "If something goes wrong during the request (like the URL being unreachable), the error is caught, and an error message is saved for that URL.\n",
        "\n",
        "**10. return results:**\n",
        "\n",
        "After looping through all the URLs, the function returns the results dictionary, which contains the response time and content length for each URL.\n",
        "\n",
        "**11. results = get_page_info_for_multiple_urls(urls):**\n",
        "\n",
        "This calls the function with the list of URLs and stores the returned data in the results variable.\n",
        "\n",
        "**12. for url, data in results.items():**\n",
        "\n",
        "This loop prints the response time and content length for each URL, displaying the results in an easily readable format.\n",
        "\n",
        "\n",
        "# What the Output Will Look Like:\n",
        "\n",
        "            URL: https://thatware.co/, Data: {'response_time': 0.105, 'content_length': 131169}\n",
        "            URL: https://thatware.co/services/, Data: {'response_time': 0.072, 'content_length': 193006}\n",
        "            URL: https://thatware.co/why-ai/, Data: {'response_time': 0.221, 'content_length': 175143}\n",
        "            URL: https://thatware.co/contact-us/, Data: {'response_time': 0.257, 'content_length': 130614}\n",
        "\n"
      ],
      "metadata": {
        "id": "6cVfYIZa_JDt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initial solution (In Simulated Annealing, we need to start with an initial guess)\n",
        "# Here, we will initially collect data (like response time, content length) for each URL\n",
        "initial_solution = {}\n",
        "for url in urls:\n",
        "    initial_solution[url] = get_page_info(url)\n",
        "\n",
        "# Display the initial solution, i.e., the data collected from the URLs\n",
        "print(\"Initial Solution (Data Collected from Web Pages):\")\n",
        "for url, data in initial_solution.items():\n",
        "    print(f\"URL: {url}, Data: {data}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eYcV5hiA4lB",
        "outputId": "33772643-eaf0-4e04-d915-52fa3cf57a88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Solution (Data Collected from Web Pages):\n",
            "URL: https://thatware.co/, Data: {'status_code': 200, 'response_time': 0.092613, 'content_length': 131335}\n",
            "URL: https://thatware.co/services/, Data: {'status_code': 200, 'response_time': 0.071826, 'content_length': 193006}\n",
            "URL: https://thatware.co/why-ai/, Data: {'status_code': 200, 'response_time': 0.073382, 'content_length': 175143}\n",
            "URL: https://thatware.co/contact-us/, Data: {'status_code': 200, 'response_time': 0.071876, 'content_length': 130614}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1: Initializing an Empty Dictionary (initial_solution = {})**\n",
        "\n",
        "         initial_solution = {}\n",
        "* This line creates an **empty dictionary called initial_solution**. In **Simulated Annealing**, we need a **starting point (an \"initial guess\")**. This dictionary will hold the initial data collected from the URLs (such as their response times and content lengths).\n",
        "\n",
        "*  A **dictionary** is a data structure that stores **key-value pairs**. Here, the **key will be the URL** and the **value will be the data collected** from that URL (**response time and content length**).\n",
        "\n",
        "**Step 2: Collecting Data from URLs Using a For Loop**\n",
        "\n",
        "    for url in urls:\n",
        "      initial_solution[url] = get_page_info(url)\n",
        "\n",
        "*  **for url in urls::** This is a loop that goes through each URL in the urls list. The list urls contains the web pages you want to analyze, such as the homepage, services page, etc.\n",
        "\n",
        "*  **get_page_info(url):** This function is called for each URL in the loop. It fetches the web page data, such as response time (how long the web page takes to load) and content length (the size of the content on the web page). The function will return a dictionary containing this information.\n",
        "\n",
        "*  **initial_solution[url] = get_page_info(url):**\n",
        "\n",
        "*  For each URL, the function **get_page_info(url)** is executed, and the collected data** (response time, content length)** is stored in the initial_solution dictionary.\n",
        "\n",
        "*  The **URL** is the key in this dictionary, and **the collected data** (from the **get_page_info function)** becomes the value associated with that URL.\n",
        "\n",
        "**For example:**\n",
        "\n",
        "**After this loop, the dictionary might look like this:**\n",
        "\n",
        "      initial_solution = {\n",
        "           'https://thatware.co/': {'response_time': 0.1049, 'content_length': 131169},\n",
        "          'https://thatware.co/services/': {'response_time': 0.0717, 'content_length': 193006},\n",
        "      # other URLs...\n",
        "      }\n",
        "\n",
        "This means the **homepage (https://thatware.co/) took 0.1049 seconds** to load and has a **content size of 131,169 bytes.**\n",
        "\n",
        "**Step 3: Printing the Collected Data (print)**\n",
        "\n",
        "     print(\"Initial Solution (Data Collected from Web Pages):\")\n",
        "\n",
        "*  **This prints a header (\"Initial Solution (Data Collected from Web Pages):\")** to the console so that you know the following output will be the initial data collected from the URLs.\n",
        "\n",
        "**Step 4: Displaying the Collected Data in a Readable Format**\n",
        "\n",
        "        for url, data in initial_solution.items():\n",
        "           print(f\"URL: {url}, Data: {data}\")\n",
        "\n",
        "**for url, data in initial_solution.items()::**\n",
        "\n",
        "* This loop goes through the **initial_solution dictionary** that was created in Step 2.\n",
        "\n",
        "* **url represents each key** (i.e., the URL of the web page), and data represents each value (i.e., the collected response time and content length for that URL).\n",
        "\n",
        "**print(f\"URL: {url}, Data: {data}\"):**\n",
        "\n",
        "*  This prints out each URL and the corresponding data (response time and content length).\n",
        "\n",
        "*  **f\"URL: {url}, Data: {data}\"** is a formatted string that ensures the URL and its data are printed together in a readable format.\n",
        "\n",
        "**For example, the output might look like this:**\n",
        "\n",
        "\n",
        "       Initial Solution (Data Collected from Web Pages):\n",
        "       URL: https://thatware.co/, Data: {'response_time': 0.1049, 'content_length': 131169}\n",
        "       URL: https://thatware.co/services/, Data: {'response_time': 0.0717, 'content_length': 193006}\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CdpMrLw-BSVL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries for handling web requests, random number generation, and mathematical functions\n",
        "import requests  # To make HTTP requests and fetch data from web pages\n",
        "import random    # To generate random numbers and simulate random changes\n",
        "import math      # To perform mathematical operations like exponential calculations\n",
        "\n",
        "# Function to simulate fetching web page details like content and response time\n",
        "def get_page_info(url):\n",
        "    \"\"\"\n",
        "    This function takes a URL as input, fetches its content,\n",
        "    and measures how fast the server responds.\n",
        "\n",
        "    url: string, the web page URL you want to analyze\n",
        "    return: dictionary with the status code (response code) and content of the web page\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = requests.get(url)  # Make a request to the website URL\n",
        "        page_info = {\n",
        "            'status_code': response.status_code,  # Check if the website responded successfully (status 200 means OK)\n",
        "            'response_time': response.elapsed.total_seconds(),  # Measure how long it took to get the page\n",
        "            'content_length': len(response.content)  # The length of the content (size of the page)\n",
        "        }\n",
        "        return page_info  # Return the collected information\n",
        "    except Exception as e:\n",
        "        return {'error': str(e)}  # If something goes wrong, return an error message\n",
        "\n",
        "# List of URLs you want to optimize for SEO (These are the core pages of your website)\n",
        "urls = [\n",
        "    'https://thatware.co/',  # Home page\n",
        "    'https://thatware.co/services/',  # Services page\n",
        "    'https://thatware.co/why-ai/',  # AI explanation page\n",
        "    'https://thatware.co/contact-us/'  # Contact us page\n",
        "]\n",
        "\n",
        "# Initial solution (In Simulated Annealing, we need to start with an initial guess)\n",
        "# Here, we will initially collect data (like response time, content length) for each URL\n",
        "initial_solution = {}\n",
        "for url in urls:\n",
        "    initial_solution[url] = get_page_info(url)\n",
        "\n",
        "# Display the initial solution, i.e., the data collected from the URLs\n",
        "print(\"Initial Solution (Data Collected from Web Pages):\")\n",
        "for url, data in initial_solution.items():\n",
        "    print(f\"URL: {url}, Data: {data}\")\n",
        "\n",
        "# Simulated Annealing algorithm function\n",
        "def simulated_annealing(urls, initial_solution, max_iterations=1000, cooling_rate=0.99):\n",
        "    \"\"\"\n",
        "    This function performs Simulated Annealing optimization on the given URLs.\n",
        "    It tries to find the best solution to minimize the response time and maximize content efficiency.\n",
        "\n",
        "    urls: list of URLs to analyze\n",
        "    initial_solution: dictionary containing the initial data for each URL\n",
        "    max_iterations: number of iterations to try before stopping\n",
        "    cooling_rate: how fast the temperature should drop (influences exploration vs. exploitation)\n",
        "    \"\"\"\n",
        "    current_solution = initial_solution  # Start with the initial solution\n",
        "    current_score = calculate_score(current_solution)  # Calculate how good this initial solution is\n",
        "    best_solution = current_solution  # Store the best solution found\n",
        "    best_score = current_score  # The score of the best solution\n",
        "\n",
        "    temperature = 1.0  # Start with a high temperature (to allow exploration of many solutions)\n",
        "\n",
        "    # Iterate through the optimization process\n",
        "    for iteration in range(max_iterations):\n",
        "        # Simulate a random change to the current solution (perturb the solution slightly)\n",
        "        new_solution = perturb_solution(current_solution)\n",
        "        new_score = calculate_score(new_solution)  # Calculate the score of this new solution\n",
        "\n",
        "        # If the new solution is better, or if it's worse but within the acceptance probability, we accept it\n",
        "        if new_score < current_score or random.uniform(0, 1) < acceptance_probability(current_score, new_score, temperature):\n",
        "            current_solution = new_solution  # Accept the new solution\n",
        "            current_score = new_score  # Update the current score\n",
        "\n",
        "            # If the new solution is the best we've seen, we store it as the best solution\n",
        "            if new_score < best_score:\n",
        "                best_solution = new_solution\n",
        "                best_score = new_score\n",
        "\n",
        "        # Cool down the temperature to reduce the chance of accepting worse solutions\n",
        "        temperature *= cooling_rate\n",
        "\n",
        "        # For demonstration purposes, print the progress every 100 iterations\n",
        "        if iteration % 100 == 0:\n",
        "            print(f\"Iteration {iteration}, Best Score So Far: {best_score}\")\n",
        "\n",
        "    return best_solution\n",
        "\n",
        "# Helper function to calculate the score (how \"good\" a solution is)\n",
        "def calculate_score(solution):\n",
        "    \"\"\"\n",
        "    This function calculates the score of the current solution.\n",
        "    The score will be based on response time (lower is better) and content length (longer pages might be better).\n",
        "\n",
        "    solution: dictionary containing data for each URL\n",
        "    return: numerical score (lower is better)\n",
        "    \"\"\"\n",
        "    score = 0\n",
        "    for url, data in solution.items():\n",
        "        if 'error' in data:\n",
        "            score += 1000  # Penalize if there's an error (high score means worse)\n",
        "        else:\n",
        "            score += data['response_time']  # Minimize response time\n",
        "            score += 0.01 * data['content_length']  # Prefer pages with more content (but less important)\n",
        "    return score\n",
        "\n",
        "# Helper function to simulate a small random change to the solution\n",
        "def perturb_solution(solution):\n",
        "    \"\"\"\n",
        "    This function makes a small random change to the current solution.\n",
        "    It might represent trying a different optimization strategy or setting.\n",
        "\n",
        "    solution: the current solution to modify slightly\n",
        "    return: a new solution with a small random change\n",
        "    \"\"\"\n",
        "    new_solution = solution.copy()  # Make a copy of the current solution\n",
        "    for url in new_solution:\n",
        "        if 'error' not in new_solution[url]:\n",
        "            # Randomly adjust the response time and content length by a small percentage\n",
        "            new_solution[url]['response_time'] *= random.uniform(0.9, 1.1)  # Adjust response time by ±10%\n",
        "            new_solution[url]['content_length'] *= random.uniform(0.95, 1.05)  # Adjust content length by ±5%\n",
        "    return new_solution\n",
        "\n",
        "# Helper function to calculate the acceptance probability of a worse solution\n",
        "def acceptance_probability(current_score, new_score, temperature):\n",
        "    \"\"\"\n",
        "    This function calculates the probability of accepting a worse solution.\n",
        "    It allows the algorithm to explore suboptimal solutions to avoid getting stuck in local optima.\n",
        "\n",
        "    current_score: the score of the current solution\n",
        "    new_score: the score of the new solution\n",
        "    temperature: the current temperature (high temperature means higher probability of accepting worse solutions)\n",
        "    return: probability of accepting the new solution (higher is more likely)\n",
        "    \"\"\"\n",
        "    if new_score < current_score:\n",
        "        return 1.0  # Always accept if the new solution is better\n",
        "    else:\n",
        "        # Use the temperature to determine the probability of accepting a worse solution\n",
        "        return math.exp((current_score - new_score) / temperature)\n",
        "\n",
        "# Run the Simulated Annealing algorithm on the URLs you provided\n",
        "best_solution = simulated_annealing(urls, initial_solution)\n",
        "\n",
        "# Display the final best solution found by Simulated Annealing\n",
        "print(\"Best Solution Found (Optimized Web Page Data):\")\n",
        "for url, data in best_solution.items():\n",
        "    print(f\"URL: {url}, Data: {data}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhyUWiT0fqA1",
        "outputId": "a68479cf-2c44-4961-cf2a-7b9038126b7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Solution (Data Collected from Web Pages):\n",
            "URL: https://thatware.co/, Data: {'status_code': 200, 'response_time': 0.131602, 'content_length': 131335}\n",
            "URL: https://thatware.co/services/, Data: {'status_code': 200, 'response_time': 0.207567, 'content_length': 193006}\n",
            "URL: https://thatware.co/why-ai/, Data: {'status_code': 200, 'response_time': 0.071614, 'content_length': 175143}\n",
            "URL: https://thatware.co/contact-us/, Data: {'status_code': 200, 'response_time': 0.072565, 'content_length': 130614}\n",
            "Iteration 0, Best Score So Far: 6301.463348\n",
            "Iteration 100, Best Score So Far: 6276.499567598134\n",
            "Iteration 200, Best Score So Far: 6276.499567598134\n",
            "Iteration 300, Best Score So Far: 6276.499567598134\n",
            "Iteration 400, Best Score So Far: 6276.499567598134\n",
            "Iteration 500, Best Score So Far: 6276.499567598134\n",
            "Iteration 600, Best Score So Far: 5632.448969300607\n",
            "Iteration 700, Best Score So Far: 5070.497779097348\n",
            "Iteration 800, Best Score So Far: 3884.8178224708467\n",
            "Iteration 900, Best Score So Far: 3884.8178224708467\n",
            "Best Solution Found (Optimized Web Page Data):\n",
            "URL: https://thatware.co/, Data: {'status_code': 200, 'response_time': 0.03386448051612617, 'content_length': 87658.34979386657}\n",
            "URL: https://thatware.co/services/, Data: {'status_code': 200, 'response_time': 0.23553011818374683, 'content_length': 153306.93644208807}\n",
            "URL: https://thatware.co/why-ai/, Data: {'status_code': 200, 'response_time': 0.032520075746828844, 'content_length': 168296.0491219134}\n",
            "URL: https://thatware.co/contact-us/, Data: {'status_code': 200, 'response_time': 0.03234162054658152, 'content_length': 49738.64346876568}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Understanding The Output :\n",
        "\n",
        "**1. Initial Solution (Data Collected from Web Pages)**\n",
        "\n",
        "This is the **data collected before** the **Simulated Annealing model** started optimizing anything. It represents the **current performance of the web pages**, focusing on two main factors:\n",
        "\n",
        "* **Response Time:** How long it takes for the webpage to load (in seconds).\n",
        "\n",
        "* **Content Length:** The size of the content on the page (in bytes). Larger content may take more time to load.\n",
        "\n",
        "**Here’s a breakdown of the data:**\n",
        "\n",
        "**URL: https://thatware.co/**\n",
        "\n",
        "* **Response time: 0.1049 seconds** (about 0.1 second) — The time it takes for the homepage to load.\n",
        "\n",
        "* **Content length: 131,169 bytes** — This is the size of the content on the homepage.\n",
        "\n",
        "**URL: https://thatware.co/services/**\n",
        "\n",
        "* **Response time: 0.0717 seconds** (about 0.07 seconds) — The time it takes for the services page to load.\n",
        "\n",
        "*  **Content length: 193,006 bytes** — This is the size of the content on the services page.\n",
        "\n",
        "**URL: https://thatware.co/why-ai/**\n",
        "\n",
        "*  **Response time: 0.0720 seconds** (about 0.07 seconds) — The time it takes for the AI-related page to load.\n",
        "\n",
        "* **Content length: 175,143 bytes** — This is the size of the content on this page.\n",
        "\n",
        "**URL: https://thatware.co/contact-us/**\n",
        "\n",
        "* **Response time: 0.0718 seconds** (about 0.07 seconds) — The time it takes for the contact page to load.\n",
        "\n",
        "*  **Content length: 130,614 bytes** — This is the size of the content on this page.\n",
        "\n",
        "**What does this initial data mean?**\n",
        "\n",
        "*  **Response Time:** All the response times here are quite fast, under 0.1 seconds, which is good because faster load times improve user experience and SEO. However, further optimization may still be possible.\n",
        "\n",
        "*  **Content Length:** This refers to how much information is on each page. More content can provide rich information for search engines but may also slow down load times if not handled correctly."
      ],
      "metadata": {
        "id": "1jMar_2hr22d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. The Iteration Process:\n",
        "\n",
        "**What is an Iteration?**\n",
        "\n",
        "In simple terms, **an iteration is just one cycle** or step where the program (in this case, **Simulated Annealing**) tries a **new solution** and checks if it’s better than the **current solution**. This process is **repeated many times (iterations)** to improve the results.\n",
        "\n",
        "**What is Happening in Each Iteration?**\n",
        "\n",
        "* In each iteration, the **Simulated Annealing model** is making a **small random change to the current solution** (for example, making the page load faster or reducing the content size slightly).\n",
        "\n",
        "* It **calculates a score** for each new solution. The goal is to **minimize the score,** which represents how good the solution is. A lower score means a better solution (faster load times, appropriate content size).\n",
        "\n",
        "* The **model sometimes even accepts a worse solution (a higher score) to explore all possibilities.** This is part of the strategy to avoid getting stuck in a suboptimal (less than ideal) solution early on.\n",
        "\n",
        "**What Does the Iteration Process Do?**\n",
        "\n",
        "*  **Iteration 0 (Starting Point):** The first time the model tries, it gets a **score of 6299.640505.** This is the **starting point,** and we want to improve it.\n",
        "\n",
        "*  **Iteration 100:** By the **100th cycle,** the model has found a better solution, and the **score drops to** **5955.711670029009.** The model is getting better at optimizing the **page's load time and content.**\n",
        "\n",
        "*  **Iteration 200:** The score improves further to **5943.467704014847,** meaning the page is loading faster and/or the content is better balanced.\n",
        "\n",
        "*  **Iteration 300–900:** By **iteration 400,** the model finds its best solution with a score of **5737.069199592406.** The model keeps trying, **but it can’t find a better solution beyond this point.**\n",
        "\n",
        "**Why Is the Iteration Process Important?**\n",
        "\n",
        "*  The iteration process is how the Simulated Annealing algorithm tests multiple possibilities to find the best possible solution for optimizing a website.\n",
        "*  Each iteration is like experimenting with different ways to speed up the page and adjust the content size.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YnmpTN6qtFJD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Best Solution Found (Optimized Web Page Data)\n",
        "\n",
        "**What Is This Section Saying?**\n",
        "\n",
        "* This part of the output shows the **best solution that the Simulated Annealing model found after running through many iterations**. It tells you what the **ideal response time** and **content length** would be for your website pages if you optimized them.\n",
        "\n",
        "**Let’s Break Down Each Example:**\n",
        "\n",
        "**1. Home Page (https://thatware.co/)**\n",
        "\n",
        "*  **Original Response Time: 0.1049 seconds** (before optimization)\n",
        "\n",
        "* **Optimized Response Time: 0.0576 seconds** (after optimization)\n",
        "\n",
        "*  **Original Content Length: 131,169 bytes** (before optimization)\n",
        "\n",
        "*  **Optimized Content Length: 36,145 bytes** (after optimization)\n",
        "\n",
        "**What does this mean?:** The model suggests that the homepage could load much faster **(from 0.1049 seconds to 0.0576 seconds)** and could reduce its content size **(from 131,169 bytes to 36,145 bytes)**. This would make the homepage faster and potentially improve its SEO ranking.\n",
        "\n",
        "**2. Services Page (https://thatware.co/services/)**\n",
        "\n",
        "* **Original Response Time: 0.0717 seconds**\n",
        "\n",
        "*  **Optimized Response Time: 0.0017 seconds** (incredibly fast)\n",
        "\n",
        "*  **Original Content Length: 193,006 bytes**\n",
        "\n",
        "*  **Optimized Content Length: 72,188 bytes**\n",
        "\n",
        "* **What does this mean?:** The model suggests that the services page could be optimized to **load in just 0.0017 seconds** and reduce the **content to 72,188 bytes.** This would make the page extremely fast, which is beneficial for **SEO and user experience.**\n",
        "\n",
        "**3.  AI Page (https://thatware.co/why-ai/)**\n",
        "\n",
        "*  **Original Response Time: 0.0720 seconds**\n",
        "\n",
        "*  **Optimized Response Time: 0.0063 seconds**\n",
        "\n",
        "*  **Original Content Length: 175,143 bytes**\n",
        "\n",
        "*  **Optimized Content Length: 466,962 bytes** (increased)\n",
        "\n",
        "*  **What does this mean?:** The model suggests that the **AI page can load faster**, but interestingly, it **increased the content length to 466,962 bytes**. This could mean the **page would benefit from more detailed content, possibly improving its ranking for AI-related keywords.**\n",
        "\n",
        "**4.  Contact Us Page (https://thatware.co/contact-us/)**\n",
        "\n",
        "*  **Original Response Time: 0.0718 seconds**\n",
        "\n",
        "*  **Optimized Response Time: 2.8396 seconds (slower)**\n",
        "\n",
        "* **Original Content Length: 130,614 bytes**\n",
        "\n",
        "* **Optimized Content Length: 175,896 bytes** (increased)\n",
        "\n",
        "*  **What does this mean?:** The model suggests that **increasing the content size on this page has made it slower** (which is not ideal). This is a suggestion that more content might be valuable for users, but the **slow load time would need to be addressed.**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "791aDoO6vkIg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What Should Website Owner Do with This Output?\n",
        "\n",
        "Based on the results, here are the steps Thatware can take to improve their **website and SEO performance:**\n",
        "\n",
        "**1. Optimize Home Page:**\n",
        "\n",
        "*  The **homepage** saw significant improvement in both load time and content reduction. This is a big win, as faster load times and lighter content on the homepage can improve **user engagement and SEO rankings.**\n",
        "\n",
        "**2. Maintain Services Page Optimization:**\n",
        "\n",
        "*  The **services page** saw a **dramatic improvement in load time** (almost instant) and a **balanced reduction in content size**. This makes the **page very user-friendly and appealing for search engines**. The client should ensure that the reduced content still effectively describes their services.\n",
        "\n",
        "**3. Review AI Page Content:**\n",
        "\n",
        "*  Although the **AI page became faster**, the **content size increased significantly**. This could mean the page is now **more informative** and can rank better for informational queries related to AI. However, the client should make sure the additional content is well-organized and relevant.\n",
        "\n",
        "**4. Fix Contact Page Load Time:**\n",
        "\n",
        "*  The **contact page became much slower after optimization**, which is undesirable. A **slow contact page can frustrate users and reduce conversion rates.** The client should consider **reducing unnecessary content or compressing the page elements to improve load time.**"
      ],
      "metadata": {
        "id": "iCv3NHr_ycxc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  How Does This Help Websites Business and SEO?\n",
        "\n",
        "*  **Faster Pages Improve SEO:** Google and other search engines prioritize fast-loading pages. By optimizing load times across key pages, Thatware’s website will perform better in search rankings. The faster your website, the better the user experience, and the more likely visitors are to stay, reducing the bounce rate (people leaving the site quickly).\n",
        "\n",
        "*  **Rich Content on Important Pages:** Adding more relevant and informative content to pages like the AI page can help with content SEO, allowing those pages to rank for more keywords and better answer user queries.\n",
        "\n",
        "*  **Balance Between Speed and Content:** Finding the right balance between page speed and rich content is key. For the homepage and services page, speed improvements are excellent. However, the contact page’s slower time should be addressed, as it might negatively affect conversions.\n"
      ],
      "metadata": {
        "id": "KoottUhfzu64"
      }
    }
  ]
}