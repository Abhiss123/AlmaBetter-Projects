{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM6k8NqmAgrdL8Ww8ntzPlD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abhiss123/AlmaBetter-Projects/blob/main/Federated_Learning_for_Personalized_SEO_Recommendations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name:- Federated Learning for Personalized SEO Recommendations**\n",
        "\n",
        "### **Purpose Of The Project:**\n",
        "\n",
        "**Overview of the Project Purpose:**\n",
        "The project \"Federated Learning for Personalized SEO Recommendations\" aims to harness the power of federated learning—a form of decentralized machine learning—to analyze website engagement data and generate personalized recommendations that improve the visibility, engagement, and overall performance of websites in search engine results. This project is designed to benefit website owners, digital marketers, and content strategists by offering actionable insights that are tailored to the specific needs and behaviors of their target audience.\n",
        "\n",
        "**Key Objectives and Benefits:**\n",
        "1. **Personalized Content Recommendations:**\n",
        "   - The project creates tailored suggestions to help website owners optimize their content based on user behavior and engagement data. For example, if a specific webpage has high user engagement but low traffic, the model might recommend promoting that page more widely to attract more visitors.\n",
        "   \n",
        "2. **SEO Insights and Optimization:**\n",
        "   - By analyzing metrics like views, bounce rates, average session durations, and user engagement, the project generates insights on which types of content, keywords, and topics perform best. This helps website owners refine their SEO strategies, improve their ranking in search results, and better serve their target audience.\n",
        "   \n",
        "3. **Enhanced User Experience:**\n",
        "   - The recommendations aim to enhance the overall user experience on a website by suggesting improvements to page structure, content relevance, loading speed, and interactive features based on data-driven insights.\n",
        "\n",
        "**Why Use Federated Learning?**\n",
        "- **Privacy-Preserving Data Analysis:** Unlike traditional models that collect and analyze data on a central server, federated learning works by training models locally on user devices or in separate data silos, ensuring that sensitive user data remains private. This makes it particularly appealing for analyzing user engagement without compromising privacy.\n",
        "- **Improved Accuracy:** By leveraging data from multiple sources without aggregating it into one central location, federated learning can deliver accurate insights while maintaining data security.\n",
        "\n",
        "### How the Project Achieves Its Purpose:\n",
        "The project involves three main parts, each with a specific role in achieving the overall purpose:\n",
        "\n",
        "1. **Part 1 - Data Collection and Cleaning:**\n",
        "   - This step involves scraping relevant content from specified URLs. It collects data such as webpage meta descriptions, keywords, and main text content. The data is then cleaned and standardized for further analysis.\n",
        "   \n",
        "2. **Part 2 - Data Integration and Merging:**\n",
        "   - This step merges the scraped content data with engagement and user interaction data. By standardizing and combining data from multiple sources (e.g., webpage views, user sessions, and bounce rates), the project creates a comprehensive dataset ready for analysis.\n",
        "   \n",
        "3. **Part 3 - Content Recommendation Generation:**\n",
        "   - In the final step, the merged data is analyzed to generate personalized recommendations based on user engagement metrics, views, bounce rates, etc. The generated recommendations provide actionable insights that website owners can use to enhance content quality, optimize SEO, and improve overall engagement.\n"
      ],
      "metadata": {
        "id": "MXjhpVKpXcMi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1. What is Federated Learning (FL) in SEO?**\n",
        "\n",
        "Federated Learning is a method in machine learning where models are trained on data that remains on users’ devices or on local servers, rather than collecting all data in a central location. In SEO (Search Engine Optimization), applying FL means the model learns from data distributed across multiple sources (e.g., users visiting different pages on your website, user interactions with the website’s content, or even from various websites) without needing to centralize or collect this data in one place. This is particularly useful for personalization in SEO, where the goal is to make search results or website content more relevant to each user without compromising their privacy.\n",
        "\n",
        "### **2. How Does Federated Learning Work in SEO?**\n",
        "\n",
        "In traditional SEO, personalization can involve collecting user data (like search queries, clicks, and preferences) and then analyzing it centrally to improve search results and recommendations. Federated Learning changes this by keeping the data on the devices (or on the website servers where it's generated) and only sharing the model’s learned updates, not the actual user data. For example:\n",
        "- **Step 1**: Federated Learning collects insights from different sources, like how visitors interact with a site or what keywords they’re interested in.\n",
        "- **Step 2**: The FL model adjusts based on these insights at each local device or server level.\n",
        "- **Step 3**: Updates (model changes) are sent to a central server, which merges them to improve the main model without seeing any actual user data.\n",
        "\n",
        "### **3. Use Cases for Federated Learning in SEO (Website Context)**\n",
        "\n",
        "In the context of a website, Federated Learning can be used for:\n",
        "- **Personalized Content Recommendations**: Tailoring the articles, products, or resources shown to each user based on their previous interactions, without storing their data on a central server.\n",
        "- **Improved Search Rankings within the Website**: The model can improve how it ranks or recommends content on the website itself based on user behavior (like click-through rates or time spent on each page).\n",
        "- **Predicting User Intent**: By learning from previous user interactions, the model can predict what each visitor is looking for and guide them to relevant content faster.\n",
        "- **Content Optimization**: Understanding which keywords or page types (blogs, product pages, etc.) perform best for different user segments and adjusting site content accordingly, enhancing SEO.\n",
        "\n",
        "### **4. Real-Life Implementations of Federated Learning in SEO**\n",
        "\n",
        "While Federated Learning is relatively new in SEO, it’s being adopted in areas like:\n",
        "- **Personalized Recommendations on News Websites**: Federated models help personalize content based on how users interact with articles, without sharing their reading habits.\n",
        "- **E-commerce Product Recommendations**: Online stores are beginning to use FL for customized product suggestions based on previous interactions, maintaining user privacy.\n",
        "- **Search Engines with Localized Results**: Search engines (e.g., Google’s early experiments with FL) use Federated Learning to improve personalization by learning from device-level interactions.\n",
        "\n",
        "### **5. What Kind of Data Does a Federated Learning Model Need?**\n",
        "\n",
        "For Federated Learning in SEO, the model typically needs:\n",
        "- **User Interaction Data**: Information on clicks, page visits, time spent on different sections, or search queries within the website.\n",
        "- **Content Data**: Information about the content on the site, like keywords, meta tags, and other SEO-related elements.\n",
        "- **Behavioral Data**: How users navigate and interact with different content types (blogs, articles, product pages).\n",
        "  \n",
        "The data can be in various formats, but a **CSV file** with structured data (e.g., columns for URL, keywords, user interaction metrics) often works best. Alternatively, the model can work directly with website content URLs if it has the capability to process the text from these URLs directly.\n",
        "\n",
        "### **6. Do You Need URLs or Just Data in CSV Format?**\n",
        "\n",
        "You have two options:\n",
        "- **URL-based Processing**: If the Federated Learning model can fetch and analyze webpage content directly, then you would only need to provide URLs of your website’s pages. This approach allows the model to process the text and extract keywords and other elements by crawling the page.\n",
        "- **CSV-based Data**: If you already have structured data (like user interaction metrics, page keywords, content categories) in a CSV, you can provide this file. The model will then use this data to learn without needing to access the website directly.\n",
        "\n",
        "For non-technical users, providing structured data in a CSV format is often simpler and more practical than configuring URL-based processing.\n",
        "\n",
        "### 7. How Federated Learning Enhances Personalized Search Results\n",
        "\n",
        "Federated Learning can enhance SEO by personalizing user experiences without collecting personal data. For example, as users interact with the website, the model learns which types of content or keywords are most relevant to different audiences. It can then adjust search result rankings or content recommendations to suit each user’s interests, offering a more tailored experience. Since FL doesn’t need to centralize user data, it’s also a privacy-friendly approach, making it suitable for companies sensitive to data privacy concerns.\n",
        "\n",
        "### 8. Expected Output from Federated Learning in SEO\n",
        "\n",
        "The output from a Federated Learning SEO model generally includes:\n",
        "- **Personalized Content Recommendations**: A list of suggested pages or articles tailored for each user based on past behavior.\n",
        "- **Optimized Internal Search Results**: Improved ranking of pages within the site’s search feature to show more relevant results to individual users.\n",
        "- **SEO Insights**: Analysis on which keywords or content types are performing best, helping website owners adjust their strategy.\n",
        "  \n",
        "In website contexts, this output could take the form of **recommendation lists** or **search result adjustments** on the site itself. For instance, when a visitor searches for \"beginner SEO tips,\" the model might suggest articles related to \"SEO for beginners\" or \"simple SEO hacks\" based on previous interactions.\n",
        "\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "zaERYAWEYPkm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqY_cI3G20h6",
        "outputId": "0cba8587-0395-422e-8325-62c5e131d03c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "\n",
        "#### **Part 1: Web Scraping and Content Extraction**\n",
        "- **Purpose**: This part of the code is responsible for extracting content from specified web pages. It collects meta descriptions, keywords, and main textual content, which will later be analyzed for SEO improvements.\n",
        "- **What It Does**:\n",
        "  - **Import Libraries**: Imports necessary libraries for web scraping (like requests, BeautifulSoup) and text processing.\n",
        "  - **Define `clean_text` Function**: This function cleans the text by removing non-letter characters, converting it to lowercase, and removing common words (stopwords) that do not add much meaning (like \"the\", \"is\").\n",
        "  - **Specify URLs**: A list of URLs to scrape is defined. These URLs point to different web pages related to SEO services.\n",
        "  - **Scrape Content**: For each URL, the code sends a request to fetch the page content. It extracts meta descriptions, keywords (if available), and text from paragraphs and headings.\n",
        "  - **Clean the Content**: The extracted text is cleaned using the `clean_text` function.\n",
        "  - **Save Data**: The scraped data is saved into a CSV file named `final_scraped_webtool_content.csv` for use in later steps.\n",
        "\n"
      ],
      "metadata": {
        "id": "eTKPm00QTU-6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries for web scraping, data processing, and text cleaning\n",
        "import requests  # To send HTTP requests to URLs and fetch web content\n",
        "from bs4 import BeautifulSoup  # For parsing HTML content from webpages\n",
        "import pandas as pd  # For handling data in tabular (spreadsheet-like) format\n",
        "import re  # Regular expressions for text cleaning (e.g., removing unwanted characters)\n",
        "from nltk.corpus import stopwords  # To remove commonly used English words that do not add much meaning\n",
        "import nltk  # Natural Language Toolkit for text processing\n",
        "\n",
        "# Downloading stopwords if they are not already available\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Step 1: Function to clean and process text content\n",
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "    Cleans input text by:\n",
        "    - Removing non-alphabetic characters (e.g., numbers, punctuation)\n",
        "    - Converting text to lowercase\n",
        "    - Removing common English stopwords (e.g., 'and', 'the', etc.)\n",
        "\n",
        "    Args:\n",
        "    - text (str): The text content to clean\n",
        "\n",
        "    Returns:\n",
        "    - str: The cleaned text\n",
        "    \"\"\"\n",
        "    # Using regular expressions to keep only letters and spaces (removes digits, punctuation, etc.)\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    # Converting text to lowercase (ensures uniformity)\n",
        "    text = text.lower()\n",
        "    # Removing common English words that do not carry much meaning (stopwords)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    # Splitting the text into words, removing stopwords, and joining them back together\n",
        "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
        "    return text\n",
        "\n",
        "# Step 2: List of URLs we want to scrape content from\n",
        "urls = [\n",
        "    'https://webtool.co/fitness-based-seo-service/',\n",
        "    'https://webtool.co/attorney-based-seo-service/',\n",
        "    'https://webtool.co/medical-seo-service/',\n",
        "    'https://webtool.co/photography-seo-service/',\n",
        "    'https://webtool.co/banking-seo-service/',\n",
        "    'https://webtool.co/fashion-based-seo-service/',\n",
        "    'https://webtool.co/real-estate-seo-service/',\n",
        "    'https://webtool.co/adult-seo-service/',\n",
        "    'https://webtool.co/cbd-seo-service/',\n",
        "    'https://webtool.co/crypto-seo-service/',\n",
        "    'https://webtool.co/ecommerce-seo-service/',\n",
        "    'https://webtool.co/education-based-seo/',\n",
        "    'https://webtool.co/gaming-seo/',\n",
        "    'https://webtool.co/igaming-seo-service/',\n",
        "    'https://webtool.co/cosmetics-seo-service/',\n",
        "    'https://webtool.co/glass-wall-seo/',\n",
        "    'https://webtool.co/cora/',\n",
        "    'https://webtool.co/cosine-similarity/',\n",
        "    'https://webtool.co/bagofwords/',\n",
        "    'https://webtool.co/lda/',\n",
        "    'https://webtool.co/tf-idf-checker/',\n",
        "    'https://webtool.co/cooccurence/',\n",
        "    'https://webtool.co/keydensity/',\n",
        "    'https://webtool.co/proximity/',\n",
        "    'https://webtool.co/semantic/',\n",
        "    'https://webtool.co/n-gram/',\n",
        "    'https://webtool.co/sentiment/',\n",
        "    'https://webtool.co/advanced-seo-service/'\n",
        "]\n",
        "\n",
        "# Step 3: List to store data scraped from each URL\n",
        "scraped_data = []\n",
        "\n",
        "# Step 4: Function to scrape data from a single URL\n",
        "def scrape_content(url):\n",
        "    \"\"\"\n",
        "    Scrapes data from a given URL:\n",
        "    - Extracts meta description and keywords (if present)\n",
        "    - Extracts main text content (e.g., paragraphs, headings)\n",
        "    - Cleans the extracted text using the clean_text function\n",
        "\n",
        "    Args:\n",
        "    - url (str): The URL to scrape\n",
        "\n",
        "    Returns:\n",
        "    - dict: A dictionary containing URL, cleaned meta description, keywords, and main text\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Sending a request to the URL to get its content\n",
        "        response = requests.get(url, timeout=10)\n",
        "        # Check if the request was successful (status code 200 means success)\n",
        "        if response.status_code != 200:\n",
        "            return {'URL': url, 'Meta Description': 'Error fetching data', 'Keywords': 'N/A', 'Cleaned Text': 'Error fetching data'}\n",
        "\n",
        "        # Parsing the HTML content using BeautifulSoup\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # Extracting meta description (provides a brief summary of the webpage)\n",
        "        meta_description = soup.find('meta', attrs={'name': 'description'})\n",
        "        meta_content = meta_description['content'] if meta_description else 'No description'\n",
        "\n",
        "        # Extracting meta keywords (keywords for SEO purposes, if available)\n",
        "        meta_keywords = soup.find('meta', attrs={'name': 'keywords'})\n",
        "        if meta_keywords and 'content' in meta_keywords.attrs:\n",
        "            keywords_content = meta_keywords['content'].strip()  # Extracting the actual keywords content\n",
        "        else:\n",
        "            keywords_content = None  # If no keywords are found\n",
        "\n",
        "        # Extracting main text content from paragraphs and headings (provides most of the page's content)\n",
        "        paragraphs = soup.find_all('p')\n",
        "        headings = soup.find_all(['h1', 'h2'])\n",
        "        # Combining text from paragraphs and headings into a single string\n",
        "        main_text = ' '.join([p.get_text() for p in paragraphs + headings])\n",
        "\n",
        "        # Cleaning the extracted text using the clean_text function\n",
        "        cleaned_text = clean_text(main_text)\n",
        "\n",
        "        # Returning the data in a dictionary\n",
        "        return {\n",
        "            'URL': url,\n",
        "            'Meta Description': clean_text(meta_content),  # Cleaned meta description text\n",
        "            'Keywords': clean_text(keywords_content) if keywords_content else 'N/A',  # Cleaned keywords or 'N/A'\n",
        "            'Cleaned Text': cleaned_text  # Cleaned main text\n",
        "        }\n",
        "    except Exception as e:\n",
        "        # Handling any errors during the scraping process gracefully\n",
        "        return {\n",
        "            'URL': url,\n",
        "            'Meta Description': 'Error fetching data',\n",
        "            'Keywords': 'N/A',\n",
        "            'Cleaned Text': 'Error fetching data'\n",
        "        }\n",
        "\n",
        "# Step 5: Looping through the list of URLs to scrape content\n",
        "for url in urls:\n",
        "    # Scraping data from each URL and adding it to the list\n",
        "    scraped_data.append(scrape_content(url))\n",
        "\n",
        "# Step 6: Converting the list of scraped data into a DataFrame for easier processing and analysis\n",
        "scraped_df = pd.DataFrame(scraped_data)\n",
        "\n",
        "# Displaying the first few rows of the DataFrame to verify the scraped data\n",
        "print(\"Final Scraped Data (Preview):\")\n",
        "print(scraped_df.head())\n",
        "\n",
        "# Step 7: Saving the DataFrame to a CSV file for later use (e.g., merging with other datasets)\n",
        "scraped_df.to_csv('final_scraped_webtool_content.csv', index=False)\n",
        "\n",
        "# End of the first part\n",
        "# This code handles web scraping and prepares the data, which will be used for merging in the next part.\n"
      ],
      "metadata": {
        "id": "TMWFTBsROuYp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92180883-4d54-4088-806c-f1dee996beaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Scraped Data (Preview):\n",
            "                                              URL  \\\n",
            "0   https://webtool.co/fitness-based-seo-service/   \n",
            "1  https://webtool.co/attorney-based-seo-service/   \n",
            "2         https://webtool.co/medical-seo-service/   \n",
            "3     https://webtool.co/photography-seo-service/   \n",
            "4         https://webtool.co/banking-seo-service/   \n",
            "\n",
            "                                    Meta Description Keywords  \\\n",
            "0  transform fitness brand expert seo services ba...      N/A   \n",
            "1  looking way boost law firms online visibility ...      N/A   \n",
            "2  medical seo services help improve healthcare o...      N/A   \n",
            "3  looking boost photography businesss online vis...      N/A   \n",
            "4  improve banks online visibility reach professi...      N/A   \n",
            "\n",
            "                                        Cleaned Text  \n",
            "0  fitness based seo service quick enquiry seo se...  \n",
            "1  attorney based seo service quick enquiry seo s...  \n",
            "2  medical seo service quick enquiry medical base...  \n",
            "3  photography including techniques levitra gener...  \n",
            "4  banking seo service quick enquiry seo service ...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### Explanation of the Output:\n",
        "\n",
        "1. **Downloading Package Stopwords**:\n",
        "   - This part of the output shows that the code is downloading or verifying the presence of a package called `stopwords` from the Natural Language Toolkit (NLTK).\n",
        "   - **Why is this needed?** Stopwords are common words like \"is\", \"and\", \"the\" that do not contribute much meaning when analyzing text. They are removed from text data to make the analysis more focused and meaningful.\n",
        "   - The line `nltk_data Downloading package stopwords to /root/nltk_data...` simply shows the location where these stopwords are stored.\n",
        "\n",
        "2. **Final Scraped Data (Preview)**:\n",
        "   - This section shows a preview of the data that was extracted (or scraped) from various URLs (web pages). This data represents web content and meta-information relevant to SEO analysis.\n",
        "   - **What does it contain?** The preview displays a few columns for the first few rows of the dataset. Here’s what each column represents:\n",
        "     - **URL**: This is the web address of the page that was scraped.\n",
        "       - Example: `/fitness-based-seo-service/` is the URL for a webpage related to fitness-based SEO services.\n",
        "     - **Meta Description**: This is a brief summary or description of the webpage, usually provided in the meta tags of the HTML source code. It helps search engines understand the page’s content.\n",
        "       - Example: The description for the fitness-based SEO service page mentions improving online visibility for fitness brands.\n",
        "     - **Keywords**: These are keywords extracted from the page's meta tags. They provide an idea of the focus topics or themes of the page. In this example, the value is shown as `N/A`, which means keywords were not found or extracted.\n",
        "     - **Cleaned Text**: This column contains the main text content extracted from the webpage, which has been cleaned. Cleaning involves converting text to lowercase, removing punctuation, and getting rid of common stopwords to make the text more relevant for analysis.\n",
        "       - Example: For the fitness-based SEO service page, it shows a snippet of the cleaned text that mentions “fitness based seo service quick enquiry seo service...”.\n",
        "\n",
        "### What This Data Means:\n",
        "\n",
        "- **Purpose**: This data is a preliminary step in preparing information for SEO analysis. It helps us understand what content is present on each webpage and allows us to analyze it further for optimization.\n",
        "- **Use Case**: By having the URL, meta description, keywords, and cleaned text, you can evaluate how well-optimized each page is for search engines. For instance:\n",
        "  - If a page has a weak or missing meta description, you can recommend creating a more engaging and keyword-rich description.\n",
        "  - If no relevant keywords are found, it may indicate that the page needs better SEO optimization.\n",
        "  - The cleaned text can help identify the main topics or keywords being emphasized on the page.\n",
        "\n",
        "### Why This Matters for SEO:\n",
        "\n",
        "- **Meta Descriptions and Keywords**: These elements play a critical role in search engine optimization. The meta description can affect click-through rates, and the right keywords help improve a page’s visibility in search results.\n",
        "- **Content Analysis**: By analyzing the main content (cleaned text), you can assess whether the page is focused on the right topics, if it’s optimized for specific keywords, or if it needs improvements like better structure, additional content, or different formatting.\n",
        "\n",
        "### Next Steps Based on This Output:\n",
        "\n",
        "1. **Analyze Meta Descriptions and Keywords**: Identify pages that have missing or weak descriptions and provide recommendations for improvements.\n",
        "2. **Content Quality Check**: Assess the cleaned text to determine if the content is relevant, engaging, and keyword-rich.\n",
        "3. **Optimization Recommendations**: Suggest ways to improve the on-page SEO elements based on the analysis, such as adding or refining meta descriptions, optimizing content for target keywords, and enhancing user engagement.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "UrZHH7wuQT0u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Part 2: Data Merging and Standardization**\n",
        "- **Purpose**: This part merges the scraped content data with other provided datasets (Landing Pages and Pageviews Engagement). The goal is to combine information from different sources to get a comprehensive view of each web page's performance.\n",
        "- **What It Does**:\n",
        "  - **Load Data**: Loads the scraped content data (from Part 1) and two other datasets: Landing Pages and Pageviews Engagement data.\n",
        "  - **Standardize URLs**: Ensures that URLs in all datasets have a consistent format by converting to lowercase, removing trailing slashes, and trimming any whitespace. This makes merging possible.\n",
        "  - **Merge Data**: Merges the three datasets using the `URL` as the key to bring together content, engagement, and pageview metrics for each page.\n",
        "  - **Handle Missing Data**: Fills in missing values (e.g., setting missing numerical values to 0) to ensure data consistency.\n",
        "  - **Save the Merged Data**: Saves the merged data into a CSV file named `final_merged_data.csv` for further processing.\n"
      ],
      "metadata": {
        "id": "8tcf1l14URAF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries for data handling and merging\n",
        "import pandas as pd  # This library is used for data manipulation and analysis, especially working with datasets in table formats (DataFrames)\n",
        "\n",
        "# File paths for the provided datasets\n",
        "# Paths to the CSV files containing different datasets. These should match the location of your data files.\n",
        "landing_page_path = '/content/drive/MyDrive/Federated Learning Datasets/Webtool_landing_pages.csv'\n",
        "pageviews_engagement_path = '/content/drive/MyDrive/Federated Learning Datasets/Webtool_pageviews_user_engagement.csv'\n",
        "scraped_content_path = 'final_scraped_webtool_content.csv'  # This is the output file from the previous web scraping code\n",
        "\n",
        "# Step 1: Load datasets into DataFrames\n",
        "# Reading data from CSV files into pandas DataFrames for easy data manipulation\n",
        "scraped_content_df = pd.read_csv(scraped_content_path)  # This contains data scraped from various URLs\n",
        "landing_page_df = pd.read_csv(landing_page_path)  # This contains data related to landing pages\n",
        "pageviews_engagement_df = pd.read_csv(pageviews_engagement_path)  # This contains data on user engagement and pageviews\n",
        "\n",
        "# Display previews of the datasets to understand their structure and contents\n",
        "print(\"Final Scraped Webtool Content DataFrame (Preview):\")\n",
        "print(scraped_content_df.head())  # Displays the first 5 rows of the scraped content data\n",
        "print(\"\\nLanding Page DataFrame (Preview):\")\n",
        "print(landing_page_df.head())  # Displays the first 5 rows of the landing page data\n",
        "print(\"\\nPageviews Engagement DataFrame (Preview):\")\n",
        "print(pageviews_engagement_df.head())  # Displays the first 5 rows of the pageviews engagement data\n",
        "\n",
        "# Step 2: Standardize URLs for consistency across datasets\n",
        "def standardize_url(url):\n",
        "    \"\"\"\n",
        "    Standardizes URLs by converting them to lowercase, trimming whitespace, and removing trailing slashes.\n",
        "\n",
        "    URLs may differ in terms of cases, extra spaces, or trailing slashes. This function ensures that all URLs\n",
        "    have a consistent format, making it easier to match URLs across datasets during merging.\n",
        "\n",
        "    Args:\n",
        "    - url (str): The URL to be standardized.\n",
        "\n",
        "    Returns:\n",
        "    - str: The standardized URL.\n",
        "    \"\"\"\n",
        "    if pd.isna(url):  # Handle missing (NaN) values gracefully to avoid errors\n",
        "        return url  # Return as-is if the value is NaN\n",
        "    # Convert the URL to lowercase, remove leading/trailing whitespace, and remove any trailing slashes\n",
        "    url = url.lower().strip().rstrip('/')\n",
        "    return url\n",
        "\n",
        "# Apply the URL standardization function to the URLs in all datasets\n",
        "scraped_content_df['URL'] = scraped_content_df['URL'].str.replace('https://webtool.co', '', regex=False).apply(standardize_url)\n",
        "# Renaming the column 'Page path and screen class' to 'URL' for consistent merging keys\n",
        "landing_page_df.rename(columns={'Page path and screen class': 'URL'}, inplace=True)\n",
        "landing_page_df['URL'] = landing_page_df['URL'].apply(standardize_url)\n",
        "# Similarly, renaming and standardizing URLs in the pageviews engagement dataset\n",
        "pageviews_engagement_df.rename(columns={'Page path and screen class': 'URL'}, inplace=True)\n",
        "pageviews_engagement_df['URL'] = pageviews_engagement_df['URL'].apply(standardize_url)\n",
        "\n",
        "# Step 3: Merging the datasets\n",
        "# The goal is to combine information from different sources based on matching URLs\n",
        "# Merge the scraped content DataFrame with the landing page DataFrame using 'URL' as the common key\n",
        "merged_data = pd.merge(scraped_content_df, landing_page_df, on='URL', how='inner')  # 'inner' ensures only matching URLs are kept\n",
        "\n",
        "# Merge the result with the pageviews engagement DataFrame on 'URL'\n",
        "final_merged_data = pd.merge(merged_data, pageviews_engagement_df, on='URL', how='inner')\n",
        "\n",
        "# Display the merged data to verify that the merging process worked correctly\n",
        "print(\"\\nFinal Merged DataFrame (Preview) with all three datasets:\")\n",
        "print(final_merged_data.head())  # Display the first 5 rows of the final merged DataFrame\n",
        "\n",
        "# Step 4: Handle Missing Data (if any)\n",
        "# Fill missing values with default values for consistency and to avoid issues in later analysis\n",
        "# This ensures there are no empty or missing values for critical fields\n",
        "final_merged_data.fillna({\n",
        "    'Engaged sessions': 0,  # Replace missing values with 0 for numerical fields\n",
        "    'Engagement rate': 0.0,\n",
        "    'Bounce rate': 0.0,\n",
        "    'Average session duration': 0.0,\n",
        "    'Engaged sessions per active user': 0.0,\n",
        "    'Sessions': 0,\n",
        "    'Views': 0,\n",
        "    'Active users': 0,\n",
        "    'Views per active user': 0.0,\n",
        "    'Average engagement time per active user': 0.0,\n",
        "    'Event count': 0,\n",
        "    'Key events': 0,\n",
        "    'Total revenue': 0.0\n",
        "}, inplace=True)\n",
        "\n",
        "# Step 5: Save the final merged data to a CSV file for further use\n",
        "final_merged_data.to_csv('final_merged_data.csv', index=False)  # Save the cleaned and merged data as a new CSV file\n",
        "print(\"\\nFinal merged data successfully saved as 'final_merged_data.csv'.\")\n",
        "\n",
        "# Displaying a confirmation message\n",
        "print(\"The final merged dataset has been saved and is ready for further analysis.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8nr-6sCHVkv",
        "outputId": "0a50bbe3-48ce-45bc-a742-ac822567ce74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Scraped Webtool Content DataFrame (Preview):\n",
            "                                              URL  \\\n",
            "0   https://webtool.co/fitness-based-seo-service/   \n",
            "1  https://webtool.co/attorney-based-seo-service/   \n",
            "2         https://webtool.co/medical-seo-service/   \n",
            "3     https://webtool.co/photography-seo-service/   \n",
            "4         https://webtool.co/banking-seo-service/   \n",
            "\n",
            "                                    Meta Description Keywords  \\\n",
            "0  transform fitness brand expert seo services ba...      NaN   \n",
            "1  looking way boost law firms online visibility ...      NaN   \n",
            "2  medical seo services help improve healthcare o...      NaN   \n",
            "3  looking boost photography businesss online vis...      NaN   \n",
            "4  improve banks online visibility reach professi...      NaN   \n",
            "\n",
            "                                        Cleaned Text  \n",
            "0  fitness based seo service quick enquiry seo se...  \n",
            "1  attorney based seo service quick enquiry seo s...  \n",
            "2  medical seo service quick enquiry medical base...  \n",
            "3  photography including techniques levitra gener...  \n",
            "4  banking seo service quick enquiry seo service ...  \n",
            "\n",
            "Landing Page DataFrame (Preview):\n",
            "  Page path and screen class  Engaged sessions  Engagement rate  Bounce rate  \\\n",
            "0                        NaN               218         0.435130     0.564870   \n",
            "1                          /               131         0.461268     0.538732   \n",
            "2        /adult-seo-service/                39         0.709091     0.290909   \n",
            "3        /cosine-similarity/                31         0.688889     0.311111   \n",
            "4     /advanced-seo-service/                16         0.666667     0.333333   \n",
            "\n",
            "   Average session duration  Engaged sessions per active user  Sessions  \n",
            "0                209.188276                          0.514151       501  \n",
            "1                143.174858                          0.524000       284  \n",
            "2                244.989794                          0.866667        55  \n",
            "3                259.153598                          0.794872        45  \n",
            "4                 26.295755                          0.842105        24  \n",
            "\n",
            "Pageviews Engagement DataFrame (Preview):\n",
            "  Page path and screen class  Views  Active users  Views per active user  \\\n",
            "0                          /    943           371               2.541779   \n",
            "1        /adult-seo-service/    172            66               2.606061   \n",
            "2        /cosine-similarity/    134            51               2.627451   \n",
            "3     /advanced-seo-service/     78            32               2.437500   \n",
            "4               /contact-us/     64            28               2.285714   \n",
            "\n",
            "   Average engagement time per active user  Event count  Key events  \\\n",
            "0                                34.304582         3381           0   \n",
            "1                                48.984848          630           0   \n",
            "2                                65.529412          514           0   \n",
            "3                                24.125000          328           0   \n",
            "4                                55.071429          180           0   \n",
            "\n",
            "   Total revenue  \n",
            "0              0  \n",
            "1              0  \n",
            "2              0  \n",
            "3              0  \n",
            "4              0  \n",
            "\n",
            "Final Merged DataFrame (Preview) with all three datasets:\n",
            "                           URL  \\\n",
            "0   /fitness-based-seo-service   \n",
            "1  /attorney-based-seo-service   \n",
            "2         /medical-seo-service   \n",
            "3     /photography-seo-service   \n",
            "4         /banking-seo-service   \n",
            "\n",
            "                                    Meta Description Keywords  \\\n",
            "0  transform fitness brand expert seo services ba...      NaN   \n",
            "1  looking way boost law firms online visibility ...      NaN   \n",
            "2  medical seo services help improve healthcare o...      NaN   \n",
            "3  looking boost photography businesss online vis...      NaN   \n",
            "4  improve banks online visibility reach professi...      NaN   \n",
            "\n",
            "                                        Cleaned Text  Engaged sessions  \\\n",
            "0  fitness based seo service quick enquiry seo se...                 5   \n",
            "1  attorney based seo service quick enquiry seo s...                 0   \n",
            "2  medical seo service quick enquiry medical base...                 1   \n",
            "3  photography including techniques levitra gener...                 0   \n",
            "4  banking seo service quick enquiry seo service ...                 1   \n",
            "\n",
            "   Engagement rate  Bounce rate  Average session duration  \\\n",
            "0         0.833333     0.166667                 25.923008   \n",
            "1         0.000000     1.000000                  0.000000   \n",
            "2         0.500000     0.500000                 13.431745   \n",
            "3         0.000000     1.000000                  0.000000   \n",
            "4         0.500000     0.500000                 97.144310   \n",
            "\n",
            "   Engaged sessions per active user  Sessions  Views  Active users  \\\n",
            "0                          0.833333         6     16             8   \n",
            "1                          0.000000         1      6             3   \n",
            "2                          0.500000         2     10             4   \n",
            "3                          0.000000         1      4             2   \n",
            "4                          0.500000         2      6             3   \n",
            "\n",
            "   Views per active user  Average engagement time per active user  \\\n",
            "0                    2.0                                27.750000   \n",
            "1                    2.0                                48.666667   \n",
            "2                    2.5                                20.500000   \n",
            "3                    2.0                                 1.000000   \n",
            "4                    2.0                                 6.666667   \n",
            "\n",
            "   Event count  Key events  Total revenue  \n",
            "0           46           0              0  \n",
            "1           20           0              0  \n",
            "2           28           0              0  \n",
            "3           12           0              0  \n",
            "4           18           0              0  \n",
            "\n",
            "Final merged data successfully saved as 'final_merged_data.csv'.\n",
            "The final merged dataset has been saved and is ready for further analysis.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### Explanation of the Output:\n",
        "\n",
        "#### 1. **Final Scraped Webtool Content DataFrame (Preview)**\n",
        "   - **What it represents**: This is the data extracted from the URLs of web pages. It shows information collected through web scraping in the first part of your code.\n",
        "   - **Columns in this DataFrame**:\n",
        "     - **URL**: The web address of the page that was scraped.\n",
        "       - Example: `https://webtool.co/fitness-based-seo-service/` is a URL for a fitness SEO service.\n",
        "     - **Meta Description**: This is a brief description of the content found on the page. It comes from the meta tag in the webpage's HTML. It's important for SEO because it gives search engines and users a snapshot of what the page is about.\n",
        "       - Example: The description for the fitness-based SEO service page talks about transforming fitness brands with expert SEO services.\n",
        "     - **Keywords**: Keywords are extracted from the page’s meta tag and can indicate what the page is optimized for. Here, it shows as `NaN` (meaning \"Not a Number\") because the data was either missing or could not be extracted.\n",
        "     - **Cleaned Text**: This column contains the main text content from the page, processed to remove unnecessary characters like punctuation and stopwords (common words like \"the\" or \"and\" that don’t add much meaning).\n",
        "       - Example: \"fitness based seo service quick enquiry seo service\" is part of the cleaned text.\n",
        "\n",
        "#### 2. **Landing Page DataFrame (Preview)**\n",
        "   - **What it represents**: This DataFrame contains data about user engagement metrics for different web pages.\n",
        "   - **Columns in this DataFrame**:\n",
        "     - **Page path and screen class**: This column shows the page path or URL suffix for different pages.\n",
        "       - Example: `/adult-seo-service/` is the path for a page about adult SEO services.\n",
        "     - **Engaged sessions**: The number of sessions where users were actively engaged with the page.\n",
        "       - Example: 39 sessions were engaged for the `/adult-seo-service/` page.\n",
        "     - **Engagement rate**: The proportion of sessions where users were actively engaged.\n",
        "     - **Bounce rate**: The proportion of sessions where users left after viewing just one page.\n",
        "     - **Average session duration**: The average time spent by users on the page, measured in seconds.\n",
        "     - **Engaged sessions per active user**, **Sessions**, etc.: These columns provide further metrics about how users interact with the page.\n",
        "\n",
        "#### 3. **Pageviews Engagement DataFrame (Preview)**\n",
        "   - **What it represents**: This DataFrame provides data on page views and user engagement, indicating how often pages are viewed and by how many active users.\n",
        "   - **Columns in this DataFrame**:\n",
        "     - **Page path and screen class**: Similar to the previous DataFrame, it shows the page path.\n",
        "     - **Views**: Number of times the page was viewed.\n",
        "     - **Active users**: Number of unique users who interacted with the page.\n",
        "     - **Views per active user**: Average number of views per active user.\n",
        "     - **Average engagement time per active user**: The average time users spent engaging with the page.\n",
        "     - **Event count**, **Key events**, **Total revenue**: These columns provide more detailed metrics about user activity and interactions.\n",
        "\n",
        "#### 4. **Final Merged DataFrame (Preview) with all three datasets**\n",
        "   - **What it represents**: This is the merged data that combines information from all three previous datasets. It allows for a comprehensive analysis by bringing together scraped data, user engagement metrics, and page views.\n",
        "   - **Columns in this DataFrame**:\n",
        "     - **URL**: The page’s URL after standardization.\n",
        "     - **Meta Description, Keywords, Cleaned Text**: These columns come from the scraped content.\n",
        "     - **Engaged sessions, Engagement rate, Bounce rate**, etc.: These columns come from the engagement and pageviews datasets.\n",
        "   - **Why this is useful**: By merging data, you can analyze and compare engagement metrics, views, and content optimization on the same page. For example:\n",
        "     - A page with high views but low engagement may need content improvement to retain visitors.\n",
        "     - Pages with a high bounce rate may indicate a lack of relevant content or poor user experience.\n",
        "\n",
        "### What This Data Means for SEO Improvement:\n",
        "- **Data-driven SEO Recommendations**: This merged data allows you to generate recommendations to improve SEO. For example, you can identify which pages need better meta descriptions, more engaging content, or optimization for specific keywords.\n",
        "- **User Engagement Insights**: You can see which pages perform well and which need improvement based on user engagement metrics.\n",
        "- **Personalized Content Recommendations**: With this data, you can provide specific recommendations tailored to each URL, helping to improve user engagement and search engine ranking.\n",
        "\n",
        "---\n",
        "\n",
        "### Next Steps Based on This Output:\n",
        "1. **Analyze Pages with High Bounce Rates**: Consider why users leave without further interaction. Improve the content, make it more engaging, or ensure it matches user intent.\n",
        "2. **Optimize Meta Descriptions and Keywords**: Pages with missing or poor meta descriptions and keywords need attention.\n",
        "3. **Enhance Content for Low Engagement Pages**: Use the cleaned text data to see if the content aligns with user needs and SEO goals.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "cQOkRxS1R_14"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(\"Current Working Directory:\", os.getcwd())\n",
        "print(\"Files in Directory:\", os.listdir())  # List files in the current directory\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQAm6JFPFMth",
        "outputId": "2e89ebc1-e80a-4609-f4a4-4f7271b70c46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current Working Directory: /content\n",
            "Files in Directory: ['.config', 'cleaned_merged_webtool_data.csv', 'drive', 'final_scraped_webtool_content.csv', 'final_merged_data.csv', 'sample_data']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Part 3: Generating Content Recommendations**\n",
        "- **Purpose**: This part generates content recommendations based on the merged data. It analyzes metrics like views, engagement rate, and bounce rate to provide actionable insights for improving each page's SEO performance.\n",
        "- **What It Does**:\n",
        "  - **Load Merged Data**: Loads the data merged in Part 2.\n",
        "  - **Generate Recommendations**: For each page, it checks various engagement metrics and generates recommendations based on specific conditions. For example, if a page has a high bounce rate and low engagement, it suggests revising the content. If a page has excellent engagement, it recommends expanding the content.\n",
        "  - **Save Recommendations**: The generated recommendations, along with key metrics (e.g., views, engagement rate, bounce rate), are saved into a CSV file named `content_recommendations.csv`.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "sk69JPg5Ubj7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries for data handling\n",
        "import pandas as pd  # Pandas is used for working with datasets in a tabular format (similar to spreadsheets)\n",
        "\n",
        "# Load the merged data from the previous steps\n",
        "final_merged_data_path = 'final_merged_data.csv'  # This file should contain the merged data from previous code parts\n",
        "final_merged_data = pd.read_csv(final_merged_data_path)  # Loading the CSV file into a DataFrame for processing\n",
        "\n",
        "# Display the first few rows of the data to understand its structure\n",
        "print(\"Final Merged DataFrame (Preview):\")\n",
        "print(final_merged_data.head())  # Display the first 5 rows of the DataFrame for reference\n",
        "\n",
        "# Step 1: Function to generate detailed content recommendations\n",
        "def generate_content_recommendations(data):\n",
        "    \"\"\"\n",
        "    Generates detailed content recommendations based on engagement metrics like views,\n",
        "    engagement rate, bounce rate, average session duration, etc., to provide actionable insights.\n",
        "\n",
        "    This function iterates through each URL in the data and generates a recommendation based on\n",
        "    the engagement metrics of that page.\n",
        "\n",
        "    Args:\n",
        "    - data (DataFrame): A DataFrame containing URLs and relevant engagement metrics.\n",
        "\n",
        "    Returns:\n",
        "    - recommendations_df (DataFrame): A new DataFrame with columns for URL, recommendations, and key metrics.\n",
        "    \"\"\"\n",
        "    recommendations = []  # Creating an empty list to store generated recommendations\n",
        "\n",
        "    # Iterate over each row in the data (each row represents data for one URL)\n",
        "    for _, row in data.iterrows():\n",
        "        # Extracting data for the current row (URL)\n",
        "        url = row.get('URL', 'N/A')  # Get the URL or set 'N/A' if it's missing\n",
        "        views = row.get('Views', 0)  # Get the number of views or set to 0 if missing\n",
        "        engagement_rate = row.get('Engagement rate', 0)  # Get engagement rate or 0 if missing\n",
        "        bounce_rate = row.get('Bounce rate', 100)  # Set a high default bounce rate (100%) if missing\n",
        "        avg_session_duration = row.get('Average session duration', 0)  # Get average session duration or 0 if missing\n",
        "        active_users = row.get('Active users', 0)  # Get the number of active users or set to 0 if missing\n",
        "\n",
        "        # Generating recommendations based on specific conditions\n",
        "        # These conditions check the engagement metrics and provide recommendations accordingly\n",
        "        if engagement_rate > 70 and views > 500:\n",
        "            recommendation = f\"The page '{url}' shows excellent engagement. Consider expanding its content, adding interactive elements (like videos or infographics), and optimizing high-performing keywords.\"\n",
        "        elif engagement_rate > 50 and bounce_rate < 30:\n",
        "            recommendation = f\"The page '{url}' has moderate engagement with a low bounce rate. Boost its visibility through social media promotion, backlinks, and other marketing efforts.\"\n",
        "        elif avg_session_duration > 180:\n",
        "            recommendation = f\"The page '{url}' has a high average session duration. Consider breaking down content into subtopics, adding in-depth content, or incorporating related links to retain users.\"\n",
        "        elif views < 50 and active_users < 20:\n",
        "            recommendation = f\"The page '{url}' has low views and user engagement. Revisit its SEO strategies, enhance meta tags, and consider re-optimizing the content with targeted keywords to increase visibility. Leverage social media promotion and backlinks.\"\n",
        "        else:\n",
        "            recommendation = f\"Review and update the content for '{url}' to improve engagement by focusing on relevance, structure, and user experience.\"\n",
        "\n",
        "        # Append the URL, generated recommendation, and key metrics to the list\n",
        "        recommendations.append({\n",
        "            'URL': url,\n",
        "            'Recommendation': recommendation,\n",
        "            'Views': views,\n",
        "            'Engagement Rate (%)': engagement_rate,\n",
        "            'Bounce Rate (%)': bounce_rate,\n",
        "            'Average Session Duration (seconds)': avg_session_duration,\n",
        "            'Active Users': active_users\n",
        "        })\n",
        "\n",
        "    # Convert the list of recommendations into a DataFrame for easier handling and storage\n",
        "    recommendations_df = pd.DataFrame(recommendations)\n",
        "    return recommendations_df\n",
        "\n",
        "# Step 2: Generate content recommendations using the function\n",
        "recommendations_df = generate_content_recommendations(final_merged_data)  # Call the function and pass the merged data\n",
        "\n",
        "# Displaying the generated recommendations to verify correctness\n",
        "print(\"\\nGenerated Content Recommendations (Preview):\")\n",
        "print(recommendations_df.head(15))  # Display the first 15 recommendations for review\n",
        "\n",
        "# Step 3: Save the recommendations DataFrame to a CSV file for further use\n",
        "recommendations_df.to_csv('content_recommendations.csv', index=False)  # Save the recommendations as a CSV file\n",
        "\n",
        "# End of the code\n",
        "# This code generates content recommendations based on engagement metrics such as views, engagement rate, and bounce rate.\n",
        "# It offers actionable insights for each URL, helping optimize website content and user engagement.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUDwKVqPKDAl",
        "outputId": "cb40799e-c256-4774-c11c-e780a140e7be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Merged DataFrame (Preview):\n",
            "                           URL  \\\n",
            "0   /fitness-based-seo-service   \n",
            "1  /attorney-based-seo-service   \n",
            "2         /medical-seo-service   \n",
            "3     /photography-seo-service   \n",
            "4         /banking-seo-service   \n",
            "\n",
            "                                    Meta Description Keywords  \\\n",
            "0  transform fitness brand expert seo services ba...      NaN   \n",
            "1  looking way boost law firms online visibility ...      NaN   \n",
            "2  medical seo services help improve healthcare o...      NaN   \n",
            "3  looking boost photography businesss online vis...      NaN   \n",
            "4  improve banks online visibility reach professi...      NaN   \n",
            "\n",
            "                                        Cleaned Text  Engaged sessions  \\\n",
            "0  fitness based seo service quick enquiry seo se...                 5   \n",
            "1  attorney based seo service quick enquiry seo s...                 0   \n",
            "2  medical seo service quick enquiry medical base...                 1   \n",
            "3  photography including techniques levitra gener...                 0   \n",
            "4  banking seo service quick enquiry seo service ...                 1   \n",
            "\n",
            "   Engagement rate  Bounce rate  Average session duration  \\\n",
            "0         0.833333     0.166667                 25.923008   \n",
            "1         0.000000     1.000000                  0.000000   \n",
            "2         0.500000     0.500000                 13.431745   \n",
            "3         0.000000     1.000000                  0.000000   \n",
            "4         0.500000     0.500000                 97.144310   \n",
            "\n",
            "   Engaged sessions per active user  Sessions  Views  Active users  \\\n",
            "0                          0.833333         6     16             8   \n",
            "1                          0.000000         1      6             3   \n",
            "2                          0.500000         2     10             4   \n",
            "3                          0.000000         1      4             2   \n",
            "4                          0.500000         2      6             3   \n",
            "\n",
            "   Views per active user  Average engagement time per active user  \\\n",
            "0                    2.0                                27.750000   \n",
            "1                    2.0                                48.666667   \n",
            "2                    2.5                                20.500000   \n",
            "3                    2.0                                 1.000000   \n",
            "4                    2.0                                 6.666667   \n",
            "\n",
            "   Event count  Key events  Total revenue  \n",
            "0           46           0              0  \n",
            "1           20           0              0  \n",
            "2           28           0              0  \n",
            "3           12           0              0  \n",
            "4           18           0              0  \n",
            "\n",
            "Generated Content Recommendations (Preview):\n",
            "                            URL  \\\n",
            "0    /fitness-based-seo-service   \n",
            "1   /attorney-based-seo-service   \n",
            "2          /medical-seo-service   \n",
            "3      /photography-seo-service   \n",
            "4          /banking-seo-service   \n",
            "5    /fashion-based-seo-service   \n",
            "6      /real-estate-seo-service   \n",
            "7            /adult-seo-service   \n",
            "8              /cbd-seo-service   \n",
            "9           /crypto-seo-service   \n",
            "10       /ecommerce-seo-service   \n",
            "11         /education-based-seo   \n",
            "12                  /gaming-seo   \n",
            "13         /igaming-seo-service   \n",
            "14       /cosmetics-seo-service   \n",
            "\n",
            "                                       Recommendation  Views  \\\n",
            "0   The page '/fitness-based-seo-service' has low ...     16   \n",
            "1   The page '/attorney-based-seo-service' has low...      6   \n",
            "2   The page '/medical-seo-service' has low views ...     10   \n",
            "3   The page '/photography-seo-service' has low vi...      4   \n",
            "4   The page '/banking-seo-service' has low views ...      6   \n",
            "5   The page '/fashion-based-seo-service' has low ...      8   \n",
            "6   The page '/real-estate-seo-service' has low vi...      6   \n",
            "7   The page '/adult-seo-service' has a high avera...    172   \n",
            "8   The page '/cbd-seo-service' has low views and ...      6   \n",
            "9   The page '/crypto-seo-service' has low views a...     12   \n",
            "10  The page '/ecommerce-seo-service' has low view...      8   \n",
            "11  The page '/education-based-seo' has low views ...      8   \n",
            "12  The page '/gaming-seo' has low views and user ...     12   \n",
            "13  The page '/igaming-seo-service' has low views ...      4   \n",
            "14  The page '/cosmetics-seo-service' has low view...      8   \n",
            "\n",
            "    Engagement Rate (%)  Bounce Rate (%)  Average Session Duration (seconds)  \\\n",
            "0              0.833333         0.166667                           25.923008   \n",
            "1              0.000000         1.000000                            0.000000   \n",
            "2              0.500000         0.500000                           13.431745   \n",
            "3              0.000000         1.000000                            0.000000   \n",
            "4              0.500000         0.500000                           97.144310   \n",
            "5              0.666667         0.333333                           35.965583   \n",
            "6              0.000000         1.000000                            0.000000   \n",
            "7              0.709091         0.290909                          244.989794   \n",
            "8              0.500000         0.500000                          138.041303   \n",
            "9              0.333333         0.666667                           12.007212   \n",
            "10             0.333333         0.666667                            4.734906   \n",
            "11             1.000000         0.000000                           39.983463   \n",
            "12             0.400000         0.600000                           11.930559   \n",
            "13             0.500000         0.500000                           10.793988   \n",
            "14             0.333333         0.666667                           92.899024   \n",
            "\n",
            "    Active Users  \n",
            "0              8  \n",
            "1              3  \n",
            "2              4  \n",
            "3              2  \n",
            "4              3  \n",
            "5              4  \n",
            "6              3  \n",
            "7             66  \n",
            "8              3  \n",
            "9              6  \n",
            "10             4  \n",
            "11             4  \n",
            "12             5  \n",
            "13             2  \n",
            "14             4  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries for web scraping, data processing, and text cleaning\n",
        "import requests  # To send HTTP requests to URLs\n",
        "from bs4 import BeautifulSoup  # For parsing HTML content from webpages\n",
        "import pandas as pd  # For handling and storing data in tabular format\n",
        "import re  # For text cleaning using regular expressions\n",
        "from nltk.corpus import stopwords  # To remove common English stopwords\n",
        "import nltk  # Natural Language Toolkit for text processing tasks\n",
        "\n",
        "# Downloading stopwords (necessary for text cleaning) if not already available\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Step 1: Defining a function to clean text content\n",
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "    Cleans input text by removing non-alphabetic characters, converting to lowercase,\n",
        "    and removing common English stopwords.\n",
        "\n",
        "    Args:\n",
        "    - text (str): Input text to be cleaned.\n",
        "\n",
        "    Returns:\n",
        "    - str: Cleaned and processed text.\n",
        "    \"\"\"\n",
        "    # Remove digits and punctuation, keeping only letters and spaces\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    # Convert text to lowercase for uniformity\n",
        "    text = text.lower()\n",
        "    # Remove common English stopwords (words like \"and\", \"the\", \"is\", etc.)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
        "    return text\n",
        "\n",
        "# Step 2: Defining a list of URLs to scrape content from\n",
        "urls = [\n",
        "    'https://webtool.co/fitness-based-seo-service/',\n",
        "    'https://webtool.co/attorney-based-seo-service/',\n",
        "    'https://webtool.co/medical-seo-service/',\n",
        "    'https://webtool.co/photography-seo-service/',\n",
        "    'https://webtool.co/banking-seo-service/',\n",
        "    'https://webtool.co/fashion-based-seo-service/',\n",
        "    'https://webtool.co/real-estate-seo-service/',\n",
        "    'https://webtool.co/adult-seo-service/',\n",
        "    'https://webtool.co/cbd-seo-service/',\n",
        "    'https://webtool.co/crypto-seo-service/',\n",
        "    'https://webtool.co/ecommerce-seo-service/',\n",
        "    'https://webtool.co/education-based-seo/',\n",
        "    'https://webtool.co/gaming-seo/',\n",
        "    'https://webtool.co/igaming-seo-service/',\n",
        "    'https://webtool.co/cosmetics-seo-service/',\n",
        "    'https://webtool.co/glass-wall-seo/',\n",
        "    'https://webtool.co/cora/',\n",
        "    'https://webtool.co/cosine-similarity/',\n",
        "    'https://webtool.co/bagofwords/',\n",
        "    'https://webtool.co/lda/',\n",
        "    'https://webtool.co/tf-idf-checker/',\n",
        "    'https://webtool.co/cooccurence/',\n",
        "    'https://webtool.co/keydensity/',\n",
        "    'https://webtool.co/proximity/',\n",
        "    'https://webtool.co/semantic/',\n",
        "    'https://webtool.co/n-gram/',\n",
        "    'https://webtool.co/sentiment/',\n",
        "    'https://webtool.co/advanced-seo-service/'\n",
        "]\n",
        "\n",
        "# Step 3: Creating an empty list to store scraped data\n",
        "scraped_data = []\n",
        "\n",
        "# Step 4: Function to scrape content from each URL\n",
        "def scrape_content(url):\n",
        "    \"\"\"\n",
        "    Scrapes meta descriptions, keywords (if available), and main text content from the given URL.\n",
        "\n",
        "    Args:\n",
        "    - url (str): The URL to scrape content from.\n",
        "\n",
        "    Returns:\n",
        "    - dict: A dictionary containing the URL, extracted meta description, optional keywords, and cleaned main text.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Sending an HTTP GET request to fetch the page content\n",
        "        response = requests.get(url, timeout=10)\n",
        "        # Checking if the response status code indicates a successful request (200 OK)\n",
        "        if response.status_code != 200:\n",
        "            return {'URL': url, 'Meta Description': 'Error fetching data', 'Keywords': 'N/A', 'Cleaned Text': 'Error fetching data'}\n",
        "\n",
        "        # Parsing the HTML content of the page using BeautifulSoup\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # Extracting the meta description from the page (if available)\n",
        "        meta_description = soup.find('meta', attrs={'name': 'description'})\n",
        "        meta_content = meta_description['content'] if meta_description else 'No description'\n",
        "\n",
        "        # Extracting keywords from the meta tag (if available)\n",
        "        meta_keywords = soup.find('meta', attrs={'name': 'keywords'})\n",
        "        if meta_keywords and 'content' in meta_keywords.attrs:\n",
        "            keywords_content = meta_keywords['content'].strip()  # Extracting keywords content\n",
        "        else:\n",
        "            keywords_content = None  # No keywords available\n",
        "\n",
        "        # Extracting main text content from paragraph and heading elements (if available)\n",
        "        paragraphs = soup.find_all('p')\n",
        "        headings = soup.find_all(['h1', 'h2'])\n",
        "        # Combining text from paragraphs and headings into one string\n",
        "        main_text = ' '.join([p.get_text() for p in paragraphs + headings])\n",
        "\n",
        "        # Cleaning the extracted main text content using the clean_text function\n",
        "        cleaned_text = clean_text(main_text)\n",
        "\n",
        "        # Returning the extracted and cleaned data in a dictionary format\n",
        "        return {\n",
        "            'URL': url,\n",
        "            'Meta Description': clean_text(meta_content),  # Cleaned meta description\n",
        "            'Keywords': clean_text(keywords_content) if keywords_content else 'N/A',  # Cleaned keywords or 'N/A' if not present\n",
        "            'Cleaned Text': cleaned_text  # Cleaned main text content\n",
        "        }\n",
        "    except Exception as e:\n",
        "        # Handling errors gracefully by returning an error message for this URL\n",
        "        return {\n",
        "            'URL': url,\n",
        "            'Meta Description': 'Error fetching data',\n",
        "            'Keywords': 'N/A',\n",
        "            'Cleaned Text': 'Error fetching data'\n",
        "        }\n",
        "\n",
        "# Step 5: Looping through URLs to scrape content and collect results\n",
        "for url in urls:\n",
        "    # Calling the scrape_content function for each URL and storing the result\n",
        "    scraped_data.append(scrape_content(url))\n",
        "\n",
        "# Step 6: Converting the collected data into a DataFrame for further processing and analysis\n",
        "scraped_df = pd.DataFrame(scraped_data)\n",
        "\n",
        "# Displaying the scraped data to verify the extraction\n",
        "print(\"Final Scraped Data (Preview):\")\n",
        "print(scraped_df.head())\n",
        "\n",
        "# Step 7: Saving the scraped data to a CSV file for further use in merging and analysis\n",
        "scraped_df.to_csv('final_scraped_webtool_content.csv', index=False)\n",
        "\n",
        "# End of the first part\n",
        "# This part focuses on web scraping and preparing content data, which will later be merged with other datasets in subsequent parts.\n",
        "\n",
        "# Importing necessary libraries for data handling and merging\n",
        "import pandas as pd  # For data manipulation\n",
        "\n",
        "# File paths for the provided datasets\n",
        "landing_page_path = '/content/drive/MyDrive/Federated Learning Datasets/Webtool_landing_pages.csv'\n",
        "pageviews_engagement_path = '/content/drive/MyDrive/Federated Learning Datasets/Webtool_pageviews_user_engagement.csv'\n",
        "scraped_content_path = 'final_scraped_webtool_content.csv'  # This should have been generated in the first part\n",
        "\n",
        "# Step 1: Load datasets into DataFrames\n",
        "scraped_content_df = pd.read_csv(scraped_content_path)\n",
        "landing_page_df = pd.read_csv(landing_page_path)\n",
        "pageviews_engagement_df = pd.read_csv(pageviews_engagement_path)\n",
        "\n",
        "# Display previews of the datasets for reference\n",
        "print(\"Final Scraped Webtool Content DataFrame (Preview):\")\n",
        "print(scraped_content_df.head())\n",
        "print(\"\\nLanding Page DataFrame (Preview):\")\n",
        "print(landing_page_df.head())\n",
        "print(\"\\nPageviews Engagement DataFrame (Preview):\")\n",
        "print(pageviews_engagement_df.head())\n",
        "\n",
        "# Step 2: Standardize URLs for consistency across datasets\n",
        "def standardize_url(url):\n",
        "    \"\"\"\n",
        "    Standardizes URLs by converting them to lowercase, trimming whitespace, and removing trailing slashes.\n",
        "\n",
        "    Args:\n",
        "    - url (str): The URL to be standardized.\n",
        "\n",
        "    Returns:\n",
        "    - str: Standardized URL.\n",
        "    \"\"\"\n",
        "    if pd.isna(url):  # Handle missing (NaN) values gracefully\n",
        "        return url\n",
        "    url = url.lower().strip().rstrip('/')  # Convert to lowercase, trim whitespace, remove trailing slashes\n",
        "    return url\n",
        "\n",
        "# Apply URL standardization to the datasets\n",
        "scraped_content_df['URL'] = scraped_content_df['URL'].str.replace('https://webtool.co', '', regex=False).apply(standardize_url)\n",
        "landing_page_df.rename(columns={'Page path and screen class': 'URL'}, inplace=True)\n",
        "landing_page_df['URL'] = landing_page_df['URL'].apply(standardize_url)\n",
        "pageviews_engagement_df.rename(columns={'Page path and screen class': 'URL'}, inplace=True)\n",
        "pageviews_engagement_df['URL'] = pageviews_engagement_df['URL'].apply(standardize_url)\n",
        "\n",
        "# Step 3: Merging the datasets\n",
        "# Merge Final Scraped Content with the Landing Pages dataset\n",
        "merged_data = pd.merge(scraped_content_df, landing_page_df, on='URL', how='inner')\n",
        "\n",
        "# Merge the result with the Pageviews Engagement dataset\n",
        "final_merged_data = pd.merge(merged_data, pageviews_engagement_df, on='URL', how='inner')\n",
        "\n",
        "# Display the merged data to verify the merges\n",
        "print(\"\\nFinal Merged DataFrame (Preview) with all three datasets:\")\n",
        "print(final_merged_data.head())\n",
        "\n",
        "# Step 4: Handle Missing Data (if any)\n",
        "# Fill missing values to maintain data consistency\n",
        "final_merged_data.fillna({\n",
        "    'Engaged sessions': 0,\n",
        "    'Engagement rate': 0.0,\n",
        "    'Bounce rate': 0.0,\n",
        "    'Average session duration': 0.0,\n",
        "    'Engaged sessions per active user': 0.0,\n",
        "    'Sessions': 0,\n",
        "    'Views': 0,\n",
        "    'Active users': 0,\n",
        "    'Views per active user': 0.0,\n",
        "    'Average engagement time per active user': 0.0,\n",
        "    'Event count': 0,\n",
        "    'Key events': 0,\n",
        "    'Total revenue': 0.0\n",
        "}, inplace=True)\n",
        "\n",
        "# Step 5: Save the final merged data to a CSV file for further use\n",
        "final_merged_data.to_csv('final_merged_data.csv', index=False)\n",
        "print(\"\\nFinal merged data successfully saved as 'final_merged_data.csv'.\")\n",
        "\n",
        "# Displaying a confirmation message\n",
        "print(\"The final merged dataset has been saved and is ready for further analysis.\")\n",
        "\n",
        "\n",
        "# Importing necessary libraries for data handling\n",
        "import pandas as pd\n",
        "\n",
        "# Load the merged data from previous steps\n",
        "final_merged_data_path = 'final_merged_data.csv'  # Ensure this file is available\n",
        "final_merged_data = pd.read_csv(final_merged_data_path)\n",
        "\n",
        "# Display the structure of the data for reference\n",
        "print(\"Final Merged DataFrame (Preview):\")\n",
        "print(final_merged_data.head())\n",
        "\n",
        "# Step 1: Function to generate detailed content recommendations\n",
        "def generate_content_recommendations(data):\n",
        "    \"\"\"\n",
        "    Generates detailed content recommendations based on engagement metrics like views,\n",
        "    engagement rate, bounce rate, average session duration, etc., to provide actionable insights.\n",
        "\n",
        "    Args:\n",
        "    - data (DataFrame): DataFrame containing URLs and relevant metrics.\n",
        "\n",
        "    Returns:\n",
        "    - recommendations_df (DataFrame): DataFrame with URL, recommendations, and key metrics.\n",
        "    \"\"\"\n",
        "    recommendations = []  # List to store recommendation data\n",
        "\n",
        "    # Iterate over each row in the data\n",
        "    for _, row in data.iterrows():\n",
        "        url = row.get('URL', 'N/A')\n",
        "        views = row.get('Views', 0)\n",
        "        engagement_rate = row.get('Engagement rate', 0)\n",
        "        bounce_rate = row.get('Bounce rate', 100)  # High default bounce rate if missing\n",
        "        avg_session_duration = row.get('Average session duration', 0)\n",
        "        active_users = row.get('Active users', 0)\n",
        "\n",
        "        # Generating recommendations based on conditions\n",
        "        if engagement_rate > 70 and views > 500:\n",
        "            recommendation = f\"The page '{url}' shows excellent engagement. Consider expanding its content, adding interactive elements (like videos or infographics), and optimizing high-performing keywords.\"\n",
        "        elif engagement_rate > 50 and bounce_rate < 30:\n",
        "            recommendation = f\"The page '{url}' has moderate engagement with a low bounce rate. Boost its visibility through social media promotion, backlinks, and other marketing efforts.\"\n",
        "        elif avg_session_duration > 180:\n",
        "            recommendation = f\"The page '{url}' has a high average session duration. Consider breaking down content into subtopics, adding in-depth content, or incorporating related links to retain users.\"\n",
        "        elif views < 50 and active_users < 20:\n",
        "            recommendation = f\"The page '{url}' has low views and user engagement. Revisit its SEO strategies, enhance meta tags, and consider re-optimizing the content with targeted keywords to increase visibility. Leverage social media promotion and backlinks.\"\n",
        "        else:\n",
        "            recommendation = f\"Review and update the content for '{url}' to improve engagement by focusing on relevance, structure, and user experience.\"\n",
        "\n",
        "        # Append the URL, recommendation, and key metrics to the list\n",
        "        recommendations.append({\n",
        "            'URL': url,\n",
        "            'Recommendation': recommendation,\n",
        "            'Views': views,\n",
        "            'Engagement Rate (%)': engagement_rate,\n",
        "            'Bounce Rate (%)': bounce_rate,\n",
        "            'Average Session Duration (seconds)': avg_session_duration,\n",
        "            'Active Users': active_users\n",
        "        })\n",
        "\n",
        "    # Convert the recommendations list to a DataFrame\n",
        "    recommendations_df = pd.DataFrame(recommendations)\n",
        "    return recommendations_df\n",
        "\n",
        "# Step 2: Generate recommendations based on the final merged data\n",
        "recommendations_df = generate_content_recommendations(final_merged_data)\n",
        "\n",
        "# Display the generated recommendations for verification\n",
        "print(\"\\nGenerated Content Recommendations (Preview):\")\n",
        "print(recommendations_df.head(15))\n",
        "\n",
        "# Step 3: Save the recommendations dataset to a CSV file for client use\n",
        "recommendations_df.to_csv('content_recommendations.csv', index=False)\n",
        "\n",
        "# End of the third part of the code\n",
        "# This part generates a dataset containing content recommendations and key metrics like views, engagement rate, bounce rate, etc., to offer detailed insights for each URL.\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FLFMd2DO_DS",
        "outputId": "dc78134d-6eb3-4617-8994-7ace667d2b7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Scraped Data (Preview):\n",
            "                                              URL  \\\n",
            "0   https://webtool.co/fitness-based-seo-service/   \n",
            "1  https://webtool.co/attorney-based-seo-service/   \n",
            "2         https://webtool.co/medical-seo-service/   \n",
            "3     https://webtool.co/photography-seo-service/   \n",
            "4         https://webtool.co/banking-seo-service/   \n",
            "\n",
            "                                    Meta Description Keywords  \\\n",
            "0  transform fitness brand expert seo services ba...      N/A   \n",
            "1  looking way boost law firms online visibility ...      N/A   \n",
            "2  medical seo services help improve healthcare o...      N/A   \n",
            "3  looking boost photography businesss online vis...      N/A   \n",
            "4  improve banks online visibility reach professi...      N/A   \n",
            "\n",
            "                                        Cleaned Text  \n",
            "0  fitness based seo service quick enquiry seo se...  \n",
            "1  attorney based seo service quick enquiry seo s...  \n",
            "2  medical seo service quick enquiry medical base...  \n",
            "3  photography including techniques levitra gener...  \n",
            "4  banking seo service quick enquiry seo service ...  \n",
            "Final Scraped Webtool Content DataFrame (Preview):\n",
            "                                              URL  \\\n",
            "0   https://webtool.co/fitness-based-seo-service/   \n",
            "1  https://webtool.co/attorney-based-seo-service/   \n",
            "2         https://webtool.co/medical-seo-service/   \n",
            "3     https://webtool.co/photography-seo-service/   \n",
            "4         https://webtool.co/banking-seo-service/   \n",
            "\n",
            "                                    Meta Description Keywords  \\\n",
            "0  transform fitness brand expert seo services ba...      NaN   \n",
            "1  looking way boost law firms online visibility ...      NaN   \n",
            "2  medical seo services help improve healthcare o...      NaN   \n",
            "3  looking boost photography businesss online vis...      NaN   \n",
            "4  improve banks online visibility reach professi...      NaN   \n",
            "\n",
            "                                        Cleaned Text  \n",
            "0  fitness based seo service quick enquiry seo se...  \n",
            "1  attorney based seo service quick enquiry seo s...  \n",
            "2  medical seo service quick enquiry medical base...  \n",
            "3  photography including techniques levitra gener...  \n",
            "4  banking seo service quick enquiry seo service ...  \n",
            "\n",
            "Landing Page DataFrame (Preview):\n",
            "  Page path and screen class  Engaged sessions  Engagement rate  Bounce rate  \\\n",
            "0                        NaN               218         0.435130     0.564870   \n",
            "1                          /               131         0.461268     0.538732   \n",
            "2        /adult-seo-service/                39         0.709091     0.290909   \n",
            "3        /cosine-similarity/                31         0.688889     0.311111   \n",
            "4     /advanced-seo-service/                16         0.666667     0.333333   \n",
            "\n",
            "   Average session duration  Engaged sessions per active user  Sessions  \n",
            "0                209.188276                          0.514151       501  \n",
            "1                143.174858                          0.524000       284  \n",
            "2                244.989794                          0.866667        55  \n",
            "3                259.153598                          0.794872        45  \n",
            "4                 26.295755                          0.842105        24  \n",
            "\n",
            "Pageviews Engagement DataFrame (Preview):\n",
            "  Page path and screen class  Views  Active users  Views per active user  \\\n",
            "0                          /    943           371               2.541779   \n",
            "1        /adult-seo-service/    172            66               2.606061   \n",
            "2        /cosine-similarity/    134            51               2.627451   \n",
            "3     /advanced-seo-service/     78            32               2.437500   \n",
            "4               /contact-us/     64            28               2.285714   \n",
            "\n",
            "   Average engagement time per active user  Event count  Key events  \\\n",
            "0                                34.304582         3381           0   \n",
            "1                                48.984848          630           0   \n",
            "2                                65.529412          514           0   \n",
            "3                                24.125000          328           0   \n",
            "4                                55.071429          180           0   \n",
            "\n",
            "   Total revenue  \n",
            "0              0  \n",
            "1              0  \n",
            "2              0  \n",
            "3              0  \n",
            "4              0  \n",
            "\n",
            "Final Merged DataFrame (Preview) with all three datasets:\n",
            "                           URL  \\\n",
            "0   /fitness-based-seo-service   \n",
            "1  /attorney-based-seo-service   \n",
            "2         /medical-seo-service   \n",
            "3     /photography-seo-service   \n",
            "4         /banking-seo-service   \n",
            "\n",
            "                                    Meta Description Keywords  \\\n",
            "0  transform fitness brand expert seo services ba...      NaN   \n",
            "1  looking way boost law firms online visibility ...      NaN   \n",
            "2  medical seo services help improve healthcare o...      NaN   \n",
            "3  looking boost photography businesss online vis...      NaN   \n",
            "4  improve banks online visibility reach professi...      NaN   \n",
            "\n",
            "                                        Cleaned Text  Engaged sessions  \\\n",
            "0  fitness based seo service quick enquiry seo se...                 5   \n",
            "1  attorney based seo service quick enquiry seo s...                 0   \n",
            "2  medical seo service quick enquiry medical base...                 1   \n",
            "3  photography including techniques levitra gener...                 0   \n",
            "4  banking seo service quick enquiry seo service ...                 1   \n",
            "\n",
            "   Engagement rate  Bounce rate  Average session duration  \\\n",
            "0         0.833333     0.166667                 25.923008   \n",
            "1         0.000000     1.000000                  0.000000   \n",
            "2         0.500000     0.500000                 13.431745   \n",
            "3         0.000000     1.000000                  0.000000   \n",
            "4         0.500000     0.500000                 97.144310   \n",
            "\n",
            "   Engaged sessions per active user  Sessions  Views  Active users  \\\n",
            "0                          0.833333         6     16             8   \n",
            "1                          0.000000         1      6             3   \n",
            "2                          0.500000         2     10             4   \n",
            "3                          0.000000         1      4             2   \n",
            "4                          0.500000         2      6             3   \n",
            "\n",
            "   Views per active user  Average engagement time per active user  \\\n",
            "0                    2.0                                27.750000   \n",
            "1                    2.0                                48.666667   \n",
            "2                    2.5                                20.500000   \n",
            "3                    2.0                                 1.000000   \n",
            "4                    2.0                                 6.666667   \n",
            "\n",
            "   Event count  Key events  Total revenue  \n",
            "0           46           0              0  \n",
            "1           20           0              0  \n",
            "2           28           0              0  \n",
            "3           12           0              0  \n",
            "4           18           0              0  \n",
            "\n",
            "Final merged data successfully saved as 'final_merged_data.csv'.\n",
            "The final merged dataset has been saved and is ready for further analysis.\n",
            "Final Merged DataFrame (Preview):\n",
            "                           URL  \\\n",
            "0   /fitness-based-seo-service   \n",
            "1  /attorney-based-seo-service   \n",
            "2         /medical-seo-service   \n",
            "3     /photography-seo-service   \n",
            "4         /banking-seo-service   \n",
            "\n",
            "                                    Meta Description Keywords  \\\n",
            "0  transform fitness brand expert seo services ba...      NaN   \n",
            "1  looking way boost law firms online visibility ...      NaN   \n",
            "2  medical seo services help improve healthcare o...      NaN   \n",
            "3  looking boost photography businesss online vis...      NaN   \n",
            "4  improve banks online visibility reach professi...      NaN   \n",
            "\n",
            "                                        Cleaned Text  Engaged sessions  \\\n",
            "0  fitness based seo service quick enquiry seo se...                 5   \n",
            "1  attorney based seo service quick enquiry seo s...                 0   \n",
            "2  medical seo service quick enquiry medical base...                 1   \n",
            "3  photography including techniques levitra gener...                 0   \n",
            "4  banking seo service quick enquiry seo service ...                 1   \n",
            "\n",
            "   Engagement rate  Bounce rate  Average session duration  \\\n",
            "0         0.833333     0.166667                 25.923008   \n",
            "1         0.000000     1.000000                  0.000000   \n",
            "2         0.500000     0.500000                 13.431745   \n",
            "3         0.000000     1.000000                  0.000000   \n",
            "4         0.500000     0.500000                 97.144310   \n",
            "\n",
            "   Engaged sessions per active user  Sessions  Views  Active users  \\\n",
            "0                          0.833333         6     16             8   \n",
            "1                          0.000000         1      6             3   \n",
            "2                          0.500000         2     10             4   \n",
            "3                          0.000000         1      4             2   \n",
            "4                          0.500000         2      6             3   \n",
            "\n",
            "   Views per active user  Average engagement time per active user  \\\n",
            "0                    2.0                                27.750000   \n",
            "1                    2.0                                48.666667   \n",
            "2                    2.5                                20.500000   \n",
            "3                    2.0                                 1.000000   \n",
            "4                    2.0                                 6.666667   \n",
            "\n",
            "   Event count  Key events  Total revenue  \n",
            "0           46           0              0  \n",
            "1           20           0              0  \n",
            "2           28           0              0  \n",
            "3           12           0              0  \n",
            "4           18           0              0  \n",
            "\n",
            "Generated Content Recommendations (Preview):\n",
            "                            URL  \\\n",
            "0    /fitness-based-seo-service   \n",
            "1   /attorney-based-seo-service   \n",
            "2          /medical-seo-service   \n",
            "3      /photography-seo-service   \n",
            "4          /banking-seo-service   \n",
            "5    /fashion-based-seo-service   \n",
            "6      /real-estate-seo-service   \n",
            "7            /adult-seo-service   \n",
            "8              /cbd-seo-service   \n",
            "9           /crypto-seo-service   \n",
            "10       /ecommerce-seo-service   \n",
            "11         /education-based-seo   \n",
            "12                  /gaming-seo   \n",
            "13         /igaming-seo-service   \n",
            "14       /cosmetics-seo-service   \n",
            "\n",
            "                                       Recommendation  Views  \\\n",
            "0   The page '/fitness-based-seo-service' has low ...     16   \n",
            "1   The page '/attorney-based-seo-service' has low...      6   \n",
            "2   The page '/medical-seo-service' has low views ...     10   \n",
            "3   The page '/photography-seo-service' has low vi...      4   \n",
            "4   The page '/banking-seo-service' has low views ...      6   \n",
            "5   The page '/fashion-based-seo-service' has low ...      8   \n",
            "6   The page '/real-estate-seo-service' has low vi...      6   \n",
            "7   The page '/adult-seo-service' has a high avera...    172   \n",
            "8   The page '/cbd-seo-service' has low views and ...      6   \n",
            "9   The page '/crypto-seo-service' has low views a...     12   \n",
            "10  The page '/ecommerce-seo-service' has low view...      8   \n",
            "11  The page '/education-based-seo' has low views ...      8   \n",
            "12  The page '/gaming-seo' has low views and user ...     12   \n",
            "13  The page '/igaming-seo-service' has low views ...      4   \n",
            "14  The page '/cosmetics-seo-service' has low view...      8   \n",
            "\n",
            "    Engagement Rate (%)  Bounce Rate (%)  Average Session Duration (seconds)  \\\n",
            "0              0.833333         0.166667                           25.923008   \n",
            "1              0.000000         1.000000                            0.000000   \n",
            "2              0.500000         0.500000                           13.431745   \n",
            "3              0.000000         1.000000                            0.000000   \n",
            "4              0.500000         0.500000                           97.144310   \n",
            "5              0.666667         0.333333                           35.965583   \n",
            "6              0.000000         1.000000                            0.000000   \n",
            "7              0.709091         0.290909                          244.989794   \n",
            "8              0.500000         0.500000                          138.041303   \n",
            "9              0.333333         0.666667                           12.007212   \n",
            "10             0.333333         0.666667                            4.734906   \n",
            "11             1.000000         0.000000                           39.983463   \n",
            "12             0.400000         0.600000                           11.930559   \n",
            "13             0.500000         0.500000                           10.793988   \n",
            "14             0.333333         0.666667                           92.899024   \n",
            "\n",
            "    Active Users  \n",
            "0              8  \n",
            "1              3  \n",
            "2              4  \n",
            "3              2  \n",
            "4              3  \n",
            "5              4  \n",
            "6              3  \n",
            "7             66  \n",
            "8              3  \n",
            "9              6  \n",
            "10             4  \n",
            "11             4  \n",
            "12             5  \n",
            "13             2  \n",
            "14             4  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explanation of the Output\n",
        "\n",
        "\n",
        " **Final Scraped Data (Preview)**:\n",
        "   - This section shows a preview of the data that was extracted (or scraped) from various URLs (web pages). This data represents web content and meta-information relevant to SEO analysis.\n",
        "   - **What does it contain?** The preview displays a few columns for the first few rows of the dataset. Here’s what each column represents:\n",
        "     - **URL**: This is the web address of the page that was scraped.\n",
        "       - Example: `/fitness-based-seo-service/` is the URL for a webpage related to fitness-based SEO services.\n",
        "     - **Meta Description**: This is a brief summary or description of the webpage, usually provided in the meta tags of the HTML source code. It helps search engines understand the page’s content.\n",
        "       - Example: The description for the fitness-based SEO service page mentions improving online visibility for fitness brands.\n",
        "     - **Keywords**: These are keywords extracted from the page's meta tags. They provide an idea of the focus topics or themes of the page. In this example, the value is shown as `N/A`, which means keywords were not found or extracted.\n",
        "     - **Cleaned Text**: This column contains the main text content extracted from the webpage, which has been cleaned. Cleaning involves converting text to lowercase, removing punctuation, and getting rid of common stopwords to make the text more relevant for analysis.\n",
        "       - Example: For the fitness-based SEO service page, it shows a snippet of the cleaned text that mentions “fitness based seo service quick enquiry seo service...”.\n",
        "\n",
        "### What This Data Means:\n",
        "\n",
        "- **Purpose**: This data is a preliminary step in preparing information for SEO analysis. It helps us understand what content is present on each webpage and allows us to analyze it further for optimization.\n",
        "- **Use Case**: By having the URL, meta description, keywords, and cleaned text, you can evaluate how well-optimized each page is for search engines. For instance:\n",
        "  - If a page has a weak or missing meta description, you can recommend creating a more engaging and keyword-rich description.\n",
        "  - If no relevant keywords are found, it may indicate that the page needs better SEO optimization.\n",
        "  - The cleaned text can help identify the main topics or keywords being emphasized on the page.\n",
        "\n",
        "### Why This Matters for SEO:\n",
        "\n",
        "- **Meta Descriptions and Keywords**: These elements play a critical role in search engine optimization. The meta description can affect click-through rates, and the right keywords help improve a page’s visibility in search results.\n",
        "- **Content Analysis**: By analyzing the main content (cleaned text), you can assess whether the page is focused on the right topics, if it’s optimized for specific keywords, or if it needs improvements like better structure, additional content, or different formatting.\n",
        "\n",
        "### Next Steps Based on This Output:\n",
        "\n",
        "1. **Analyze Meta Descriptions and Keywords**: Identify pages that have missing or weak descriptions and provide recommendations for improvements.\n",
        "2. **Content Quality Check**: Assess the cleaned text to determine if the content is relevant, engaging, and keyword-rich.\n",
        "3. **Optimization Recommendations**: Suggest ways to improve the on-page SEO elements based on the analysis, such as adding or refining meta descriptions, optimizing content for target keywords, and enhancing user engagement.\n",
        "\n",
        "---\n",
        "\n",
        "1. **Final Merged DataFrame (Preview)**:\n",
        "    - This table shows the merged data from various sources, including URLs and their associated SEO metrics.\n",
        "    - Columns explained:\n",
        "        - **URL**: This column lists the unique URLs or web pages that have been analyzed.\n",
        "        - **Meta Description**: This column contains a brief description of the content on the page, extracted during the scraping process. If this value is `NaN` (Not a Number), it means no meta description was found for that URL.\n",
        "        - **Cleaned Text**: This column shows the cleaned main text content from the page.\n",
        "        - **Engaged Sessions, Engagement Rate, Bounce Rate, etc.**: These columns show various metrics related to user engagement, such as:\n",
        "            - **Engaged Sessions**: The number of sessions where users were actively engaged.\n",
        "            - **Engagement Rate**: The percentage of sessions where users interacted meaningfully with the page.\n",
        "            - **Bounce Rate**: The percentage of users who left the page without engaging further.\n",
        "            - **Average Session Duration**: The average time users spent on the page.\n",
        "            - **Views, Active Users, Event Count, etc.**: Additional metrics that provide insights into the user behavior on each page.\n",
        "\n",
        "    - **Use Case**: This table allows you to understand how each URL performs based on user engagement metrics, which is critical for evaluating SEO performance.\n",
        "\n",
        "2. **Generated Content Recommendations (Preview)**:\n",
        "    - This table is the output of the content recommendation system based on the analyzed data. Each row corresponds to a specific URL and provides actionable recommendations.\n",
        "    - Columns explained:\n",
        "        - **URL**: The web page for which the recommendation is made.\n",
        "        - **Recommendation**: A detailed suggestion tailored to improve the page's engagement, visibility, or other metrics. For example:\n",
        "            - If the engagement rate is low or the views are minimal, the recommendation might suggest revisiting SEO strategies, enhancing content, or improving user targeting.\n",
        "            - High engagement might prompt suggestions to expand content or add interactive elements to retain users further.\n",
        "        - **Views**: The number of times the page was viewed.\n",
        "        - **Engagement Rate (%)**: The percentage indicating how engaged users were with the page.\n",
        "        - **Bounce Rate (%)**: The percentage of users who left after viewing the page.\n",
        "        - **Average Session Duration (seconds)**: The average time spent by users on the page.\n",
        "        - **Active Users**: The number of unique users who actively engaged with the page.\n",
        "\n",
        "    - **Use Case**: This table serves as a guide for improving content performance. By examining the metrics and recommendations, you can identify pages that need content optimization, increased visibility, or restructuring to reduce bounce rates.\n",
        "\n",
        "\n",
        "3. **Understanding the Columns and Their Relevance**:\n",
        "   - **URL**: This identifies the web page being analyzed. Each URL is unique, representing a specific page on your site.\n",
        "   - **Recommendation**: This column provides actionable insights based on the data for that URL. The recommendations are generated based on the page's metrics, such as views, engagement rate, bounce rate, and session duration. The goal of these recommendations is to improve the performance of the page by addressing specific issues or optimizing areas where it is performing well.\n",
        "     - For example, if the engagement rate is low and views are minimal, the recommendation suggests revisiting the page's SEO strategy, enhancing content, or targeting better keywords.\n",
        "   - **Views**: This represents how many times the page was viewed by users. A high number of views indicates good visibility, while a low number suggests the need to improve the page's reach or relevance.\n",
        "   - **Engagement Rate (%)**: This shows how effectively the page engages users. A higher engagement rate indicates that users are interacting more with the content. If this value is low, it may suggest that the content is not capturing user interest.\n",
        "   - **Bounce Rate (%)**: A high bounce rate indicates that many users leave the page after viewing it without engaging further. This could point to a lack of engaging content or relevance to the user's intent.\n",
        "   - **Average Session Duration (seconds)**: This metric shows the average amount of time users spend on the page. A longer duration generally suggests that users find the content engaging or useful, while a shorter duration may indicate a lack of interest or relevance.\n",
        "   - **Active Users**: This indicates the number of unique users who actively engaged with the page. More active users can signify that the page has a broad appeal.\n",
        "\n",
        "4. **Example Interpretations**:\n",
        "   - **Row 0 (URL: /fitness-based-seo-service)**:\n",
        "     - **Recommendation**: The recommendation suggests that the page has low views and user engagement. It advises revisiting SEO strategies, enhancing meta tags, and re-optimizing content with targeted keywords to increase visibility and engagement.\n",
        "     - **Views**: 16 views indicate that the page is not receiving a lot of traffic.\n",
        "     - **Engagement Rate (%)**: 0.83 (or 83%) suggests a relatively high level of engagement among users who visit.\n",
        "     - **Bounce Rate (%)**: 0.16 (or 16%) is low, indicating that users who visit tend to stay and engage with the page.\n",
        "     - **Average Session Duration**: 25.92 seconds, suggesting the average time users spent on the page.\n",
        "     - **Active Users**: 8 unique users engaged with the page.\n",
        "\n",
        "   - **Row 7 (URL: /adult-seo-service)**:\n",
        "     - **Recommendation**: The recommendation highlights that the page has a high average session duration and good engagement. It suggests considering breaking down the content further or adding in-depth analysis to retain users longer.\n",
        "     - **Views**: 172 views, showing a relatively high traffic level.\n",
        "     - **Engagement Rate (%)**: 0.71 (or 71%), indicating strong engagement.\n",
        "     - **Bounce Rate (%)**: 0.29 (or 29%), meaning a lower percentage of users leave without further engagement.\n",
        "     - **Average Session Duration**: 244.99 seconds, reflecting a long user stay time, indicating high engagement.\n",
        "     - **Active Users**: 66 unique users, a good number of active users.\n",
        "\n",
        "5. **Using the Output**:\n",
        "   - **Identify and Prioritize Improvements**: Use the recommendations to focus your efforts on improving specific pages. For example, pages with low engagement or high bounce rates should be optimized for better content relevance, faster loading times, or improved user targeting.\n",
        "   - **Measure Impact Over Time**: After implementing changes based on the recommendations, track these metrics to see if engagement, views, or other aspects improve.\n",
        "   - **Optimize Content**: Pages with high engagement might be expanded or enhanced to retain users further, while pages with low performance should be re-evaluated for content quality and relevance.\n",
        "\n",
        "\n",
        "### Key Takeaways from the Output\n",
        "- The **\"Final Merged DataFrame\"** provides a comprehensive view of all the metrics related to each URL. This helps in understanding the current state of SEO performance.\n",
        "- The **\"Generated Content Recommendations\"** table offers actionable insights for each page. The goal is to improve user engagement, reduce bounce rates, and optimize content based on how users currently interact with each page.\n",
        "- **Example Interpretations**:\n",
        "    - For a page with low views and high bounce rates, the recommendation might suggest revisiting SEO strategies or improving content relevance.\n",
        "    - A page with high engagement and long average session duration may prompt expanding the content to retain user interest.\n",
        "\n",
        "### Next Steps\n",
        "1. **Use the Recommendations**: Implement the suggested recommendations for each URL to improve SEO performance.\n",
        "2. **Track Metrics**: After implementing changes, track the metrics over time to assess the impact.\n",
        "3. **Iterative Improvements**: Continue to refine and optimize content based on updated metrics and user behavior insights.\n",
        "\n",
        "### Summary\n",
        "This output provides a comprehensive overview of each URL's performance and actionable steps to improve SEO performance. By following the recommendations, you can increase user engagement, improve content relevance, and enhance SEO strategy for each page on your website. The goal is to provide a tailored approach to optimize your site’s content based on real user behavior and engagement data.    \n"
      ],
      "metadata": {
        "id": "gWJtLgOMN-1g"
      }
    }
  ]
}