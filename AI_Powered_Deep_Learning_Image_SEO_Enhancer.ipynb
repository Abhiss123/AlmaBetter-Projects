{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMguPZKS92CeboaSEUp4Wty",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abhiss123/AlmaBetter-Projects/blob/main/AI_Powered_Deep_Learning_Image_SEO_Enhancer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name:- AI-Powered Deep Learning Image SEO Enhancer**\n",
        "\n",
        "### **Purpose of the Project:**\n",
        "\n",
        "The purpose of this project is to use artificial intelligence (AI) and deep learning techniques to analyze and optimize images on a website for **SEO (Search Engine Optimization)**. By enhancing images in this way, the project aims to make them more discoverable by search engines like Google, improve accessibility for users (especially those who rely on screen readers), and ultimately help drive more traffic and visibility to the website.\n",
        "\n",
        "**To understand why this is important, let's break down some key terms:**\n",
        "- **Search Engine Optimization (SEO)**: This is the process of making a website more visible to people who are searching for relevant content using search engines like Google. For images, this involves using keywords, descriptions, and other elements that help search engines understand what the image is about.\n",
        "- **Deep Learning**: This is a form of AI that mimics the way the human brain works. It can learn from large amounts of data to recognize patterns and make decisions. In this project, it helps analyze and understand the content of images.\n",
        "\n",
        "#### **Detailed Breakdown of the Purpose:**\n",
        "\n",
        "1. **Automatically Generate Tags for Images**:\n",
        "   - **What this means**: The deep learning model analyzes each image and generates descriptive tags (keywords) that represent what the image contains. For example, if the image is of a \"book jacket,\" the model might generate tags like \"book,\" \"cover,\" and \"jacket.\"\n",
        "   - **Why it matters**: These tags help search engines better understand what the image is about, making it easier for people to find the image when they search online. This can increase website traffic.\n",
        "\n",
        "2. **Improve Alt Text for Images**:\n",
        "   - **What this means**: Alt text (alternative text) is a description of an image that is displayed when the image cannot be shown. It is also used by screen readers to describe images to visually impaired users.\n",
        "   - **Why it matters**: Many images on websites either have no alt text or have alt text that is not very helpful. This project uses AI to automatically create meaningful and descriptive alt text for each image, improving accessibility and helping search engines understand the image's content.\n",
        "\n",
        "3. **Categorize Images Based on Content**:\n",
        "   - **What this means**: The model groups images into categories based on what it \"sees\" in the image. For example, if the model detects that an image shows a book cover, it might categorize it as \"Books.\"\n",
        "   - **Why it matters**: Categorizing images makes it easier to organize and display them on a website. It also helps users find related images more easily and can improve the overall user experience.\n",
        "\n",
        "4. **Enhance Metadata for SEO**:\n",
        "   - **What this means**: Metadata is additional information about an image, like its tags, alt text, and category. This project enriches the metadata with detailed descriptions that are optimized for search engines.\n",
        "   - **Why it matters**: Enhanced metadata improves the chances of an image appearing in search engine results, driving more traffic to the website. It also helps search engines better understand the context of each image, making them more relevant for users.\n",
        "\n",
        "#### **Practical Benefits for a Website Owner:**\n",
        "\n",
        "1. **Increased Visibility**: Optimized images are more likely to appear in search engine results, which can attract more visitors to the website.\n",
        "2. **Better User Experience**: Improved alt text and image categorization make the website more accessible and user-friendly, especially for visually impaired users.\n",
        "3. **Higher Engagement**: When users can easily find and understand images, they are more likely to engage with the website, leading to higher retention rates and potentially more sales or conversions.\n",
        "4. **Streamlined Image Management**: Automated tagging and categorization make it easier to manage large image libraries, saving time and effort.\n"
      ],
      "metadata": {
        "id": "3yZHAdnIxasB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Deep Learning for Image SEO:**\n",
        "\n",
        "#### What is Deep Learning for Image SEO?\n",
        "\n",
        "Deep Learning for Image SEO (Search Engine Optimization) focuses on using advanced AI models to automatically recognize, tag, and enhance the discoverability of images on websites. This is achieved using a form of deep learning called Convolutional Neural Networks (CNNs), which are especially effective in processing and understanding visual content like images. CNNs can learn to detect patterns, features, and objects within images, allowing for improved labeling, categorization, and overall SEO optimization, meaning your website images become more searchable and rank higher on search engines like Google.\n",
        "\n",
        "#### **Use Cases of Deep Learning for Image SEO**\n",
        "\n",
        "1. **Automatic Image Tagging**: Using CNNs, images on a website can be automatically tagged with relevant keywords based on what the AI identifies. This tagging can make images more accessible in search results, boosting the website's traffic.\n",
        "2. **Enhanced Image Descriptions (Alt Text)**: CNN models can generate or improve descriptive alternative text for images, enhancing accessibility and SEO ranking.\n",
        "3. **Content-Based Image Retrieval**: For websites with large image databases (e.g., e-commerce sites), deep learning can enable better user search results based on the image's content, leading to more relevant suggestions.\n",
        "4. **Image Categorization**: Deep learning can group and categorize images based on recognized features (e.g., clothing type in a fashion store) to optimize user navigation and content discovery.\n",
        "5. **Image Quality Enhancement**: Techniques like image super-resolution or noise reduction can enhance image quality for better user experience and SEO.\n",
        "\n",
        "#### **Real-Life Implementations**\n",
        "\n",
        "1. **E-Commerce Websites**: Sites like Amazon or eBay use image recognition to automatically tag product images, making them searchable by features such as color, shape, or product type.\n",
        "2. **Social Media Platforms**: Platforms such as Instagram use deep learning to recommend relevant hashtags or group similar content.\n",
        "3. **Search Engines**: Google’s reverse image search relies heavily on deep learning models like CNNs to understand and categorize images based on visual content.\n",
        "\n",
        "#### **Website Context Use Case Explanation**\n",
        "\n",
        "For website owners, Deep Learning for Image SEO can improve how images are indexed and discovered by search engines. Suppose you own an online store. By using a deep learning model, your website’s images could be tagged automatically with terms like \"red leather jacket\" or \"modern lamp,\" based on their content. This makes the images more searchable and likely to appear in Google’s image results, driving more organic traffic to your site.\n",
        "\n",
        "#### **Data Requirements for Deep Learning for Image SEO**\n",
        "\n",
        "To train and use a Deep Learning for Image SEO model, the following data inputs are typically required:\n",
        "- **Image Files**: The model needs access to the images you want to optimize (e.g., product photos).\n",
        "- **Labels/Tags**: In some cases, labeled training data might be needed, especially when customizing the model for specific image categories.\n",
        "- **Webpage URLs (Optional)**: If you want the model to associate images with specific web pages or text content, URLs can be provided.\n",
        "- **CSV Files (Optional)**: CSV files can store metadata like image names, current tags, or related descriptions, which the model may use to enhance context during processing.\n",
        "\n",
        "For a non-tech approach, data can be supplied as images directly or in CSV files with metadata. The model processes these inputs to produce outputs such as automatic tags, alt texts, and optimized metadata for images on your website.\n",
        "\n",
        "#### **Expected Output from the Model**\n",
        "\n",
        "The output from a Deep Learning for Image SEO model includes:\n",
        "1. **Auto-Generated Tags**: Relevant tags for each image, aiding in SEO.\n",
        "2. **Improved Alt Text**: Descriptive alt text that aligns with image content and enhances accessibility.\n",
        "3. **Categorization Data**: Grouping of images into categories, useful for better display and user navigation.\n",
        "4. **Enhanced Metadata**: SEO-rich metadata that improves image search rankings.\n",
        "\n",
        "#### **Practical Example**\n",
        "\n",
        "Imagine a website selling artwork. When you upload images of paintings, a deep learning model scans the image and generates tags like \"abstract art,\" \"blue tones,\" and \"oil on canvas.\" It can also create descriptive alt text such as \"Blue abstract oil painting with textured strokes.\" This makes it easier for search engines to understand and display your images in relevant search results.\n"
      ],
      "metadata": {
        "id": "foJe7Dl_x4MK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explanation of Labels/Tags\n",
        "\n",
        "When I mentioned **labels/tags**, I was referring to descriptive keywords or categories that define the content of images. For example, an image of a red car could have labels like \"car,\" \"vehicle,\" \"red color,\" and \"sedan.\" These tags help the Deep Learning model understand what the image represents. The more accurately labeled data you provide during training, the better the model can learn and make predictions.\n",
        "\n",
        "For non-technical users, here’s how you might provide labels/tags:\n",
        "1. **Manual Labeling**: You can manually assign keywords or categories to your images based on what they depict. This can be done in a spreadsheet (CSV file) where you list image names and their respective tags.\n",
        "2. **Automatic Labeling with Pretrained Models**: You can also use existing image recognition models to automatically generate tags for images, which can then be fine-tuned.\n",
        "\n",
        "### Collecting Data from Webpages with URLs via Web Scraping\n",
        "\n",
        "If the Deep Learning for Image SEO model can collect image details from web pages by using URLs and web scraping. Yes, this is absolutely possible. Here’s how it can be done:\n",
        "\n",
        "1. **Web Scraping Process**:\n",
        "   - You can use web scraping tools like **BeautifulSoup (Python)** or **Scrapy** to fetch the content of web pages, including images.\n",
        "   - The scraper extracts the image URLs, alt texts, and any other metadata associated with the images on your web pages.\n",
        "   - Example: Suppose you have a webpage URL. The web scraping code can extract all image elements (`<img>` tags) and gather the `src` (image URL), `alt` attributes (text descriptions), and other related data.\n",
        "\n",
        "2. **Feeding Data to the Deep Learning Model**:\n",
        "   - Once the data is gathered, you can save it in a structured format (e.g., CSV file) with fields like image URLs, alt text, etc.\n",
        "   - The **Deep Learning for Image SEO** model can then access this data. You can either download the images locally using their URLs or use direct links if your model supports online processing.\n",
        "   - If necessary, additional preprocessing can be done, such as resizing images, converting formats, or extracting features.\n",
        "\n",
        "### How This Works Together\n",
        "\n",
        "- **Step 1**: Use a web scraper to extract images and their metadata (alt text, descriptions) from your webpages using their URLs.\n",
        "- **Step 2**: Save this extracted data in a structured way (CSV file or directly in your code).\n",
        "- **Step 3**: Provide this data to the Deep Learning model. The model can access the images either by downloading them (if needed) or by using URLs to process and analyze them.\n",
        "- **Step 4**: The Deep Learning model will then generate output like enhanced tags, optimized alt text, and other metadata improvements for each image, all of which help improve image SEO for your website.\n",
        "\n",
        "### Possible Challenges and Solutions\n",
        "\n",
        "1. **Web Scraping Challenges**:\n",
        "   - **Rate Limiting**: Some websites may restrict scraping activity, so you need to ensure you respect their policies and use techniques like throttling requests.\n",
        "   - **Dynamic Content**: If your website uses dynamically loaded content (e.g., JavaScript), you may need more advanced scraping tools like **Selenium**.\n",
        "\n",
        "2. **Image Processing**:\n",
        "   - **Storage**: Downloaded images can take up space, so consider whether you want local or online processing.\n",
        "   - **Model Customization**: Depending on your goals, you may want to customize your Deep Learning model to recognize specific features relevant to your website’s niche (e.g., fashion, automobiles).\n",
        "\n",
        "\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "Hv9beIW4yhGB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Applicability of Deep Learning for Image SEO on Non-Product Websites\n",
        "\n",
        "**Yes, a Deep Learning for Image SEO Model can still be useful for non-product-based websites** like thatware.co, but its application and benefits will be slightly different from product-selling sites (e.g., Amazon, Flipkart). Here's how and why it matters:\n",
        "\n",
        "#### Why Deep Learning for Image SEO is Useful for Content Websites\n",
        "\n",
        "1. **Improving Search Engine Visibility**: Even though the images on a site like thatware.co are used to support content rather than sell products, they can still play a crucial role in boosting SEO. Search engines like Google index images and use them as part of how they understand and rank web pages. Therefore, optimizing these images with relevant tags, descriptions, and metadata can increase the chances of the website appearing in image searches, which can bring more traffic to the site.\n",
        "2. **Accessibility**: Descriptive alt text (alternative text) is essential for accessibility. Users with visual impairments who use screen readers rely on this text to understand the content of images. Improved alt text makes your website more inclusive and can positively impact its SEO rankings since search engines prioritize accessible websites.\n",
        "3. **Contextual Relevance**: Since the images on the website are meant to explain or enhance textual content, having accurate and contextually relevant tags and descriptions helps search engines better understand the content on pages. This can improve the relevance of web pages in search results.\n",
        "\n",
        "#### Specific Outputs for thatware.co and Their Relevance\n",
        "\n",
        "1. **Auto-Generated Tags**:\n",
        "   - **Purpose**: Automatically generating tags for each image ensures that each image has meaningful descriptors related to the content it supports. For example, an image on a page about \"SEO strategies\" might be tagged with terms like \"SEO,\" \"digital marketing,\" and \"content strategy.\"\n",
        "   - **Relevance**: This is useful for enhancing discoverability of images on your site in image search results.\n",
        "\n",
        "2. **Improved Alt Text**:\n",
        "   - **Purpose**: Creating accurate and descriptive alt text for images makes the content accessible and helps search engines understand the relevance of the image within the webpage’s context.\n",
        "   - **Relevance**: This is especially important for content-driven sites to ensure inclusivity and better SEO rankings.\n",
        "\n",
        "3. **Categorization Data**:\n",
        "   - **Purpose**: Grouping images into categories (e.g., \"infographics,\" \"graphs,\" \"illustrations\") can help organize visual content and make it easier for users to navigate content-rich pages.\n",
        "   - **Relevance**: While not as critical as for e-commerce sites, it still helps improve user experience, which can positively impact SEO indirectly.\n",
        "\n",
        "4. **Enhanced Metadata**:\n",
        "   - **Purpose**: Adding SEO-rich metadata to images ensures that search engines can understand what each image is about and how it relates to the overall webpage content.\n",
        "   - **Relevance**: For sites like thatware.co, having relevant metadata increases the chances of pages being indexed accurately by search engines, boosting overall visibility.\n",
        "\n"
      ],
      "metadata": {
        "id": "tiFC_yHyy-0_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. **Part 1: Image Data Collection and Scraping**\n",
        "   - **Name**: **\"Image Data Scraper\"**\n",
        "   - **What It Does**: This part of the code collects image data from specified web pages.\n",
        "   - **Purpose**: This script goes through a list of URLs, fetches the HTML content of each page, extracts image information (like image URLs, alt text, and other metadata), and saves this data to a CSV file.\n",
        "   - **Why It's Important**: This part is the first step in building a dataset of images from a website. It helps you gather information on all the images present on the provided web pages, which will be used later for SEO enhancement.\n",
        "\n",
        "   - **Key Steps**:\n",
        "     1. **Sending HTTP Requests**: Fetches the HTML content of each URL.\n",
        "     2. **Parsing HTML**: Extracts `<img>` tags to find images on each page.\n",
        "     3. **Extracting Image Data**: Retrieves image URLs, alt text (if available), and other metadata like width, height, etc.\n",
        "     4. **Saving to CSV**: Saves this collected data in a structured format (CSV).\n"
      ],
      "metadata": {
        "id": "vR1-61aYyD3f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests  # Library for sending HTTP requests to access web content\n",
        "from bs4 import BeautifulSoup  # Library for parsing HTML content\n",
        "import pandas as pd  # Library for creating and managing data tables (DataFrames)\n",
        "from urllib.parse import urljoin  # Utility to handle relative URLs and convert them to absolute URLs\n",
        "\n",
        "# List of URLs to scrape\n",
        "urls = [\n",
        "    'https://thatware.co/',\n",
        "    'https://thatware.co/services/',\n",
        "    'https://thatware.co/advanced-seo-services/',\n",
        "    'https://thatware.co/digital-marketing-services/',\n",
        "    'https://thatware.co/business-intelligence-services/',\n",
        "    'https://thatware.co/link-building-services/',\n",
        "    'https://thatware.co/branding-press-release-services/',\n",
        "    'https://thatware.co/conversion-rate-optimization/',\n",
        "    'https://thatware.co/social-media-marketing/',\n",
        "    'https://thatware.co/content-proofreading-services/',\n",
        "    'https://thatware.co/website-design-services/',\n",
        "    'https://thatware.co/web-development-services/',\n",
        "    'https://thatware.co/app-development-services/',\n",
        "    'https://thatware.co/website-maintenance-services/',\n",
        "    'https://thatware.co/bug-testing-services/',\n",
        "    'https://thatware.co/software-development-services/',\n",
        "    'https://thatware.co/competitor-keyword-analysis/'\n",
        "]\n",
        "\n",
        "# A list to store the data we scrape from each webpage\n",
        "data = []\n",
        "\n",
        "# Function to scrape image data from a given URL\n",
        "def scrape_images(url):\n",
        "    try:\n",
        "        # Step 1: Send a request to the URL to get the webpage content\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()  # Raise an error if the request fails (e.g., page not found)\n",
        "\n",
        "        # Step 2: Parse the HTML content of the webpage using BeautifulSoup\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # Step 3: Find all <img> (image) tags on the webpage\n",
        "        images = soup.find_all('img')\n",
        "\n",
        "        # Step 4: Loop through each image tag found\n",
        "        for img in images:\n",
        "            # Extract the 'src' (source) attribute of the image, which gives the URL of the image\n",
        "            img_url = img.get('src')\n",
        "            # If the 'src' URL is relative (not a full URL), convert it to an absolute URL\n",
        "            if img_url:\n",
        "                img_url = urljoin(url, img_url)\n",
        "\n",
        "            # Extract the 'alt' text of the image, or use a default value if 'alt' is missing\n",
        "            alt_text = img.get('alt') if img.get('alt') else 'No alt text available'\n",
        "\n",
        "            # Collecting additional metadata from the image tag (other attributes)\n",
        "            metadata = img.attrs  # This captures all attributes of the <img> tag in a dictionary\n",
        "\n",
        "            # Add the extracted information to the data list as a dictionary\n",
        "            data.append({\n",
        "                'Page URL': url,  # The URL of the page where the image was found\n",
        "                'Image URL': img_url,  # The URL of the image\n",
        "                'Alt Text': alt_text,  # The alternative text of the image\n",
        "                'Metadata': metadata  # Additional attributes of the image\n",
        "            })\n",
        "\n",
        "    except requests.RequestException as e:\n",
        "        # Handle any errors that occur during the request (e.g., network issues, 404 errors)\n",
        "        print(f\"Error fetching URL {url}: {e}\")\n",
        "\n",
        "# Step 5: Loop through each URL in the 'urls' list and scrape images from each page\n",
        "for url in urls:\n",
        "    scrape_images(url)\n",
        "\n",
        "# Step 6: Convert the collected data into a DataFrame for easy management and export\n",
        "image_data_df = pd.DataFrame(data)\n",
        "\n",
        "# Display the first 5 rows of the image data for verification\n",
        "print(\"Image Data Preview:\")\n",
        "print(image_data_df.head())  # This shows the first 5 rows of the data\n",
        "\n",
        "# Step 7: Save the collected data to a CSV file for further analysis or processing\n",
        "image_data_df.to_csv('image_data.csv', index=False)\n",
        "\n",
        "# Indicate completion of the data scraping process\n",
        "print(\"Image data has been successfully scraped and saved to 'image_data.csv'\")\n"
      ],
      "metadata": {
        "id": "jd_xb2wcTiHx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc25e50b-0a98-4708-ba8e-14c2ffdbcaf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image Data Preview:\n",
            "               Page URL                                          Image URL  \\\n",
            "0  https://thatware.co/  https://www.facebook.com/tr?id=152193597153558...   \n",
            "1  https://thatware.co/  https://thatware.co/wp-content/uploads/2023/03...   \n",
            "2  https://thatware.co/  https://thatware.co/wp-content/uploads/2024/11...   \n",
            "3  https://thatware.co/  data:image/svg+xml,%3Csvg%20xmlns='http://www....   \n",
            "4  https://thatware.co/  https://thatware.co/wp-content/uploads/2023/12...   \n",
            "\n",
            "                Alt Text                                           Metadata  \n",
            "0  No alt text available  {'height': '1', 'width': '1', 'style': 'displa...  \n",
            "1               Thatware  {'src': 'https://thatware.co/wp-content/upload...  \n",
            "2  Thatware Achievements  {'src': 'https://thatware.co/wp-content/upload...  \n",
            "3             Case Study  {'src': 'data:image/svg+xml,%3Csvg%20xmlns='ht...  \n",
            "4             Case Study  {'src': 'https://thatware.co/wp-content/upload...  \n",
            "Image data has been successfully scraped and saved to 'image_data.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### Explanation of the Code\n",
        "\n",
        "#### Importing Libraries\n",
        "```python\n",
        "import requests  # Library for sending HTTP requests to access web content\n",
        "from bs4 import BeautifulSoup  # Library for parsing HTML content\n",
        "import pandas as pd  # Library for creating and managing data tables (DataFrames)\n",
        "from urllib.parse import urljoin  # Utility to handle relative URLs and convert them to absolute URLs\n",
        "```\n",
        "- **`requests`**: This library allows us to send HTTP requests to websites and retrieve their content (e.g., HTML pages). Imagine this like visiting a webpage and getting its data for further processing.\n",
        "- **`BeautifulSoup`**: This library is used to parse HTML and XML documents. It helps in finding and extracting specific parts of a webpage, such as images, text, etc., from the HTML code.\n",
        "- **`pandas`**: This library is used for data manipulation and analysis, making it easy to work with tables (data frames) like those in Excel.\n",
        "- **`urljoin`**: This function helps combine base URLs with relative URLs to create complete (absolute) URLs for images.\n",
        "\n",
        "#### List of URLs to Scrape\n",
        "```python\n",
        "# List of URLs to scrape\n",
        "urls = [\n",
        "    'https://thatware.co/',\n",
        "    'https://thatware.co/services/',\n",
        "    'https://thatware.co/advanced-seo-services/',\n",
        "    # ... more URLs\n",
        "]\n",
        "```\n",
        "- **Purpose**: This is a list of website pages that you want to scrape images from. Each URL represents a webpage from which images will be collected.\n",
        "- **Example**: If you want to get images from a homepage and a services page, you add their URLs here.\n",
        "\n",
        "#### Data Storage List\n",
        "```python\n",
        "# A list to store the data we scrape from each webpage\n",
        "data = []\n",
        "```\n",
        "- **Purpose**: This empty list will be used to store the data (like image URLs, alt text, and metadata) that we extract from each webpage.\n",
        "\n",
        "#### Function to Scrape Images\n",
        "```python\n",
        "# Function to scrape image data from a given URL\n",
        "def scrape_images(url):\n",
        "    try:\n",
        "        # Step 1: Send a request to the URL to get the webpage content\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()  # Raise an error if the request fails (e.g., page not found)\n",
        "```\n",
        "- **Explanation**: This function takes a URL as input and tries to fetch the webpage content using the `requests` library. If it fails (e.g., if the page doesn’t exist), an error will be raised.\n",
        "\n",
        "```python\n",
        "        # Step 2: Parse the HTML content of the webpage using BeautifulSoup\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "```\n",
        "- **Explanation**: Here, the HTML content of the webpage is parsed using `BeautifulSoup`. This makes it easier to navigate and extract specific parts of the webpage.\n",
        "\n",
        "```python\n",
        "        # Step 3: Find all <img> (image) tags on the webpage\n",
        "        images = soup.find_all('img')\n",
        "```\n",
        "- **Explanation**: This line searches for all `<img>` tags in the HTML. These tags represent images on the webpage. If a webpage has five images, it will find all five.\n",
        "\n",
        "#### Loop to Extract Image Information\n",
        "```python\n",
        "        # Step 4: Loop through each image tag found\n",
        "        for img in images:\n",
        "            # Extract the 'src' (source) attribute of the image, which gives the URL of the image\n",
        "            img_url = img.get('src')\n",
        "            # If the 'src' URL is relative (not a full URL), convert it to an absolute URL\n",
        "            if img_url:\n",
        "                img_url = urljoin(url, img_url)\n",
        "```\n",
        "- **Explanation**: This loop goes through each image found on the webpage. It extracts the `src` attribute, which holds the image’s URL.\n",
        "- **`urljoin`**: If the image URL is not a complete URL (e.g., it starts with `/images/example.jpg`), this function converts it into a full URL (e.g., `https://thatware.co/images/example.jpg`).\n",
        "\n",
        "```python\n",
        "            # Extract the 'alt' text of the image, or use a default value if 'alt' is missing\n",
        "            alt_text = img.get('alt') if img.get('alt') else 'No alt text available'\n",
        "```\n",
        "- **Explanation**: The `alt` attribute provides a text description of the image, useful for accessibility and SEO. If no `alt` text is present, we set it to 'No alt text available'.\n",
        "\n",
        "```python\n",
        "            # Collecting additional metadata from the image tag (other attributes)\n",
        "            metadata = img.attrs  # This captures all attributes of the <img> tag in a dictionary\n",
        "```\n",
        "- **Explanation**: This line captures all the attributes of the `<img>` tag (e.g., width, height) and stores them in a dictionary called `metadata`.\n",
        "\n",
        "#### Storing the Extracted Data\n",
        "```python\n",
        "            # Add the extracted information to the data list as a dictionary\n",
        "            data.append({\n",
        "                'Page URL': url,  # The URL of the page where the image was found\n",
        "                'Image URL': img_url,  # The URL of the image\n",
        "                'Alt Text': alt_text,  # The alternative text of the image\n",
        "                'Metadata': metadata  # Additional attributes of the image\n",
        "            })\n",
        "```\n",
        "- **Explanation**: This line creates a dictionary with the collected data (page URL, image URL, alt text, and metadata) and adds it to the `data` list.\n",
        "\n",
        "#### Handling Request Errors\n",
        "```python\n",
        "    except requests.RequestException as e:\n",
        "        # Handle any errors that occur during the request (e.g., network issues, 404 errors)\n",
        "        print(f\"Error fetching URL {url}: {e}\")\n",
        "```\n",
        "- **Explanation**: If there is an issue fetching a webpage (e.g., it doesn’t exist or there’s a network error), this `except` block prints an error message.\n",
        "\n",
        "#### Loop to Scrape All URLs\n",
        "```python\n",
        "# Step 5: Loop through each URL in the 'urls' list and scrape images from each page\n",
        "for url in urls:\n",
        "    scrape_images(url)\n",
        "```\n",
        "- **Explanation**: This loop goes through each URL in the `urls` list and calls the `scrape_images` function to extract image data from each webpage.\n",
        "\n",
        "#### Creating a DataFrame and Saving the Data\n",
        "```python\n",
        "# Step 6: Convert the collected data into a DataFrame for easy management and export\n",
        "image_data_df = pd.DataFrame(data)\n",
        "\n",
        "# Display the first 5 rows of the image data for verification\n",
        "print(\"Image Data Preview:\")\n",
        "print(image_data_df.head())  # This shows the first 5 rows of the data\n",
        "\n",
        "# Step 7: Save the collected data to a CSV file for further analysis or processing\n",
        "image_data_df.to_csv('image_data.csv', index=False)\n",
        "\n",
        "# Indicate completion of the data scraping process\n",
        "print(\"Image data has been successfully scraped and saved to 'image_data.csv'\")\n",
        "```\n",
        "- **Explanation**:\n",
        "  - The data collected is converted into a DataFrame using `pandas` for easy viewing and manipulation.\n",
        "  - `print(image_data_df.head())`: This displays the first 5 rows of the data to check what was collected.\n",
        "  - `image_data_df.to_csv(...)`: This saves the collected data to a CSV file named 'image_data.csv', which can be opened in Excel or used for further processing.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "fmWqXzznthtI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. **Part 2: Data Cleaning and Filtering**\n",
        "   - **Name**: **\"Image Data Cleaner\"**\n",
        "   - **What It Does**: This part of the code cleans and filters the image data collected in the first part.\n",
        "   - **Purpose**: It removes irrelevant or unnecessary entries from the dataset to ensure only useful data remains for further processing.\n",
        "   - **Why It's Important**: Cleaning the data helps remove noise and ensures that only relevant images are analyzed. It focuses on images from specific domains and removes entries like SVG images or invalid URLs.\n",
        "\n",
        "   - **Key Steps**:\n",
        "     1. **Loading the Dataset**: Reads the CSV file created by the first part.\n",
        "     2. **Removing Unwanted Entries**: Excludes SVG images, data URIs, or invalid URLs.\n",
        "     3. **Domain Filtering**: Keeps only images that belong to a specific domain (e.g., 'thatware.co').\n",
        "     4. **Saving the Cleaned Data**: Writes the cleaned data to a new CSV file for further use.\n"
      ],
      "metadata": {
        "id": "EJF5FU9yyNoo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd  # Importing the pandas library for working with data tables (DataFrames)\n",
        "\n",
        "# Step 1: Load the input dataset\n",
        "# Explanation: This section loads the data we collected in the first part of the project.\n",
        "# The 'image_data.csv' file should already exist as it was generated in the previous step.\n",
        "input_file_path = 'image_data.csv'  # Path to the file containing the scraped image data\n",
        "try:\n",
        "    image_data_df = pd.read_csv(input_file_path)  # Read the CSV file into a DataFrame\n",
        "except FileNotFoundError:\n",
        "    # If the file is not found, print an error message and exit the script\n",
        "    print(f\"Error: The file '{input_file_path}' was not found. Please ensure the file exists and try again.\")\n",
        "    exit()\n",
        "\n",
        "# Step 2: Data Cleaning Function\n",
        "# Explanation: This function cleans the data by removing unnecessary entries. The goal is to keep only relevant image data.\n",
        "def clean_image_data(dataframe):\n",
        "    # Step 2.1: Remove entries with SVG placeholders or non-HTTP URLs\n",
        "    # Explanation: SVG images are vector graphics and often not relevant for image SEO.\n",
        "    # Non-HTTP URLs may point to local or invalid resources, so we exclude them.\n",
        "    dataframe = dataframe[~dataframe['Image URL'].str.contains('data:image/svg+xml', na=False)]  # Remove SVG images\n",
        "    dataframe = dataframe[dataframe['Image URL'].str.startswith('http', na=False)]  # Keep only URLs starting with 'http'\n",
        "\n",
        "    # Step 2.2: Retain only entries from a specific domain ('thatware.co')\n",
        "    # Explanation: This ensures that we are only analyzing images from the 'thatware.co' domain.\n",
        "    # Images from other domains may not be relevant to our analysis.\n",
        "    dataframe = dataframe[dataframe['Image URL'].str.contains('thatware.co', na=False)]  # Keep only URLs from 'thatware.co'\n",
        "\n",
        "    # Return the cleaned DataFrame\n",
        "    return dataframe\n",
        "\n",
        "# Step 3: Apply the cleaning function to the loaded data\n",
        "# Explanation: The function is applied to clean the data based on the criteria defined above.\n",
        "cleaned_image_data_df = clean_image_data(image_data_df)\n",
        "\n",
        "# Step 4: Save the cleaned data to a new CSV file\n",
        "# Explanation: We save the cleaned data so it can be used for further processing or analysis in the next steps.\n",
        "cleaned_output_file_path = 'cleaned_image_output.csv'  # Output file name\n",
        "cleaned_image_data_df.to_csv(cleaned_output_file_path, index=False)  # Save the DataFrame to a CSV file\n",
        "\n",
        "# Step 5: Display the first 5 rows of the cleaned dataset for verification\n",
        "# Explanation: Displaying the first 5 rows allows us to quickly verify that the data has been cleaned correctly.\n",
        "print(\"Cleaned Image Data Preview:\")\n",
        "print(cleaned_image_data_df.head())\n",
        "\n",
        "# Step 6: Provide a completion message\n",
        "# Explanation: A completion message lets the user know that the cleaning process was successful.\n",
        "print(f\"Cleaned data has been saved to '{cleaned_output_file_path}'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eWtN-LyjEG7",
        "outputId": "4b87454a-a446-4609-e095-6b4497b4931e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned Image Data Preview:\n",
            "               Page URL                                          Image URL  \\\n",
            "1  https://thatware.co/  https://thatware.co/wp-content/uploads/2023/03...   \n",
            "2  https://thatware.co/  https://thatware.co/wp-content/uploads/2024/11...   \n",
            "4  https://thatware.co/  https://thatware.co/wp-content/uploads/2023/12...   \n",
            "6  https://thatware.co/  https://thatware.co/wp-content/uploads/2023/12...   \n",
            "8  https://thatware.co/  https://thatware.co/wp-content/uploads/2023/12...   \n",
            "\n",
            "                Alt Text                                           Metadata  \n",
            "1               Thatware  {'src': 'https://thatware.co/wp-content/upload...  \n",
            "2  Thatware Achievements  {'src': 'https://thatware.co/wp-content/upload...  \n",
            "4             Case Study  {'src': 'https://thatware.co/wp-content/upload...  \n",
            "6               Client 1  {'src': 'https://thatware.co/wp-content/upload...  \n",
            "8               Client 2  {'src': 'https://thatware.co/wp-content/upload...  \n",
            "Cleaned data has been saved to 'cleaned_image_output.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### Explanation of the Code:\n",
        "\n",
        "#### Importing Required Library\n",
        "```python\n",
        "import pandas as pd  # Importing the pandas library for working with data tables (DataFrames)\n",
        "```\n",
        "- **Explanation**: The `pandas` library is used to work with data in table-like structures, similar to Excel sheets. It makes it easy to manipulate and analyze data.\n",
        "- **Example**: If you have a table of image data, `pandas` lets you view, clean, and modify the data.\n",
        "\n",
        "#### Step 1: Load the Input Dataset\n",
        "```python\n",
        "input_file_path = 'image_data.csv'  # Path to the file containing the scraped image data\n",
        "try:\n",
        "    image_data_df = pd.read_csv(input_file_path)  # Read the CSV file into a DataFrame\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file '{input_file_path}' was not found. Please ensure the file exists and try again.\")\n",
        "    exit()\n",
        "```\n",
        "- **Explanation**: This block loads the data that was previously scraped and saved into a CSV file named 'image_data.csv'. If the file doesn't exist, an error message is printed.\n",
        "- **Use Case**: This ensures we have data to work with. If the file is missing, it prevents further processing, which would result in errors.\n",
        "- **Example**: Imagine you have data about images saved in an Excel-like file (CSV). This code reads that data into a table (DataFrame) for further processing.\n",
        "\n",
        "#### Step 2: Data Cleaning Function\n",
        "```python\n",
        "def clean_image_data(dataframe):\n",
        "    # Step 2.1: Remove entries with SVG placeholders or non-HTTP URLs\n",
        "    dataframe = dataframe[~dataframe['Image URL'].str.contains('data:image/svg+xml', na=False)]  # Remove SVG images\n",
        "    dataframe = dataframe[dataframe['Image URL'].str.startswith('http', na=False)]  # Keep only URLs starting with 'http'\n",
        "\n",
        "    # Step 2.2: Retain only entries from a specific domain ('thatware.co')\n",
        "    dataframe = dataframe[dataframe['Image URL'].str.contains('thatware.co', na=False)]  # Keep only URLs from 'thatware.co'\n",
        "\n",
        "    return dataframe\n",
        "```\n",
        "- **Explanation**:\n",
        "  - **Purpose**: This function cleans the data by filtering out unwanted entries based on specific criteria.\n",
        "  - **Step 2.1**: The first two lines remove:\n",
        "    - Entries with SVG images (often vector images used in web design). SVG images may not be relevant for image SEO.\n",
        "    - URLs that don't start with 'http' (e.g., data URIs or invalid URLs).\n",
        "    - **Example**: If an entry has an image URL like `'data:image/svg+xml,...'`, it will be removed because it's not relevant for our analysis.\n",
        "  - **Step 2.2**: The next line filters out images that do not belong to the 'thatware.co' domain.\n",
        "    - **Use Case**: This is useful when you only want to focus on images hosted on a specific website.\n",
        "    - **Example**: If an image URL points to a third-party site like `https://example.com/image.jpg`, it will be excluded.\n",
        "\n",
        "#### Step 3: Apply the Cleaning Function to the Loaded Data\n",
        "```python\n",
        "cleaned_image_data_df = clean_image_data(image_data_df)\n",
        "```\n",
        "- **Explanation**: This line applies the cleaning function to the loaded data. The result is a cleaned DataFrame that contains only relevant image data.\n",
        "- **Use Case**: Ensures that the data used in further analysis is accurate and relevant.\n",
        "\n",
        "#### Step 4: Save the Cleaned Data to a New CSV File\n",
        "```python\n",
        "cleaned_output_file_path = 'cleaned_image_output.csv'  # Output file name\n",
        "cleaned_image_data_df.to_csv(cleaned_output_file_path, index=False)  # Save the DataFrame to a CSV file\n",
        "```\n",
        "- **Explanation**: This saves the cleaned data to a new CSV file named 'cleaned_image_output.csv'.\n",
        "- **Use Case**: Storing cleaned data allows you to use it later without needing to repeat the cleaning process.\n",
        "- **Example**: You now have a new file with only the cleaned image data that you can use for further analysis.\n",
        "\n",
        "#### Step 5: Display the First 5 Rows of the Cleaned Dataset for Verification\n",
        "```python\n",
        "print(\"Cleaned Image Data Preview:\")\n",
        "print(cleaned_image_data_df.head())\n",
        "```\n",
        "- **Explanation**: This prints the first 5 rows of the cleaned data, making it easy to quickly verify that the data has been cleaned correctly.\n",
        "- **Example**: If your cleaned data contains 100 entries, this will show the first 5 so you can check for issues.\n",
        "\n",
        "#### Step 6: Provide a Completion Message\n",
        "```python\n",
        "print(f\"Cleaned data has been saved to '{cleaned_output_file_path}'\")\n",
        "```\n",
        "- **Explanation**: This is a simple print statement to let the user know that the data cleaning process has completed successfully.\n",
        "- **Use Case**: It confirms that the cleaned data has been saved.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "lt0vV87_uToT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. **Part 3: Image Data Enhancement with Deep Learning**\n",
        "   - **Name**: **\"Deep Learning Image Enhancer\"**\n",
        "   - **What It Does**: This part of the code enhances the image data by analyzing each image using a pre-trained deep learning model (ResNet50).\n",
        "   - **Purpose**: The model recognizes and categorizes the content of each image, generates relevant tags, improves the alt text, and adds categorization and metadata enhancements.\n",
        "   - **Why It's Important**: This step uses artificial intelligence to analyze the images and generate SEO-friendly data, which can improve the visibility and accessibility of images on search engines.\n",
        "\n",
        "   - **Key Steps**:\n",
        "     1. **Loading a Pre-trained Model**: Uses ResNet50, a deep learning model trained to recognize objects in images.\n",
        "     2. **Fetching and Preprocessing Images**: Downloads and prepares images for analysis by resizing and converting them to a format the model can understand.\n",
        "     3. **Generating Tags**: Uses the model to generate descriptive tags for each image based on its content.\n",
        "     4. **Improving Alt Text**: Creates new alt text using the generated tags.\n",
        "     5. **Categorization and Metadata Enhancement**: Categorizes each image and creates additional metadata to improve its SEO value.\n",
        "     6. **Saving the Enhanced Data**: Writes the enhanced data to a new CSV file.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "umLEOYKHyUX7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests  # Importing requests library to handle HTTP requests and fetch images from URLs\n",
        "from PIL import Image  # Importing the Python Imaging Library to work with images\n",
        "from io import BytesIO  # Utility to handle byte data (used for image conversion)\n",
        "import numpy as np  # NumPy library for numerical computations\n",
        "from tensorflow.keras.applications import ResNet50  # Importing the pre-trained ResNet50 model for image recognition\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions  # Functions for data preprocessing and decoding model predictions\n",
        "import pandas as pd  # Pandas library to manage and manipulate data in tabular form\n",
        "\n",
        "# Load the cleaned dataset produced in the second part\n",
        "input_file_path = 'cleaned_image_output.csv'  # Path to the cleaned dataset\n",
        "cleaned_image_data_df = pd.read_csv(input_file_path)  # Load the CSV file into a DataFrame\n",
        "\n",
        "# Load a pretrained deep learning model (ResNet50) for image recognition tasks\n",
        "# Explanation: ResNet50 is a pre-trained deep learning model that has been trained on millions of images.\n",
        "# It can identify various objects in images, making it useful for generating tags based on image content.\n",
        "model = ResNet50(weights='imagenet')  # Load the model with pre-trained weights from ImageNet\n",
        "\n",
        "# Function to fetch and preprocess images from a URL for analysis\n",
        "def fetch_and_preprocess_image(image_url):\n",
        "    try:\n",
        "        # Step 1: Send an HTTP request to fetch the image from the URL\n",
        "        response = requests.get(image_url)\n",
        "        response.raise_for_status()  # Raise an error if the request fails (e.g., 404 error)\n",
        "        img = Image.open(BytesIO(response.content)).convert('RGB')  # Convert the image to RGB format for compatibility\n",
        "        img = img.resize((224, 224))  # Resize the image to 224x224 pixels (input size expected by ResNet50)\n",
        "        img_array = np.array(img)  # Convert the image to a NumPy array for processing\n",
        "        img_array = np.expand_dims(img_array, axis=0)  # Add an extra dimension (batch size) required by the model\n",
        "        img_array = preprocess_input(img_array)  # Preprocess the image (scaling and normalizing)\n",
        "        return img_array  # Return the processed image array\n",
        "    except requests.RequestException as e:\n",
        "        # Handle any errors during the image request (e.g., network issues)\n",
        "        print(f\"Error fetching image from {image_url}: {e}\")\n",
        "        return None  # Return None if the image could not be fetched\n",
        "\n",
        "# Function to generate tags using the deep learning model\n",
        "def generate_tags(image_array):\n",
        "    # Use the ResNet50 model to make predictions on the image\n",
        "    predictions = model.predict(image_array)\n",
        "    # Decode the predictions into human-readable labels (top 3 results)\n",
        "    decoded_predictions = decode_predictions(predictions, top=3)[0]  # Top 3 predictions\n",
        "    tags = [pred[1] for pred in decoded_predictions]  # Extract the tag names from the predictions\n",
        "    return tags  # Return the generated tags\n",
        "\n",
        "# Function to enhance the data by adding new information using the deep learning model\n",
        "def enhance_image_data(dataframe):\n",
        "    enhanced_data = []  # List to store enhanced data\n",
        "    for index, row in dataframe.iterrows():  # Iterate over each row in the DataFrame\n",
        "        image_url = row['Image URL']  # Extract the image URL from the row\n",
        "        # Use the existing alt text if available; otherwise, use a default description\n",
        "        alt_text = row['Alt Text'] if row['Alt Text'] != 'No alt text available' else \"Default description\"\n",
        "\n",
        "        # Fetch and preprocess the image for deep learning analysis\n",
        "        img_array = fetch_and_preprocess_image(image_url)\n",
        "        if img_array is not None:  # Proceed only if the image was successfully fetched and processed\n",
        "            # Generate tags using the deep learning model\n",
        "            auto_tags = generate_tags(img_array)\n",
        "\n",
        "            # Create improved alt text using the generated tags\n",
        "            improved_alt_text = f\"Image showing {', '.join(auto_tags)}\"\n",
        "\n",
        "            # Categorize the image based on the top generated tag\n",
        "            category = auto_tags[0] if auto_tags else \"Uncategorized\"\n",
        "\n",
        "            # Create a dictionary to store enhanced metadata for the image\n",
        "            enhanced_metadata = {\n",
        "                \"auto_tags\": auto_tags,  # Automatically generated tags\n",
        "                \"improved_alt_text\": improved_alt_text,  # Improved alt text description\n",
        "                \"category\": category  # Categorized label based on content\n",
        "            }\n",
        "\n",
        "            # Add the enhanced data to the list\n",
        "            enhanced_data.append({\n",
        "                \"Page URL\": row['Page URL'],  # Original page URL where the image was found\n",
        "                \"Image URL\": image_url,  # Image URL\n",
        "                \"Original Alt Text\": alt_text,  # Original alt text from the image\n",
        "                \"Generated Tags\": auto_tags,  # Tags generated by the model\n",
        "                \"Improved Alt Text\": improved_alt_text,  # Improved alt text description\n",
        "                \"Category\": category,  # Categorized label\n",
        "                \"Enhanced Metadata\": enhanced_metadata  # Additional metadata\n",
        "            })\n",
        "        else:\n",
        "            # Print a message if the image could not be processed\n",
        "            print(f\"Skipping image at {image_url} due to loading issues.\")\n",
        "\n",
        "    # Convert the enhanced data into a new DataFrame\n",
        "    return pd.DataFrame(enhanced_data)\n",
        "\n",
        "# Apply the enhancement function to the cleaned data\n",
        "enhanced_image_data_df = enhance_image_data(cleaned_image_data_df)\n",
        "\n",
        "# Save the enhanced dataset to a new CSV file\n",
        "enhanced_output_file_path = 'enhanced_image_output.csv'  # Output file path\n",
        "enhanced_image_data_df.to_csv(enhanced_output_file_path, index=False)  # Save the enhanced data to a CSV file\n",
        "\n",
        "# Display the first 5 rows of the enhanced dataset for verification\n",
        "print(\"Enhanced Image Data Preview:\")\n",
        "print(enhanced_image_data_df.head())  # Display the first 5 rows of the enhanced data\n",
        "\n",
        "# Provide a completion message\n",
        "print(f\"Enhanced data has been saved to '{enhanced_output_file_path}'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FI1sVlrvsjz6",
        "outputId": "3f2d9b48-b1d0-4008-ec54-05a276f12c93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340ms/step\n",
            "Enhanced Image Data Preview:\n",
            "               Page URL                                          Image URL  \\\n",
            "0  https://thatware.co/  https://thatware.co/wp-content/uploads/2023/03...   \n",
            "1  https://thatware.co/  https://thatware.co/wp-content/uploads/2024/11...   \n",
            "2  https://thatware.co/  https://thatware.co/wp-content/uploads/2023/12...   \n",
            "3  https://thatware.co/  https://thatware.co/wp-content/uploads/2023/12...   \n",
            "4  https://thatware.co/  https://thatware.co/wp-content/uploads/2023/12...   \n",
            "\n",
            "       Original Alt Text                         Generated Tags  \\\n",
            "0               Thatware  [book_jacket, comic_book, barbershop]   \n",
            "1  Thatware Achievements               [slot, web_site, laptop]   \n",
            "2             Case Study             [web_site, envelope, menu]   \n",
            "3               Client 1     [loudspeaker, face_powder, binder]   \n",
            "4               Client 2       [scoreboard, plate_rack, switch]   \n",
            "\n",
            "                                   Improved Alt Text     Category  \\\n",
            "0  Image showing book_jacket, comic_book, barbershop  book_jacket   \n",
            "1               Image showing slot, web_site, laptop         slot   \n",
            "2             Image showing web_site, envelope, menu     web_site   \n",
            "3     Image showing loudspeaker, face_powder, binder  loudspeaker   \n",
            "4       Image showing scoreboard, plate_rack, switch   scoreboard   \n",
            "\n",
            "                                   Enhanced Metadata  \n",
            "0  {'auto_tags': ['book_jacket', 'comic_book', 'b...  \n",
            "1  {'auto_tags': ['slot', 'web_site', 'laptop'], ...  \n",
            "2  {'auto_tags': ['web_site', 'envelope', 'menu']...  \n",
            "3  {'auto_tags': ['loudspeaker', 'face_powder', '...  \n",
            "4  {'auto_tags': ['scoreboard', 'plate_rack', 'sw...  \n",
            "Enhanced data has been saved to 'enhanced_image_output.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### Explanation of the Code:\n",
        "\n",
        "#### Importing Required Libraries\n",
        "```python\n",
        "import requests  # Importing requests library to handle HTTP requests and fetch images from URLs\n",
        "from PIL import Image  # Importing the Python Imaging Library to work with images\n",
        "from io import BytesIO  # Utility to handle byte data (used for image conversion)\n",
        "import numpy as np  # NumPy library for numerical computations\n",
        "from tensorflow.keras.applications import ResNet50  # Importing the pre-trained ResNet50 model for image recognition\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions  # Functions for data preprocessing and decoding model predictions\n",
        "import pandas as pd  # Pandas library to manage and manipulate data in tabular form\n",
        "```\n",
        "- **Purpose**: These libraries are used to:\n",
        "  - `requests`: Fetch images from the internet using their URLs.\n",
        "  - `PIL (Python Imaging Library)`: Process and transform images.\n",
        "  - `BytesIO`: Handle byte streams for image conversion.\n",
        "  - `NumPy`: Handle numerical operations and create arrays (data structures) for image processing.\n",
        "  - `ResNet50`: A pre-trained model that recognizes and classifies objects in images.\n",
        "  - `pandas`: Work with data in table format, making it easy to process and analyze.\n",
        "\n",
        "#### Loading the Cleaned Dataset\n",
        "```python\n",
        "input_file_path = 'cleaned_image_output.csv'  # Path to the cleaned dataset\n",
        "cleaned_image_data_df = pd.read_csv(input_file_path)  # Load the CSV file into a DataFrame\n",
        "```\n",
        "- **Purpose**: Load the cleaned data from the previous step. This data contains image URLs and metadata from the initial data-cleaning step.\n",
        "- **Example**: If the CSV file contains image data like URLs, alt text, etc., this line reads the file into a data table (DataFrame) for further processing.\n",
        "\n",
        "#### Loading a Pre-trained Deep Learning Model\n",
        "```python\n",
        "model = ResNet50(weights='imagenet')  # Load the model with pre-trained weights from ImageNet\n",
        "```\n",
        "- **Purpose**: Load a deep learning model called ResNet50. This model has been trained on a huge dataset called ImageNet and can recognize thousands of different objects in images.\n",
        "- **Example**: If you provide an image of a cat, the model can tell you it's a cat and may even provide additional categories like \"tabby cat\" or \"Siamese cat\".\n",
        "\n",
        "#### Fetching and Preprocessing Images\n",
        "```python\n",
        "def fetch_and_preprocess_image(image_url):\n",
        "    try:\n",
        "        response = requests.get(image_url)  # Fetch the image from the URL\n",
        "        response.raise_for_status()  # Check if the request was successful\n",
        "        img = Image.open(BytesIO(response.content)).convert('RGB')  # Convert image to RGB\n",
        "        img = img.resize((224, 224))  # Resize image to 224x224 pixels (ResNet50 input size)\n",
        "        img_array = np.array(img)  # Convert image to a NumPy array\n",
        "        img_array = np.expand_dims(img_array, axis=0)  # Add an extra dimension (batch size)\n",
        "        img_array = preprocess_input(img_array)  # Preprocess the image for the model\n",
        "        return img_array  # Return the processed image\n",
        "    except requests.RequestException as e:\n",
        "        print(f\"Error fetching image from {image_url}: {e}\")\n",
        "        return None\n",
        "```\n",
        "- **Purpose**: This function fetches an image from a URL and prepares it for analysis by the deep learning model.\n",
        "- **Example**: If the URL points to an image of a dog, this function fetches the image, resizes it, and prepares it for the model to analyze.\n",
        "- **Why**: Resizing and converting images to a specific format is necessary for the model to work correctly.\n",
        "\n",
        "#### Generating Tags for Images\n",
        "```python\n",
        "def generate_tags(image_array):\n",
        "    predictions = model.predict(image_array)  # Make predictions on the image\n",
        "    decoded_predictions = decode_predictions(predictions, top=3)[0]  # Decode predictions (top 3)\n",
        "    tags = [pred[1] for pred in decoded_predictions]  # Extract tag names\n",
        "    return tags  # Return the generated tags\n",
        "```\n",
        "- **Purpose**: This function uses the model to identify the contents of an image and generate relevant tags (descriptive words) for it.\n",
        "- **Example**: If the image shows a \"car\", the generated tags might include [\"car\", \"vehicle\", \"sedan\"].\n",
        "\n",
        "#### Enhancing Image Data with New Information\n",
        "```python\n",
        "def enhance_image_data(dataframe):\n",
        "    enhanced_data = []  # List to store enhanced data\n",
        "    for index, row in dataframe.iterrows():\n",
        "        image_url = row['Image URL']  # Extract image URL\n",
        "        alt_text = row['Alt Text'] if row['Alt Text'] != 'No alt text available' else \"Default description\"\n",
        "        \n",
        "        img_array = fetch_and_preprocess_image(image_url)  # Fetch and preprocess the image\n",
        "        if img_array is not None:\n",
        "            auto_tags = generate_tags(img_array)  # Generate tags using the model\n",
        "            improved_alt_text = f\"Image showing {', '.join(auto_tags)}\"  # Create improved alt text\n",
        "            category = auto_tags[0] if auto_tags else \"Uncategorized\"  # Categorize based on tags\n",
        "            \n",
        "            enhanced_metadata = {\n",
        "                \"auto_tags\": auto_tags,\n",
        "                \"improved_alt_text\": improved_alt_text,\n",
        "                \"category\": category\n",
        "            }\n",
        "            \n",
        "            enhanced_data.append({\n",
        "                \"Page URL\": row['Page URL'],\n",
        "                \"Image URL\": image_url,\n",
        "                \"Original Alt Text\": alt_text,\n",
        "                \"Generated Tags\": auto_tags,\n",
        "                \"Improved Alt Text\": improved_alt_text,\n",
        "                \"Category\": category,\n",
        "                \"Enhanced Metadata\": enhanced_metadata\n",
        "            })\n",
        "        else:\n",
        "            print(f\"Skipping image at {image_url} due to loading issues.\")\n",
        "    return pd.DataFrame(enhanced_data)\n",
        "```\n",
        "- **Purpose**: This function adds additional useful information to each image using the deep learning model. It creates:\n",
        "  - **Auto-generated tags** for each image.\n",
        "  - **Improved alt text** using these tags.\n",
        "  - **Category labels** based on image content.\n",
        "- **Example**: If the image is a \"laptop\", it might generate tags like [\"laptop\", \"computer\"], improve the alt text, and categorize it as \"laptop\".\n",
        "\n",
        "#### Saving the Enhanced Data\n",
        "```python\n",
        "enhanced_image_data_df = enhance_image_data(cleaned_image_data_df)  # Enhance data\n",
        "enhanced_output_file_path = 'enhanced_image_output.csv'  # Output file path\n",
        "enhanced_image_data_df.to_csv(enhanced_output_file_path, index=False)  # Save enhanced data to CSV\n",
        "print(\"Enhanced Image Data Preview:\")\n",
        "print(enhanced_image_data_df.head())  # Display the first 5 rows of the enhanced data\n",
        "print(f\"Enhanced data has been saved to '{enhanced_output_file_path}'\")\n",
        "```\n",
        "- **Purpose**: This part saves the enhanced data with new tags, improved alt text, and other metadata to a new CSV file.\n",
        "- **Example**: If you previously had a simple \"image URL\" and \"alt text\", now you also have tags, better descriptions, and categories.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "9hVuYsTlu7o9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from urllib.parse import urljoin\n",
        "\n",
        "# List of URLs to scrape\n",
        "urls = [\n",
        "    'https://thatware.co/',\n",
        "    'https://thatware.co/services/',\n",
        "    'https://thatware.co/advanced-seo-services/',\n",
        "    'https://thatware.co/digital-marketing-services/',\n",
        "    'https://thatware.co/business-intelligence-services/',\n",
        "    'https://thatware.co/link-building-services/',\n",
        "    'https://thatware.co/branding-press-release-services/',\n",
        "    'https://thatware.co/conversion-rate-optimization/',\n",
        "    'https://thatware.co/social-media-marketing/',\n",
        "    'https://thatware.co/content-proofreading-services/',\n",
        "    'https://thatware.co/website-design-services/',\n",
        "    'https://thatware.co/web-development-services/',\n",
        "    'https://thatware.co/app-development-services/',\n",
        "    'https://thatware.co/website-maintenance-services/',\n",
        "    'https://thatware.co/bug-testing-services/',\n",
        "    'https://thatware.co/software-development-services/',\n",
        "    'https://thatware.co/competitor-keyword-analysis/'\n",
        "]\n",
        "\n",
        "# Data list to store image information\n",
        "data = []\n",
        "\n",
        "# Function to scrape image data from a given URL\n",
        "def scrape_images(url):\n",
        "    try:\n",
        "        # Send a request to the URL to get the HTML content\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()  # Raise an error if the request fails (e.g., 404)\n",
        "\n",
        "        # Parse the HTML content using BeautifulSoup\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # Find all image tags in the HTML\n",
        "        images = soup.find_all('img')\n",
        "\n",
        "        for img in images:\n",
        "            # Extract the image URL\n",
        "            img_url = img.get('src')\n",
        "            # If the image URL is relative, convert it to an absolute URL\n",
        "            if img_url:\n",
        "                img_url = urljoin(url, img_url)\n",
        "\n",
        "            # Extract the alt text of the image\n",
        "            alt_text = img.get('alt') if img.get('alt') else 'No alt text available'\n",
        "\n",
        "            # Collecting metadata (additional attributes can be extracted as needed)\n",
        "            metadata = img.attrs  # Dictionary of all image attributes\n",
        "\n",
        "            # Add image details to the data list\n",
        "            data.append({\n",
        "                'Page URL': url,\n",
        "                'Image URL': img_url,\n",
        "                'Alt Text': alt_text,\n",
        "                'Metadata': metadata\n",
        "            })\n",
        "\n",
        "    except requests.RequestException as e:\n",
        "        print(f\"Error fetching URL {url}: {e}\")\n",
        "\n",
        "# Iterate over each URL in the list\n",
        "for url in urls:\n",
        "    scrape_images(url)\n",
        "\n",
        "# Convert the collected data into a DataFrame for easy export\n",
        "image_data_df = pd.DataFrame(data)\n",
        "\n",
        "# Save the data to a CSV file\n",
        "image_data_df.to_csv('image_data.csv', index=False)\n",
        "\n",
        "# Output a message indicating completion\n",
        "print(\"Image data has been successfully scraped and saved to 'image_data.csv'\")\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load the input dataset\n",
        "# Note: Replace 'cleaned_image_data.csv' with the actual file path if different\n",
        "input_file_path = 'image_data.csv'  # Corrected to match the expected output from the first part\n",
        "try:\n",
        "    image_data_df = pd.read_csv(input_file_path)\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file '{input_file_path}' was not found. Please ensure the file exists and try again.\")\n",
        "    exit()\n",
        "\n",
        "# Data Cleaning Function\n",
        "def clean_image_data(dataframe):\n",
        "    # Step 1: Remove entries with SVG placeholders or non-HTTP URLs\n",
        "    # Explanation: SVG images (vector graphics) are not relevant for SEO optimization and often use data URIs. Non-HTTP URLs may point to invalid or non-web resources.\n",
        "    dataframe = dataframe[~dataframe['Image URL'].str.contains('data:image/svg+xml', na=False)]\n",
        "    dataframe = dataframe[dataframe['Image URL'].str.startswith('http', na=False)]\n",
        "\n",
        "    # Step 2: Retain only entries from the specified domain (in this case, 'thatware.co')\n",
        "    # Explanation: This ensures we only keep images that belong to the 'thatware.co' domain, as images from other domains may not be relevant.\n",
        "    dataframe = dataframe[dataframe['Image URL'].str.contains('thatware.co', na=False)]\n",
        "\n",
        "    # Return the cleaned DataFrame\n",
        "    return dataframe\n",
        "\n",
        "# Apply the cleaning function to the loaded data\n",
        "cleaned_image_data_df = clean_image_data(image_data_df)\n",
        "\n",
        "# Save the cleaned data to a new CSV file\n",
        "cleaned_output_file_path = 'cleaned_image_output.csv'\n",
        "cleaned_image_data_df.to_csv(cleaned_output_file_path, index=False)\n",
        "\n",
        "# Display the first 5 rows of the cleaned dataset for verification\n",
        "print(\"Cleaned Image Data Preview:\")\n",
        "print(cleaned_image_data_df.head())\n",
        "\n",
        "# Provide a completion message\n",
        "print(f\"Cleaned data has been saved to '{cleaned_output_file_path}'\")\n",
        "\n",
        "\n",
        "\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "import pandas as pd\n",
        "\n",
        "# Load the cleaned dataset produced in the second part\n",
        "input_file_path = 'cleaned_image_output.csv'\n",
        "cleaned_image_data_df = pd.read_csv(input_file_path)\n",
        "\n",
        "# Load a pretrained deep learning model (ResNet50) for image recognition tasks\n",
        "# This model is used to generate relevant tags for images\n",
        "model = ResNet50(weights='imagenet')\n",
        "\n",
        "# Function to fetch and preprocess images from a URL for analysis\n",
        "def fetch_and_preprocess_image(image_url):\n",
        "    try:\n",
        "        # Send a request to fetch the image from the URL\n",
        "        response = requests.get(image_url)\n",
        "        response.raise_for_status()  # Ensure the request was successful\n",
        "        img = Image.open(BytesIO(response.content)).convert('RGB')  # Convert to RGB format\n",
        "        img = img.resize((224, 224))  # Resize image to fit model input size\n",
        "        img_array = np.array(img)\n",
        "        img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "        img_array = preprocess_input(img_array)  # Preprocess the image\n",
        "        return img_array\n",
        "    except requests.RequestException as e:\n",
        "        print(f\"Error fetching image from {image_url}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Function to generate tags using the deep learning model\n",
        "def generate_tags(image_array):\n",
        "    # Use the model to make predictions\n",
        "    predictions = model.predict(image_array)\n",
        "    # Decode the predictions into human-readable labels (top 3 results)\n",
        "    decoded_predictions = decode_predictions(predictions, top=3)[0]\n",
        "    tags = [pred[1] for pred in decoded_predictions]  # Extract tag names\n",
        "    return tags\n",
        "\n",
        "# Data enhancement function using the deep learning model\n",
        "def enhance_image_data(dataframe):\n",
        "    enhanced_data = []\n",
        "    for index, row in dataframe.iterrows():\n",
        "        image_url = row['Image URL']\n",
        "        alt_text = row['Alt Text'] if row['Alt Text'] != 'No alt text available' else \"Default description\"\n",
        "\n",
        "        # Fetch and preprocess the image\n",
        "        img_array = fetch_and_preprocess_image(image_url)\n",
        "        if img_array is not None:\n",
        "            # Generate auto tags\n",
        "            auto_tags = generate_tags(img_array)\n",
        "\n",
        "            # Generate improved alt text (based on generated tags)\n",
        "            improved_alt_text = f\"Image showing {', '.join(auto_tags)}\"\n",
        "\n",
        "            # Categorize based on the top generated tag\n",
        "            category = auto_tags[0] if auto_tags else \"Uncategorized\"\n",
        "\n",
        "            # Enrich metadata\n",
        "            enhanced_metadata = {\n",
        "                \"auto_tags\": auto_tags,\n",
        "                \"improved_alt_text\": improved_alt_text,\n",
        "                \"category\": category\n",
        "            }\n",
        "\n",
        "            # Append the enhanced data to a new list\n",
        "            enhanced_data.append({\n",
        "                \"Page URL\": row['Page URL'],\n",
        "                \"Image URL\": image_url,\n",
        "                \"Original Alt Text\": alt_text,\n",
        "                \"Generated Tags\": auto_tags,\n",
        "                \"Improved Alt Text\": improved_alt_text,\n",
        "                \"Category\": category,\n",
        "                \"Enhanced Metadata\": enhanced_metadata\n",
        "            })\n",
        "        else:\n",
        "            print(f\"Skipping image at {image_url} due to loading issues.\")\n",
        "\n",
        "    # Convert the enhanced data to a DataFrame\n",
        "    return pd.DataFrame(enhanced_data)\n",
        "\n",
        "# Apply the enhancement function to the cleaned data\n",
        "enhanced_image_data_df = enhance_image_data(cleaned_image_data_df)\n",
        "\n",
        "# Save the enhanced dataset to a new CSV file\n",
        "enhanced_output_file_path = 'enhanced_image_output.csv'\n",
        "enhanced_image_data_df.to_csv(enhanced_output_file_path, index=False)\n",
        "\n",
        "# Display the first 5 rows of the enhanced dataset for verification\n",
        "print(\"Enhanced Image Data Preview:\")\n",
        "print(enhanced_image_data_df.head())\n",
        "\n",
        "# Provide a completion message\n",
        "print(f\"Enhanced data has been saved to '{enhanced_output_file_path}'\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUCv4vu9spDD",
        "outputId": "a30cfdbe-e86f-44ee-b5d7-e429c1c71d5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image data has been successfully scraped and saved to 'image_data.csv'\n",
            "Cleaned Image Data Preview:\n",
            "               Page URL                                          Image URL  \\\n",
            "1  https://thatware.co/  https://thatware.co/wp-content/uploads/2023/03...   \n",
            "2  https://thatware.co/  https://thatware.co/wp-content/uploads/2024/11...   \n",
            "4  https://thatware.co/  https://thatware.co/wp-content/uploads/2023/12...   \n",
            "6  https://thatware.co/  https://thatware.co/wp-content/uploads/2023/12...   \n",
            "8  https://thatware.co/  https://thatware.co/wp-content/uploads/2023/12...   \n",
            "\n",
            "                Alt Text                                           Metadata  \n",
            "1               Thatware  {'src': 'https://thatware.co/wp-content/upload...  \n",
            "2  Thatware Achievements  {'src': 'https://thatware.co/wp-content/upload...  \n",
            "4             Case Study  {'src': 'https://thatware.co/wp-content/upload...  \n",
            "6               Client 1  {'src': 'https://thatware.co/wp-content/upload...  \n",
            "8               Client 2  {'src': 'https://thatware.co/wp-content/upload...  \n",
            "Cleaned data has been saved to 'cleaned_image_output.csv'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step\n",
            "Enhanced Image Data Preview:\n",
            "               Page URL                                          Image URL  \\\n",
            "0  https://thatware.co/  https://thatware.co/wp-content/uploads/2023/03...   \n",
            "1  https://thatware.co/  https://thatware.co/wp-content/uploads/2024/11...   \n",
            "2  https://thatware.co/  https://thatware.co/wp-content/uploads/2023/12...   \n",
            "3  https://thatware.co/  https://thatware.co/wp-content/uploads/2023/12...   \n",
            "4  https://thatware.co/  https://thatware.co/wp-content/uploads/2023/12...   \n",
            "\n",
            "       Original Alt Text                         Generated Tags  \\\n",
            "0               Thatware  [book_jacket, comic_book, barbershop]   \n",
            "1  Thatware Achievements               [slot, web_site, laptop]   \n",
            "2             Case Study             [web_site, envelope, menu]   \n",
            "3               Client 1     [loudspeaker, face_powder, binder]   \n",
            "4               Client 2       [scoreboard, plate_rack, switch]   \n",
            "\n",
            "                                   Improved Alt Text     Category  \\\n",
            "0  Image showing book_jacket, comic_book, barbershop  book_jacket   \n",
            "1               Image showing slot, web_site, laptop         slot   \n",
            "2             Image showing web_site, envelope, menu     web_site   \n",
            "3     Image showing loudspeaker, face_powder, binder  loudspeaker   \n",
            "4       Image showing scoreboard, plate_rack, switch   scoreboard   \n",
            "\n",
            "                                   Enhanced Metadata  \n",
            "0  {'auto_tags': ['book_jacket', 'comic_book', 'b...  \n",
            "1  {'auto_tags': ['slot', 'web_site', 'laptop'], ...  \n",
            "2  {'auto_tags': ['web_site', 'envelope', 'menu']...  \n",
            "3  {'auto_tags': ['loudspeaker', 'face_powder', '...  \n",
            "4  {'auto_tags': ['scoreboard', 'plate_rack', 'sw...  \n",
            "Enhanced data has been saved to 'enhanced_image_output.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analysis of the Provided Output\n",
        "\n",
        "1. **Page URL and Image URL**:\n",
        "   - These columns provide the webpage URL where each image is found and the direct URL to the image itself. This information is important for understanding where each image is located on the website and how it can be accessed or linked.\n",
        "\n",
        "2. **Original Alt Text**:\n",
        "   - This column shows the alt text that was originally associated with each image. For images that had alt text, it is preserved. If there was no original alt text, subsequent steps would have created improved alt text.\n",
        "\n",
        "3. **Generated Tags**:\n",
        "   - **Provided**: This column contains a list of tags generated by the Deep Learning model. For example, `['book_jacket', 'comic_book', 'barbershop']` for the first image.\n",
        "   - **Expected**: The output should contain relevant tags generated by the model to aid in SEO.\n",
        "   - **Analysis**: This expectation is met. The generated tags are present and appear to describe the content of the images. While the relevance and accuracy of tags can be further fine-tuned, this is a solid start that improves SEO by associating images with descriptive keywords.\n",
        "\n",
        "4. **Improved Alt Text**:\n",
        "   - **Provided**: This column contains improved alt text generated by the model. The improved text is descriptive and based on the generated tags (e.g., \"Image showing book_jacket, comic_book, barbershop\").\n",
        "   - **Expected**: The output should include descriptive alt text that aligns with the image content and enhances accessibility.\n",
        "   - **Analysis**: This expectation is met. The alt text has been improved to provide a more descriptive and informative description of each image's content. While the structure is templated (\"Image showing ...\"), it still adds significant value compared to missing or generic alt text.\n",
        "\n",
        "5. **Category**:\n",
        "   - **Provided**: This column categorizes each image based on the top generated tag (e.g., `book_jacket`).\n",
        "   - **Expected**: Images should be grouped into categories based on their content to facilitate better display and user navigation.\n",
        "   - **Analysis**: This requirement is met. Categorization based on the top tag provides a simple way to group images. More sophisticated categorization can be explored later, but this approach works for an initial implementation.\n",
        "\n",
        "6. **Enhanced Metadata**:\n",
        "   - **Provided**: This field contains a dictionary with enriched metadata, including `auto_tags`, `improved_alt_text`, and `category`.\n",
        "   - **Expected**: The metadata should be SEO-rich, containing information that improves image search rankings.\n",
        "   - **Analysis**: This requirement is met. The enhanced metadata combines tags, improved alt text, and category data to provide comprehensive information that can improve image searchability and SEO performance.\n",
        "\n",
        "\n",
        "#### Conclusion of the Output:\n",
        "- **Comprehensive Data**: The output includes all expected fields, such as auto-generated tags, improved alt text, categorization, and enhanced metadata.\n",
        "- **Alignment with Expected Results**: The output aligns well with your expectations, as it improves the SEO potential of images by providing descriptive information, meaningful tags, and categorization.\n",
        "- **Improved SEO Potential**: The generated tags, improved alt text, and enhanced metadata collectively provide significant potential for improving the SEO performance of the images.\n",
        "\n"
      ],
      "metadata": {
        "id": "_nrQD77jwQw6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explanation of Each Part of the Output\n",
        "\n",
        "1. **Page URL**:\n",
        "   - **What it is**: This column contains the URL of the webpage where the image is used.\n",
        "   - **Use case**: This helps identify which specific webpage contains the image, providing context for where the image appears. For example, if a business owner wants to understand where images are displayed on their website, this column will give that information.\n",
        "   - **How it can be used**: Knowing which page an image belongs to can help in analyzing how well the image content aligns with the page's purpose and SEO goals. If a webpage is underperforming, you can optimize the images on that page to increase engagement.\n",
        "\n",
        "2. **Image URL**:\n",
        "   - **What it is**: This column shows the direct URL of the image itself.\n",
        "   - **Use case**: This provides a way to directly access or view the image. It can also be used for tasks like verifying that the image loads correctly or optimizing image size and format for faster loading.\n",
        "   - **How it can be used**: You can inspect each image to ensure it is relevant to the page content, properly formatted, and displayed without issues. This can improve user experience and, ultimately, website rankings.\n",
        "\n",
        "3. **Generated Tags**:\n",
        "   - **What it is**: These are tags generated by the Deep Learning model that describe the content of the image. For example, `['book_jacket', 'comic_book', 'barbershop']` might describe the objects or concepts that the model recognized in the image.\n",
        "   - **Use case**: These tags can be used to better understand the image content and ensure it aligns with the page's topic or the website's overall theme.\n",
        "   - **How it can be used**: The tags can be added as keywords or metadata to make the image more discoverable in search engines, improving SEO and driving more traffic to the website.\n",
        "\n",
        "4. **Improved Alt Text**:\n",
        "   - **What it is**: This is alt text generated based on the generated tags. For example, \"Image showing book_jacket, comic_book, barbershop.\"\n",
        "   - **Use case**: The improved alt text provides a more descriptive and relevant description of the image content, enhancing accessibility and helping search engines better index the image.\n",
        "   - **How it can be used**: If the original alt text was missing or inadequate, the improved alt text can be used to replace or supplement it. This improves the website's accessibility and search visibility.\n",
        "\n",
        "5. **Enhanced Metadata**:\n",
        "   - **What it is**: This field contains a dictionary of metadata, including `auto_tags`, `improved_alt_text`, and `category`. This additional data provides detailed information about the image that can be used to enhance its discoverability and ranking on search engines.\n",
        "   - **Use case**: Enhanced metadata provides search engines with rich information about each image, increasing the chances of the image appearing in image search results.\n",
        "   - **How it can be used**: Website owners can use this enhanced metadata to update image descriptions, add relevant tags, and create detailed image alt text. This can improve image ranking and drive more organic traffic.\n",
        "\n",
        "### What Steps Should a Website Owner Take Next?\n",
        "\n",
        "1. **Review and Update Image Descriptions**:\n",
        "   - If the original alt text is missing or not descriptive, replace it with the improved alt text.\n",
        "   - Ensure that the alt text is accurate, descriptive, and relevant to the content of the image.\n",
        "\n",
        "2. **Incorporate Auto-Generated Tags**:\n",
        "   - Use the tags generated by the model to add relevant keywords to your image metadata. This can make your images more discoverable through image searches and improve the overall SEO of your website.\n",
        "\n",
        "3. **Optimize Page Content**:\n",
        "   - Ensure that the images are relevant to the content of the pages they are used on. If necessary, update the page content or swap out images to improve the overall user experience.\n",
        "\n",
        "4. **Use Categories to Group Similar Images**:\n",
        "   - Leverage the generated categories to create thematic sections on your website. For example, if you have images categorized under `book_jacket`, you can create a section that showcases content related to books or publishing.\n",
        "\n",
        "5. **Monitor Performance**:\n",
        "   - Track the impact of these changes on your website's traffic, engagement, and image ranking in search engines. This will help you gauge the effectiveness of the changes and make further adjustments as needed.\n",
        "\n",
        "### Summary for Non-Technical Users\n",
        "\n",
        "- This output helps you better describe, categorize, and optimize the images on your website.\n",
        "- By improving image descriptions and metadata, your website becomes more accessible and easier for search engines to understand. This increases the likelihood of your images appearing in search results, which can drive more traffic to your site.\n",
        "- The steps you take based on this output can enhance user experience, improve SEO, and ultimately contribute to growing your business online.\n"
      ],
      "metadata": {
        "id": "IJHwqC5gwjNv"
      }
    }
  ]
}